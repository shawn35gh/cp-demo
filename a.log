Attaching to kibana, ksql-cli, control-center, ksql-server, elasticsearch, streams-demo, connect, restproxy, kafka-client, schemaregistry, kafka1, kafka2, replicator-for-jar-transfer, zookeeper
[32mcontrol-center                 |[0m ===> ENV Variables ...
[32mcontrol-center                 |[0m ALLOW_UNSIGNED=false
[32mcontrol-center                 |[0m COMPONENT=control-center
[32mcontrol-center                 |[0m CONFLUENT_DEB_VERSION=1
[32mcontrol-center                 |[0m CONFLUENT_MAJOR_VERSION=5
[32mcontrol-center                 |[0m CONFLUENT_MINOR_VERSION=3
[32mcontrol-center                 |[0m CONFLUENT_MVN_LABEL=
[32mcontrol-center                 |[0m CONFLUENT_PATCH_VERSION=1
[32mcontrol-center                 |[0m CONFLUENT_PLATFORM_LABEL=
[32mcontrol-center                 |[0m CONFLUENT_VERSION=5.3.1
[32mcontrol-center                 |[0m CONTROL_CENTER_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092
[32mcontrol-center                 |[0m CONTROL_CENTER_COMMAND_TOPIC_REPLICATION=2
[32mcontrol-center                 |[0m CONTROL_CENTER_CONFIG_DIR=/etc/confluent-control-center
[32mcontrol-center                 |[0m CONTROL_CENTER_CONNECT_CLUSTER=https://connect:8083
[32mcontrol-center                 |[0m CONTROL_CENTER_DATA_DIR=/var/lib/confluent-control-center
[32mcontrol-center                 |[0m CONTROL_CENTER_DEPRECATED_VIEWS_ENABLE=true
[32mcontrol-center                 |[0m CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS=1
[32mcontrol-center                 |[0m CONTROL_CENTER_INTERNAL_TOPICS_REPLICATION=2
[32mcontrol-center                 |[0m CONTROL_CENTER_KSQL_ADVERTISED_URL=http://localhost:8088
[32mcontrol-center                 |[0m CONTROL_CENTER_KSQL_URL=http://ksql-server:8088
[32mcontrol-center                 |[0m CONTROL_CENTER_METRICS_TOPIC_PARTITIONS=1
[32mcontrol-center                 |[0m CONTROL_CENTER_METRICS_TOPIC_REPLICATION=2
[32mcontrol-center                 |[0m CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS=1
[32mcontrol-center                 |[0m CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_REPLICATION=2
[32mcontrol-center                 |[0m CONTROL_CENTER_OPTS=-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.control-center.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.control-center.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[32mcontrol-center                 |[0m CONTROL_CENTER_REPLICATION_FACTOR=2
[32mcontrol-center                 |[0m CONTROL_CENTER_REST_LISTENERS=http://0.0.0.0:9021,https://0.0.0.0:9022
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:kibana@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[32mcontrol-center                 |[0m CONTROL_CENTER_REST_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.control-center.keystore.jks
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:elasticsearch@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
[32mcontrol-center                 |[0m CONTROL_CENTER_REST_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.control-center.truststore.jks
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:xpack_main@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from uninitialized to yellow - Waiting for Elasticsearch","prevState":"uninitialized","prevMsg":"uninitialized"}
[32mcontrol-center                 |[0m CONTROL_CENTER_SCHEMA_REGISTRY_URL=https://schemaregistry:8085
[32;1mkafka-client                   |[0m Waiting for Kafka to be ready...
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["error","elasticsearch","admin"],"pid":1,"message":"Request error, retrying\nHEAD http://elasticsearch:9200/ => connect ECONNREFUSED 172.19.0.12:9200"}
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_CACHE_MAX_BYTES_BUFFERING=100000000
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_CONSUMER_REQUEST_TIMEOUT_MS=960032
[32;1mkafka-client                   |[0m 	bootstrap.servers = [kafka1:9091]
[31melasticsearch                  |[0m [2020-05-20T20:04:01,895][INFO ][o.e.n.Node               ] [] initializing ...
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"No living connections"}
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS=1
[32;1mkafka-client                   |[0m 	client.dns.lookup = default
[31melasticsearch                  |[0m [2020-05-20T20:04:02,268][INFO ][o.e.e.NodeEnvironment    ] [_wToW1C] using [1] data paths, mounts [[/ (overlay)]], net usable_space [21.3gb], net total_space [48.4gb], spins? [possibly], types [overlay]
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:xpack_main@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from yellow to red - Unable to connect to Elasticsearch at http://elasticsearch:9200.","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
[32;1mkafka-client                   |[0m 	client.id = 
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_SASL_MECHANISM=PLAIN
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:elasticsearch@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from yellow to red - Unable to connect to Elasticsearch at http://elasticsearch:9200.","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
[31melasticsearch                  |[0m [2020-05-20T20:04:02,308][INFO ][o.e.e.NodeEnvironment    ] [_wToW1C] heap size [989.8mb], compressed ordinary object pointers [true]
[32;1mkafka-client                   |[0m 	connections.max.idle.ms = 300000
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_SECURITY_PROTOCOL=SASL_SSL
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:graph@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Unable to connect to Elasticsearch at http://elasticsearch:9200.","prevState":"uninitialized","prevMsg":"uninitialized"}
[31melasticsearch                  |[0m [2020-05-20T20:04:02,316][INFO ][o.e.n.Node               ] node name [_wToW1C] derived from node ID [_wToW1CEQpueeAlzWm7YgQ]; set [node.name] to override
[31melasticsearch                  |[0m [2020-05-20T20:04:02,316][INFO ][o.e.n.Node               ] version[5.6.0], pid[1], build[781a835/2017-09-07T03:09:58.087Z], OS[Linux/5.3.0-1017-aws/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_141/25.141-b16]
[34mstreams-demo                   |[0m -Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.control-center.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.control-center.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[32;1mkafka-client                   |[0m 	metadata.max.age.ms = 300000
[32;1mkafka-client                   |[0m 	metric.reporters = []
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:16Z","tags":["status","plugin:monitoring@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[31melasticsearch                  |[0m [2020-05-20T20:04:02,316][INFO ][o.e.n.Node               ] JVM arguments [-Xms2g, -Xmx2g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djdk.io.permissionsUseCanonicalPath=true, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j.skipJansi=true, -XX:+HeapDumpOnOutOfMemoryError, -Des.cgroups.hierarchy.override=/, -Xms1g, -Xmx1g, -Des.path.home=/usr/share/elasticsearch]
[34mstreams-demo                   |[0m 
[31melasticsearch                  |[0m [2020-05-20T20:04:13,205][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [aggs-matrix-stats]
[32;1mkafka-client                   |[0m 	metrics.num.samples = 2
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:17Z","tags":["reporting","warning"],"pid":1,"message":"Generating a random key for xpack.reporting.encryptionKey. To prevent pending reports from failing on restart, please set xpack.reporting.encryptionKey in kibana.yml"}
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[34mstreams-demo                   |[0m ALLOW_UNSIGNED=false
[33mzookeeper                      |[0m ===> ENV Variables ...
[31melasticsearch                  |[0m [2020-05-20T20:04:13,205][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [ingest-common]
[32;1mkafka-client                   |[0m 	metrics.recording.level = INFO
[33;1mrestproxy                      |[0m ===> ENV Variables ...
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.control-center.keystore.jks
[34mstreams-demo                   |[0m BASH=/bin/bash
[33mzookeeper                      |[0m ALLOW_UNSIGNED=false
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:17Z","tags":["status","plugin:reporting@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Unable to connect to Elasticsearch at http://elasticsearch:9200.","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	metrics.sample.window.ms = 30000
[31melasticsearch                  |[0m [2020-05-20T20:04:13,205][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [lang-expression]
[32mcontrol-center                 |[0m CONTROL_CENTER_STREAMS_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.control-center.truststore.jks
[34mstreams-demo                   |[0m BASHOPTS=cmdhist:complete_fullquote:extquote:force_fignore:hostcomplete:interactive_comments:progcomp:promptvars:sourcepath
[33;1mrestproxy                      |[0m ALLOW_UNSIGNED=false
[33mzookeeper                      |[0m COMPONENT=zookeeper
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:19Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[32;1mkafka-client                   |[0m 	receive.buffer.bytes = 65536
[31melasticsearch                  |[0m [2020-05-20T20:04:13,205][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [lang-groovy]
[32mcontrol-center                 |[0m CONTROL_CENTER_ZOOKEEPER_CONNECT=zookeeper:2181
[34mstreams-demo                   |[0m BASH_ALIASES=()
[33;1mrestproxy                      |[0m COMPONENT=kafka-rest
[33mzookeeper                      |[0m CONFLUENT_DEB_VERSION=1
[35mksql-server                    |[0m ===> ENV Variables ...
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:19Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"No living connections"}
[32;1mkafka-client                   |[0m 	reconnect.backoff.max.ms = 1000
[31melasticsearch                  |[0m [2020-05-20T20:04:13,207][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [lang-mustache]
[32mcontrol-center                 |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[34mstreams-demo                   |[0m BASH_ARGC=()
[33;1mrestproxy                      |[0m CONFLUENT_DEB_VERSION=1
[33mzookeeper                      |[0m CONFLUENT_MAJOR_VERSION=5
[35mksql-server                    |[0m COMPONENT=ksql-server
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:22Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[32;1mkafka-client                   |[0m 	reconnect.backoff.ms = 50
[31melasticsearch                  |[0m [2020-05-20T20:04:13,207][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [lang-painless]
[32mcontrol-center                 |[0m HOME=/root
[34mstreams-demo                   |[0m BASH_ARGV=()
[33;1mrestproxy                      |[0m CONFLUENT_MAJOR_VERSION=5
[33mzookeeper                      |[0m CONFLUENT_MINOR_VERSION=3
[35mksql-server                    |[0m CUB_CLASSPATH="/usr/share/java/cp-base-new/*"
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:22Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"No living connections"}
[32;1mkafka-client                   |[0m 	request.timeout.ms = 120000
[31;1mkafka1                         |[0m ===> ENV Variables ...
[31melasticsearch                  |[0m [2020-05-20T20:04:13,207][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [parent-join]
[32mcontrol-center                 |[0m HOSTNAME=497b23eee435
[34mstreams-demo                   |[0m BASH_CMDS=()
[33;1mrestproxy                      |[0m CONFLUENT_MINOR_VERSION=3
[33mzookeeper                      |[0m CONFLUENT_MVN_LABEL=
[35mksql-server                    |[0m HOME=/root
[31;1mkafka1                         |[0m ALLOW_UNSIGNED=false
[32;1mkafka-client                   |[0m 	retries = 5
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:24Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[31melasticsearch                  |[0m [2020-05-20T20:04:13,207][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [percolator]
[32mcontrol-center                 |[0m KAFKA_VERSION=5.3.1
[34mstreams-demo                   |[0m BASH_LINENO=([0]="0")
[33;1mrestproxy                      |[0m CONFLUENT_MVN_LABEL=
[33;1mrestproxy                      |[0m CONFLUENT_PATCH_VERSION=1
[31;1mkafka1                         |[0m COMPONENT=kafka
[35mksql-server                    |[0m HOSTNAME=ksql-server
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:24Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"No living connections"}
[31melasticsearch                  |[0m [2020-05-20T20:04:13,208][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [reindex]
[32mcontrol-center                 |[0m LANG=C.UTF-8
[32;1mkafka-client                   |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m BASH_SOURCE=([0]="/app/start.sh")
[33mzookeeper                      |[0m CONFLUENT_PATCH_VERSION=1
[33;1mrestproxy                      |[0m CONFLUENT_PLATFORM_LABEL=
[35mksql-server                    |[0m KSQL_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092
[31melasticsearch                  |[0m [2020-05-20T20:04:13,208][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [transport-netty3]
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:27Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[31;1mkafka1                         |[0m CONFLUENT_DEB_VERSION=1
[31;1mkafka1                         |[0m CONFLUENT_MAJOR_VERSION=5
[35;1mschemaregistry                 |[0m ===> ENV Variables ...
[32;1mkafka-client                   |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m BASH_VERSINFO=([0]="4" [1]="3" [2]="30" [3]="1" [4]="release" [5]="x86_64-pc-linux-gnu")
[33mzookeeper                      |[0m CONFLUENT_PLATFORM_LABEL=
[33;1mrestproxy                      |[0m CONFLUENT_VERSION=5.3.1
[35mksql-server                    |[0m KSQL_CACHE_MAX_BYTES_BUFFERING=0
[32mcontrol-center                 |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[31melasticsearch                  |[0m [2020-05-20T20:04:13,208][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded module [transport-netty4]
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS=kafka1:9091
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:27Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"No living connections"}
[35;1mschemaregistry                 |[0m ALLOW_UNSIGNED=false
[32;1mkafka-client                   |[0m 	sasl.jaas.config = [hidden]
[34mstreams-demo                   |[0m BASH_VERSION='4.3.30(1)-release'
[33mzookeeper                      |[0m CONFLUENT_VERSION=5.3.1
[33;1mrestproxy                      |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[35mksql-server                    |[0m KSQL_CLASSPATH=/usr/share/java/ksql-server/*
[32mcontrol-center                 |[0m PWD=/
[31melasticsearch                  |[0m [2020-05-20T20:04:13,208][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded plugin [ingest-geoip]
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_MAX_REQUEST_SIZE=10485760
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:30Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"Unable to revive connection: http://elasticsearch:9200/"}
[32;1mkafka-client                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35;1mschemaregistry                 |[0m COMPONENT=schema-registry
[34mstreams-demo                   |[0m COMPONENT=kafka
[33mzookeeper                      |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[33mzookeeper                      |[0m HOME=/root
[33mzookeeper                      |[0m HOSTNAME=zookeeper
[33;1mrestproxy                      |[0m HOME=/root
[32mcontrol-center                 |[0m PYTHON_PIP_VERSION=8.1.2
[31melasticsearch                  |[0m [2020-05-20T20:04:13,208][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded plugin [ingest-user-agent]
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_SASL_MECHANISM=PLAIN
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:30Z","tags":["warning","elasticsearch","admin"],"pid":1,"message":"No living connections"}
[32;1mkafka-client                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m ===> ENV Variables ...
[34;1mkafka2                         |[0m ALLOW_UNSIGNED=false
[34;1mkafka2                         |[0m COMPONENT=kafka
[34;1mkafka2                         |[0m CONFLUENT_DEB_VERSION=1
[34;1mkafka2                         |[0m CONFLUENT_MAJOR_VERSION=5
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS=kafka2:9092
[32mcontrol-center                 |[0m PYTHON_VERSION=2.7.9-1
[34mstreams-demo                   |[0m CONFLUENT_DEB_VERSION=1
[34mstreams-demo                   |[0m CONFLUENT_MAJOR_VERSION=5
[31melasticsearch                  |[0m [2020-05-20T20:04:13,208][INFO ][o.e.p.PluginsService     ] [_wToW1C] loaded plugin [x-pack]
[32;1mkafka-client                   |[0m 	sasl.kerberos.service.name = null
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:36Z","tags":["status","plugin:xpack_main@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from red to red - Request Timeout after 3000ms","prevState":"red","prevMsg":"Unable to connect to Elasticsearch at http://elasticsearch:9200."}
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_MAX_REQUEST_SIZE=10485760
[35mksql-server                    |[0m KSQL_CONFIG_DIR=/etc/ksql
[33mzookeeper                      |[0m KAFKA_OPTS=-Djava.security.auth.login.config=/etc/kafka/secrets/zookeeper_jaas.conf -Dzookeeper.authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider -DrequireClientAuthScheme=sasl
[36;1mconnect                        |[0m ===> ENV Variables ...
[32mcontrol-center                 |[0m SCALA_VERSION=2.12
[34mstreams-demo                   |[0m CONFLUENT_MINOR_VERSION=3
[34mstreams-demo                   |[0m CONFLUENT_MVN_LABEL=
[33;1mrestproxy                      |[0m HOSTNAME=restproxy
[35;1mschemaregistry                 |[0m CONFLUENT_DEB_VERSION=1
[31melasticsearch                  |[0m [2020-05-20T20:04:26,828][INFO ][o.e.x.m.j.p.l.CppLogMessageHandler] [controller/67] [Main.cc@128] controller (64 bit): Version 5.6.0 (Build 93aea61f57f7d8) Copyright (c) 2017 Elasticsearch BV
[32;1mkafka-client                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:36Z","tags":["status","plugin:graph@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from red to red - Request Timeout after 3000ms","prevState":"red","prevMsg":"Unable to connect to Elasticsearch at http://elasticsearch:9200."}
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_SASL_MECHANISM=PLAIN
[35mksql-server                    |[0m KSQL_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[33mzookeeper                      |[0m KAFKA_VERSION=5.3.1
[36;1mconnect                        |[0m ALLOW_UNSIGNED=false
[32mcontrol-center                 |[0m SHLVL=1
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL=SASL_SSL
[33;1mrestproxy                      |[0m KAFKAREST_OPTS=-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.client.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.client.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[34mstreams-demo                   |[0m CONFLUENT_PATCH_VERSION=0
[35;1mschemaregistry                 |[0m CONFLUENT_MAJOR_VERSION=5
[31melasticsearch                  |[0m [2020-05-20T20:04:26,913][INFO ][o.e.d.DiscoveryModule    ] [_wToW1C] using discovery type [single-node]
[32;1mkafka-client                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:36Z","tags":["status","plugin:reporting@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from red to red - Request Timeout after 3000ms","prevState":"red","prevMsg":"Unable to connect to Elasticsearch at http://elasticsearch:9200."}
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL=SASL_SSL
[35mksql-server                    |[0m KSQL_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=sasl_ssl
[33mzookeeper                      |[0m LANG=C.UTF-8
[36;1mconnect                        |[0m CLASSPATH=/usr/share/java/monitoring-interceptors/monitoring-interceptors-5.3.1.jar
[32mcontrol-center                 |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[33;1mrestproxy                      |[0m KAFKA_REST_BOOTSTRAP_SERVERS=SASL_SSL://kafka1:9091,SASL_SSL://kafka2:9092
[34mstreams-demo                   |[0m CONFLUENT_PLATFORM_LABEL=
[35;1mschemaregistry                 |[0m CONFLUENT_MINOR_VERSION=3
[31melasticsearch                  |[0m [2020-05-20T20:04:31,104][INFO ][o.e.n.Node               ] initialized
[32;1mkafka-client                   |[0m 	sasl.login.callback.handler.class = null
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:36Z","tags":["status","plugin:elasticsearch@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from red to red - Request Timeout after 3000ms","prevState":"red","prevMsg":"Unable to connect to Elasticsearch at http://elasticsearch:9200."}
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[35mksql-server                    |[0m KSQL_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[33mzookeeper                      |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect                        |[0m COMPONENT=kafka-connect
[32mcontrol-center                 |[0m _=/usr/bin/env
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[33;1mrestproxy                      |[0m KAFKA_REST_CLIENT_SASL_MECHANISM=PLAIN
[34mstreams-demo                   |[0m CONFLUENT_VERSION=5.3.0
[31melasticsearch                  |[0m [2020-05-20T20:04:31,104][INFO ][o.e.n.Node               ] [_wToW1C] starting ...
[35;1mschemaregistry                 |[0m CONFLUENT_MVN_LABEL=
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:39Z","tags":["warning"],"pid":1,"kibanaVersion":"5.5.2","nodes":[{"version":"5.6.0","http":{"publish_address":"172.19.0.12:9200"},"ip":"172.19.0.12"}],"message":"You're running Kibana 5.5.2 with some different versions of Elasticsearch. Update Kibana or Elasticsearch to the same version to prevent compatibility issues: v5.6.0 @ 172.19.0.12:9200 (172.19.0.12)"}
[32;1mkafka-client                   |[0m 	sasl.login.class = null
[33mzookeeper                      |[0m PWD=/
[35mksql-server                    |[0m KSQL_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m CONFLUENT_DEB_VERSION=1
[32mcontrol-center                 |[0m ===> User
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_TOPIC_CREATE=false
[33;1mrestproxy                      |[0m KAFKA_REST_CLIENT_SECURITY_PROTOCOL=SASL_SSL
[34mstreams-demo                   |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[31melasticsearch                  |[0m [2020-05-20T20:04:32,314][INFO ][o.e.t.TransportService   ] [_wToW1C] publish_address {172.19.0.12:9300}, bound_addresses {0.0.0.0:9300}
[35;1mschemaregistry                 |[0m CONFLUENT_PATCH_VERSION=1
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_TOPIC_CREATE=false
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:security@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Request Timeout after 3000ms","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[33mzookeeper                      |[0m PYTHON_PIP_VERSION=8.1.2
[35mksql-server                    |[0m KSQL_CONSUMER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
[32mcontrol-center                 |[0m uid=0(root) gid=0(root) groups=0(root)
[36;1mconnect                        |[0m CONFLUENT_MAJOR_VERSION=5
[31;1mkafka1                         |[0m CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS=2
[33;1mrestproxy                      |[0m KAFKA_REST_CLIENT_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.restproxy.keystore.jks
[34mstreams-demo                   |[0m DIRSTACK=()
[31melasticsearch                  |[0m [2020-05-20T20:04:32,419][WARN ][o.e.b.BootstrapChecks    ] [_wToW1C] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
[35;1mschemaregistry                 |[0m CONFLUENT_PLATFORM_LABEL=
[34;1mkafka2                         |[0m CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS=2
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["security","warning"],"pid":1,"message":"Generating a random key for xpack.security.encryptionKey. To prevent sessions from being invalidated on restart, please set xpack.security.encryptionKey in kibana.yml"}
[32;1mkafka-client                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[33mzookeeper                      |[0m PYTHON_VERSION=2.7.9-1
[35mksql-server                    |[0m KSQL_HOST_NAME=ksql-server
[32mcontrol-center                 |[0m ===> Configuring ...
[31;1mkafka1                         |[0m CONFLUENT_MINOR_VERSION=3
[33;1mrestproxy                      |[0m KAFKA_REST_CLIENT_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.restproxy.truststore.jks
[36;1mconnect                        |[0m CONFLUENT_MINOR_VERSION=3
[34mstreams-demo                   |[0m EUID=0
[31melasticsearch                  |[0m [2020-05-20T20:04:32,699][INFO ][o.e.c.s.ClusterService   ] [_wToW1C] new_master {_wToW1C}{_wToW1CEQpueeAlzWm7YgQ}{Bhv11ViSQ1KR_d7LSHQUTg}{172.19.0.12}{172.19.0.12:9300}{ml.max_open_jobs=10, ml.enabled=true}, reason: single-node-start-initial-join[{_wToW1C}{_wToW1CEQpueeAlzWm7YgQ}{Bhv11ViSQ1KR_d7LSHQUTg}{172.19.0.12}{172.19.0.12:9300}{ml.max_open_jobs=10, ml.enabled=true}]
[35;1mschemaregistry                 |[0m CONFLUENT_VERSION=5.3.1
[34;1mkafka2                         |[0m CONFLUENT_MINOR_VERSION=3
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["security","warning"],"pid":1,"message":"Session cookies will be transmitted over insecure connections. This is not recommended."}
[32;1mkafka-client                   |[0m 	sasl.login.refresh.window.factor = 0.8
[33mzookeeper                      |[0m SCALA_VERSION=2.12
[35mksql-server                    |[0m KSQL_KSQL_SCHEMA_REGISTRY_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[32mcontrol-center                 |[0m ===> Check if /etc/confluent-control-center is writable ...
[31;1mkafka1                         |[0m CONFLUENT_MVN_LABEL=
[33;1mrestproxy                      |[0m KAFKA_REST_HOST_NAME=restproxy
[36;1mconnect                        |[0m CONFLUENT_MVN_LABEL=
[34mstreams-demo                   |[0m GROUPS=()
[31melasticsearch                  |[0m [2020-05-20T20:04:33,040][INFO ][o.e.h.n.Netty4HttpServerTransport] [_wToW1C] publish_address {172.19.0.12:9200}, bound_addresses {0.0.0.0:9200}
[35;1mschemaregistry                 |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[34;1mkafka2                         |[0m CONFLUENT_MVN_LABEL=
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:searchprofiler@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Request Timeout after 3000ms","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[33mzookeeper                      |[0m SHLVL=1
[35mksql-server                    |[0m KSQL_KSQL_SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[32mcontrol-center                 |[0m ===> Check if /var/lib/confluent-control-center is writable ...
[31;1mkafka1                         |[0m CONFLUENT_PATCH_VERSION=1
[36;1mconnect                        |[0m CONFLUENT_PATCH_VERSION=1
[33;1mrestproxy                      |[0m KAFKA_REST_LISTENERS=https://0.0.0.0:8086
[34mstreams-demo                   |[0m HOME=/root
[31melasticsearch                  |[0m [2020-05-20T20:04:33,044][INFO ][o.e.n.Node               ] [_wToW1C] started
[35;1mschemaregistry                 |[0m HOME=/root
[34;1mkafka2                         |[0m CONFLUENT_PATCH_VERSION=1
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:ml@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Request Timeout after 3000ms","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	sasl.mechanism = PLAIN
[33mzookeeper                      |[0m ZOOKEEPER_CLIENT_PORT=2181
[35mksql-server                    |[0m KSQL_KSQL_SCHEMA_REGISTRY_URL=https://schemaregistry:8085
[32mcontrol-center                 |[0m ===> Running preflight checks ... 
[31;1mkafka1                         |[0m CONFLUENT_PLATFORM_LABEL=
[36;1mconnect                        |[0m CONFLUENT_PLATFORM_LABEL=
[33;1mrestproxy                      |[0m KAFKA_REST_SCHEMA_REGISTRY_URL=https://schemaregistry:8085
[34mstreams-demo                   |[0m HOSTNAME=streams-demo
[31melasticsearch                  |[0m [2020-05-20T20:04:34,361][INFO ][o.e.g.GatewayService     ] [_wToW1C] recovered [0] indices into cluster_state
[35;1mschemaregistry                 |[0m HOSTNAME=1ebbfc6660fb
[34;1mkafka2                         |[0m CONFLUENT_PLATFORM_LABEL=
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:ml@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - Waiting for Elasticsearch","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[33mzookeeper                      |[0m ZOOKEEPER_SERVER_ID=1
[35mksql-server                    |[0m KSQL_KSQL_SERVER_UI_ENABLED=false
[32;1mkafka-client                   |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m ===> Check if Kafka is healthy ...
[31;1mkafka1                         |[0m CONFLUENT_VERSION=5.3.1
[36;1mconnect                        |[0m CONFLUENT_VERSION=5.3.1
[33;1mrestproxy                      |[0m KAFKA_REST_SSL_CLIENT_AUTH=false
[34mstreams-demo                   |[0m HOSTTYPE=x86_64
[31melasticsearch                  |[0m [2020-05-20T20:04:34,433][INFO ][o.e.m.j.JvmGcMonitorService] [_wToW1C] [gc][3] overhead, spent [312ms] collecting in the last [1s]
[35;1mschemaregistry                 |[0m KAFKA_VERSION=5.3.1
[34;1mkafka2                         |[0m CONFLUENT_VERSION=5.3.1
[33mzookeeper                      |[0m ZOOKEEPER_TICK_TIME=2000
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:tilemap@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Request Timeout after 3000ms","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	send.buffer.bytes = 131072
[35mksql-server                    |[0m KSQL_LISTENERS=http://0.0.0.0:8088
[32mcontrol-center                 |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[31;1mkafka1                         |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[36;1mconnect                        |[0m CONNECT_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092
[33;1mrestproxy                      |[0m KAFKA_REST_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.restproxy.keystore.jks
[34mstreams-demo                   |[0m IFS=$' \t\n'
[31melasticsearch                  |[0m [2020-05-20T20:04:35,430][INFO ][o.e.x.m.MachineLearningTemplateRegistry] [_wToW1C] successfully created .ml-notifications index template
[35;1mschemaregistry                 |[0m LANG=C.UTF-8
[34;1mkafka2                         |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[33mzookeeper                      |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:watcher@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Request Timeout after 3000ms","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	ssl.cipher.suites = null
[35mksql-server                    |[0m KSQL_LOG4J_OPTS=-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties
[31;1mkafka1                         |[0m HOME=/root
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=2
[33;1mrestproxy                      |[0m KAFKA_REST_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.restproxy.truststore.jks
[34mstreams-demo                   |[0m JAVA_OPTS='-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.control-center.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.control-center.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent'
[35;1mschemaregistry                 |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[35;1mschemaregistry                 |[0m PWD=/
[35;1mschemaregistry                 |[0m PYTHON_PIP_VERSION=8.1.2
[35;1mschemaregistry                 |[0m PYTHON_VERSION=2.7.9-1
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:grokdebugger@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35mksql-server                    |[0m KSQL_PRODUCER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
[31;1mkafka1                         |[0m HOSTNAME=kafka1
[31;1mkafka1                         |[0m KAFKA_ADVERTISED_LISTENERS=SASL_SSL://kafka1:9091,SASL_SSL_HOST://localhost:29091,PLAINTEXT://kafka1:10091,SSL://kafka1:11091
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[33;1mrestproxy                      |[0m KAFKA_VERSION=5.3.1
[34mstreams-demo                   |[0m KAFKA_ADVERTISED_LISTENERS=
[34mstreams-demo                   |[0m KAFKA_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092
[34;1mkafka2                         |[0m HOME=/root
[31melasticsearch                  |[0m [2020-05-20T20:04:35,998][INFO ][o.e.x.m.MachineLearningTemplateRegistry] [_wToW1C] successfully created .ml-state index template
[35;1mschemaregistry                 |[0m SCALA_VERSION=2.12
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:console@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[32;1mkafka-client                   |[0m 	ssl.endpoint.identification.algorithm = https
[35mksql-server                    |[0m KSQL_SASL_MECHANISM=PLAIN
[31;1mkafka1                         |[0m KAFKA_AUTHORIZER_CLASS_NAME=kafka.security.auth.SimpleAclAuthorizer
[36;1mconnect                        |[0m CONNECT_CONFIG_STORAGE_TOPIC=connect-configs
[33;1mrestproxy                      |[0m LANG=C.UTF-8
[32mcontrol-center                 |[0m 	client.id = 
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG='org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'
[33mzookeeper                      |[0m _=/usr/bin/env
[34;1mkafka2                         |[0m HOSTNAME=kafka2
[31melasticsearch                  |[0m [2020-05-20T20:04:36,355][INFO ][o.e.x.m.MachineLearningTemplateRegistry] [_wToW1C] successfully created .ml-meta index template
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_HOST_NAME=schemaregistry
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:41Z","tags":["status","plugin:metrics@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[35mksql-server                    |[0m KSQL_SECURITY_PROTOCOL=SASL_SSL
[32;1mkafka-client                   |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
[31;1mkafka1                         |[0m KAFKA_BROKER_ID=1
[33;1mrestproxy                      |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[33mzookeeper                      |[0m ===> User
[34;1mkafka2                         |[0m KAFKA_ADVERTISED_LISTENERS=SASL_SSL://kafka2:9092,SASL_SSL_HOST://localhost:29092,PLAINTEXT://kafka2:10092,SSL://kafka2:11092
[31melasticsearch                  |[0m [2020-05-20T20:04:36,437][INFO ][o.e.m.j.JvmGcMonitorService] [_wToW1C] [gc][5] overhead, spent [348ms] collecting in the last [1s]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:42Z","tags":["status","plugin:ml@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Waiting for Elasticsearch"}
[35mksql-server                    |[0m KSQL_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[36;1mconnect                        |[0m CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[31;1mkafka1                         |[0m KAFKA_BROKER_RACK=r1
[32;1mkafka-client                   |[0m 	ssl.keymanager.algorithm = SunX509
[33;1mrestproxy                      |[0m PWD=/
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[33mzookeeper                      |[0m uid=0(root) gid=0(root) groups=0(root)
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=SASL_SSL
[34;1mkafka2                         |[0m KAFKA_AUTHORIZER_CLASS_NAME=kafka.security.auth.SimpleAclAuthorizer
[31melasticsearch                  |[0m [2020-05-20T20:04:37,499][INFO ][o.e.x.m.MachineLearningTemplateRegistry] [_wToW1C] successfully created .ml-anomalies- index template
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM=PLAIN
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:42Z","tags":["status","plugin:timelion@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from uninitialized to green - Ready","prevState":"uninitialized","prevMsg":"uninitialized"}
[35mksql-server                    |[0m KSQL_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[36;1mconnect                        |[0m CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=SASL_SSL
[32;1mkafka-client                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[33;1mrestproxy                      |[0m PYTHON_PIP_VERSION=8.1.2
[31;1mkafka1                         |[0m KAFKA_DELETE_TOPIC_ENABLE=true
[32mcontrol-center                 |[0m 	metric.reporters = []
[33mzookeeper                      |[0m ===> Configuring ...
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[31melasticsearch                  |[0m [2020-05-20T20:04:38,308][INFO ][o.e.l.LicenseService     ] [_wToW1C] license [fd990a38-371f-41bd-b18f-07f850be96cc] mode [trial] - valid
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL=SASL_SSL
[34;1mkafka2                         |[0m KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:42Z","tags":["listening","info"],"pid":1,"message":"Server running at http://0:5601"}
[35mksql-server                    |[0m KSQL_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[32;1mkafka-client                   |[0m 	ssl.keystore.password = [hidden]
[33;1mrestproxy                      |[0m PYTHON_VERSION=2.7.9-1
[31;1mkafka1                         |[0m KAFKA_INTER_BROKER_LISTENER_NAME=SASL_SSL
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[33mzookeeper                      |[0m ===> Running preflight checks ... 
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_PASSWORD=confluent
[31melasticsearch                  |[0m [2020-05-20T20:04:42,514][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.monitoring-es-6-2020.05.20] creating index, cause [auto(bulk api)], templates [.monitoring-es], shards [1]/[1], mappings [doc]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_KAFKASTORE_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[34;1mkafka2                         |[0m KAFKA_BROKER_ID=2
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:42Z","tags":["status","ui settings","error"],"pid":1,"state":"red","message":"Status changed from uninitialized to red - Elasticsearch plugin is red","prevState":"uninitialized","prevMsg":"uninitialized"}
[35mksql-server                    |[0m LANG=C.UTF-8
[36;1mconnect                        |[0m CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[33;1mrestproxy                      |[0m SCALA_VERSION=2.12
[32;1mkafka-client                   |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m KAFKA_JMX_PORT=9991
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[33mzookeeper                      |[0m ===> Check if /var/lib/zookeeper/data is writable ...
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEY_PASSWORD=confluent
[31melasticsearch                  |[0m [2020-05-20T20:04:43,919][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.watches] creating index, cause [auto(bulk api)], templates [watches], shards [1]/[1], mappings [watch]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[34;1mkafka2                         |[0m KAFKA_BROKER_RACK=r1
[34;1mkafka2                         |[0m KAFKA_DELETE_TOPIC_ENABLE=true
[35mksql-server                    |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect                        |[0m CONNECT_CONSUMER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
[33;1mrestproxy                      |[0m SCHEMA_REGISTRY_OPTS=-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.client.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.client.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[32;1mkafka-client                   |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[33mzookeeper                      |[0m ===> Check if /var/lib/zookeeper/log is writable ...
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[31melasticsearch                  |[0m [2020-05-20T20:04:45,615][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.kibana] creating index, cause [api], templates [], shards [1]/[1], mappings [_default_, index-pattern, server, visualization, search, graph-workspace, timelion-sheet, config, dashboard, url]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:xpack_main@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[34;1mkafka2                         |[0m KAFKA_INTER_BROKER_LISTENER_NAME=SASL_SSL
[35mksql-server                    |[0m PWD=/
[33;1mrestproxy                      |[0m SHLVL=1
[36;1mconnect                        |[0m CONNECT_CONSUMER_SASL_MECHANISM=PLAIN
[32;1mkafka-client                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m KAFKA_LOG4J_LOGGERS=kafka.authorizer.logger=INFO
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[33mzookeeper                      |[0m ===> Launching ... 
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_PASSWORD=confluent
[31melasticsearch                  |[0m [2020-05-20T20:04:46,906][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [.watches/CMNKyCmySVykc4w9Es6fwA] update_mapping [watch]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_LISTENERS=https://0.0.0.0:8085
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:graph@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[34;1mkafka2                         |[0m KAFKA_JMX_PORT=9991
[35mksql-server                    |[0m SHLVL=1
[33;1mrestproxy                      |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[32;1mkafka-client                   |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m CONNECT_CONSUMER_SECURITY_PROTOCOL=SASL_SSL
[31;1mkafka1                         |[0m KAFKA_METRIC_REPORTERS=io.confluent.metrics.reporter.ConfluentMetricsReporter
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[33mzookeeper                      |[0m ===> Printing /var/lib/zookeeper/data/myid 
[34mstreams-demo                   |[0m KAFKA_CONSUMER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
[31melasticsearch                  |[0m [2020-05-20T20:04:53,703][INFO ][o.e.m.j.JvmGcMonitorService] [_wToW1C] [gc][22] overhead, spent [291ms] collecting in the last [1s]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL=INFO
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:reporting@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[34;1mkafka2                         |[0m KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[35mksql-server                    |[0m _=/usr/bin/env
[33;1mrestproxy                      |[0m _=/usr/bin/env
[32;1mkafka-client                   |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m CONNECT_CONSUMER_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[31;1mkafka1                         |[0m KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=2
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG='org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'
[33mzookeeper                      |[0m 1===> Launching zookeeper ... 
[31melasticsearch                  |[0m [2020-05-20T20:05:02,796][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.monitoring-kibana-6-2020.05.20] creating index, cause [auto(bulk api)], templates [.monitoring-kibana], shards [1]/[1], mappings [doc]
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:security@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL=https
[34;1mkafka2                         |[0m KAFKA_LOG4J_LOGGERS=kafka.authorizer.logger=INFO
[35mksql-server                    |[0m ===> User
[33;1mrestproxy                      |[0m ===> User
[32;1mkafka-client                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m CONNECT_CONSUMER_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m KAFKA_OPTS=-Djava.security.auth.login.config=/etc/kafka/secrets/broker_jaas.conf
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[33mzookeeper                      |[0m [2020-05-20 20:03:56,185] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[31melasticsearch                  |[0m [2020-05-20T20:05:37,803][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [wikipediabot] creating index, cause [api], templates [], shards [1]/[1], mappings [wikichange]
[31melasticsearch                  |[0m [2020-05-20T20:05:37,942][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [en_wikipedia_gt_1] creating index, cause [api], templates [], shards [1]/[1], mappings [wikichange]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_SSL_CLIENT_AUTH=true
[34;1mkafka2                         |[0m KAFKA_METRIC_REPORTERS=io.confluent.metrics.reporter.ConfluentMetricsReporter
[35mksql-server                    |[0m uid=0(root) gid=0(root) groups=0(root)
[33;1mrestproxy                      |[0m uid=0(root) gid=0(root) groups=0(root)
[32;1mkafka-client                   |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m CONNECT_GROUP_ID=connect
[31;1mkafka1                         |[0m KAFKA_SASL_ENABLED_MECHANISMS=PLAIN
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=SASL_SSL
[32mcontrol-center                 |[0m 	retries = 5
[33mzookeeper                      |[0m [2020-05-20 20:03:56,187] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[31melasticsearch                  |[0m [2020-05-20T20:05:44,188][WARN ][o.e.d.r.RestController   ] Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.
[34;1mkafka2                         |[0m KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=2
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:searchprofiler@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[35mksql-server                    |[0m ===> Configuring ...
[33;1mrestproxy                      |[0m ===> Configuring ...
[32;1mkafka-client                   |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
[31;1mkafka1                         |[0m KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL=PLAIN
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[33mzookeeper                      |[0m [2020-05-20 20:03:56,187] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[31melasticsearch                  |[0m [2020-05-20T20:05:44,301][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [.kibana/dvBHlQCTRs-GFomLz2B-LA] update_mapping [config]
[35;1mschemaregistry                 |[0m SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[34;1mkafka2                         |[0m KAFKA_OPTS=-Djava.security.auth.login.config=/etc/kafka/secrets/broker_jaas.conf
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:ml@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from green to yellow - No existing Kibana index found","prevState":"green","prevMsg":"Ready"}
[35mksql-server                    |[0m ===> Running preflight checks ... 
[32;1mkafka-client                   |[0m 
[33;1mrestproxy                      |[0m ===> Running preflight checks ... 
[36;1mconnect                        |[0m CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
[31;1mkafka1                         |[0m KAFKA_SSL_CLIENT_AUTH=required
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_PASSWORD=confluent
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[33mzookeeper                      |[0m [2020-05-20 20:03:56,187] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[31melasticsearch                  |[0m [2020-05-20T20:05:44,547][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [.kibana/dvBHlQCTRs-GFomLz2B-LA] update_mapping [config]
[35;1mschemaregistry                 |[0m SHLVL=1
[34;1mkafka2                         |[0m KAFKA_SASL_ENABLED_MECHANISMS=PLAIN
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:tilemap@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[35mksql-server                    |[0m ===> Check if Kafka is healthy ...
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[33;1mrestproxy                      |[0m ===> Check if Kafka is healthy ...
[36;1mconnect                        |[0m CONNECT_KEY_CONVERTER=org.apache.kafka.connect.storage.StringConverter
[31;1mkafka1                         |[0m KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[33mzookeeper                      |[0m [2020-05-20 20:03:56,187] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEY_PASSWORD=confluent
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31melasticsearch                  |[0m [2020-05-20T20:05:44,730][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [.kibana/dvBHlQCTRs-GFomLz2B-LA] update_mapping [config]
[35;1mschemaregistry                 |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[34;1mkafka2                         |[0m KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL=PLAIN
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:watcher@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[35mksql-server                    |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'listeners' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[36;1mconnect                        |[0m CONNECT_LISTENERS=https://0.0.0.0:8083
[31;1mkafka1                         |[0m KAFKA_SSL_KEYSTORE_CREDENTIALS=kafka1_keystore_creds
[33mzookeeper                      |[0m [2020-05-20 20:03:56,218] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35;1mschemaregistry                 |[0m _=/usr/bin/env
[31melasticsearch                  |[0m [2020-05-20T20:05:44,920][WARN ][o.e.d.r.RestController   ] Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.
[34;1mkafka2                         |[0m KAFKA_SSL_CLIENT_AUTH=required
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","plugin:elasticsearch@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - No existing Kibana index found","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[35mksql-server                    |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m 	bootstrap.servers = [SASL_SSL://kafka1:9091, SASL_SSL://kafka2:9092]
[36;1mconnect                        |[0m CONNECT_LOG4J_LOGGERS=org.reflections=ERROR
[31;1mkafka1                         |[0m KAFKA_SSL_KEYSTORE_FILENAME=kafka.kafka1.keystore.jks
[33mzookeeper                      |[0m [2020-05-20 20:03:56,218] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_PASSWORD=confluent
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35;1mschemaregistry                 |[0m ===> User
[31melasticsearch                  |[0m [2020-05-20T20:05:49,322][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.triggered_watches] creating index, cause [auto(bulk api)], templates [triggered_watches], shards [1]/[1], mappings [triggered_watch]
[34;1mkafka2                         |[0m KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:45Z","tags":["status","ui settings","info"],"pid":1,"state":"yellow","message":"Status changed from red to yellow - Elasticsearch plugin is yellow","prevState":"red","prevMsg":"Elasticsearch plugin is red"}
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'broker.id' was supplied but isn't a known config.
[35mksql-server                    |[0m 	client.dns.lookup = default
[33;1mrestproxy                      |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m CONNECT_LOG4J_ROOT_LOGLEVEL=INFO
[31;1mkafka1                         |[0m KAFKA_SSL_KEY_CREDENTIALS=kafka1_sslkey_creds
[33mzookeeper                      |[0m [2020-05-20 20:03:56,231] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[35;1mschemaregistry                 |[0m uid=0(root) gid=0(root) groups=0(root)
[31melasticsearch                  |[0m [2020-05-20T20:05:50,821][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.watcher-history-6-2020.05.20] creating index, cause [auto(bulk api)], templates [.watch-history-6], shards [1]/[1], mappings [doc]
[34;1mkafka2                         |[0m KAFKA_SSL_KEYSTORE_CREDENTIALS=kafka2_keystore_creds
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:elasticsearch@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Kibana index ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'zookeeper.set.acl' was supplied but isn't a known config.
[35mksql-server                    |[0m 	client.id = 
[33;1mrestproxy                      |[0m 	client.id = 
[36;1mconnect                        |[0m CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=2
[31;1mkafka1                         |[0m KAFKA_SSL_TRUSTSTORE_CREDENTIALS=kafka1_truststore_creds
[34mstreams-demo                   |[0m KAFKA_SASL_JAAS_CONFIG='org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'
[33mzookeeper                      |[0m [2020-05-20 20:03:56,231] INFO Server environment:host.name=zookeeper (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35;1mschemaregistry                 |[0m ===> Configuring ...
[31melasticsearch                  |[0m [2020-05-20T20:05:51,202][INFO ][o.e.c.m.MetaDataCreateIndexService] [_wToW1C] [.monitoring-alerts-6] creating index, cause [auto(bulk api)], templates [.monitoring-alerts], shards [1]/[1], mappings [doc]
[34;1mkafka2                         |[0m KAFKA_SSL_KEYSTORE_FILENAME=kafka.kafka2.keystore.jks
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","ui settings","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"Elasticsearch plugin is yellow"}
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[35mksql-server                    |[0m 	connections.max.idle.ms = 300000
[36;1mconnect                        |[0m CONNECT_OFFSET_STORAGE_TOPIC=connect-offsets
[33;1mrestproxy                      |[0m 	connections.max.idle.ms = 300000
[31;1mkafka1                         |[0m KAFKA_SSL_TRUSTSTORE_FILENAME=kafka.kafka1.truststore.jks
[33mzookeeper                      |[0m [2020-05-20 20:03:56,231] INFO Server environment:java.version=1.8.0_212 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m KAFKA_SASL_MECHANISM=PLAIN
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35;1mschemaregistry                 |[0m ===> Running preflight checks ... 
[31melasticsearch                  |[0m [2020-05-20T20:05:52,010][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [.watcher-history-6-2020.05.20/-nHvn6ahROmeM3jP5qTN8w] update_mapping [doc]
[34;1mkafka2                         |[0m KAFKA_SSL_KEY_CREDENTIALS=kafka2_sslkey_creds
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["license","info","xpack"],"pid":1,"message":"Imported license information from Elasticsearch for [data] cluster: mode: trial | status: active | expiry date: 2020-06-19T20:04:37+00:00"}
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'log.dirs' was supplied but isn't a known config.
[35mksql-server                    |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m CONNECT_PLUGIN_PATH=/usr/share/java,/connect-plugins
[33;1mrestproxy                      |[0m 	metadata.max.age.ms = 300000
[33mzookeeper                      |[0m [2020-05-20 20:03:56,231] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m KAFKA_SUPER_USERS=User:client;User:schemaregistry;User:restproxy;User:broker;User:connect;User:ANONYMOUS
[34mstreams-demo                   |[0m KAFKA_SCHEMA_REGISTRY_URL=https://schemaregistry:8085
[35;1mschemaregistry                 |[0m ===> Check if Kafka is healthy ...
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[31melasticsearch                  |[0m [2020-05-20T20:05:52,922][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [.watcher-history-6-2020.05.20/-nHvn6ahROmeM3jP5qTN8w] update_mapping [doc]
[34;1mkafka2                         |[0m KAFKA_SSL_TRUSTSTORE_CREDENTIALS=kafka2_truststore_creds
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:xpack_main@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[35mksql-server                    |[0m 	metric.reporters = []
[36;1mconnect                        |[0m CONNECT_PRODUCER_CLIENT_ID=connect-worker-producer
[33;1mrestproxy                      |[0m 	metric.reporters = []
[33mzookeeper                      |[0m [2020-05-20 20:03:56,231] INFO Server environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m KAFKA_SECURITY_PROTOCOL=SASL_SSL
[31;1mkafka1                         |[0m KAFKA_VERSION=5.3.1
[35;1mschemaregistry                 |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31melasticsearch                  |[0m [2020-05-20T20:06:39,003][INFO ][o.e.c.m.MetaDataMappingService] [_wToW1C] [wikipediabot/KY_bRz2CSQuKCA9WHdZWMA] update_mapping [wikichange]
[34;1mkafka2                         |[0m KAFKA_SSL_TRUSTSTORE_FILENAME=kafka.kafka2.truststore.jks
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:graph@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[35mksql-server                    |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[33;1mrestproxy                      |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[33mzookeeper                      |[0m [2020-05-20 20:03:56,231] INFO Server environment:java.class.path=/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
[35;1mschemaregistry                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m KAFKA_SUPER_USERS=User:client;User:schemaregistry;User:restproxy;User:broker;User:connect;User:ANONYMOUS
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:reporting@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005046896
[35mksql-server                    |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=SASL_SSL
[33;1mrestproxy                      |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m KAFKA_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m KAFKA_ZOOKEEPER_SET_ACL=true
[35;1mschemaregistry                 |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[33mzookeeper                      |[0m [2020-05-20 20:03:56,232] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m KAFKA_VERSION=5.3.1
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:security@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[33;1mrestproxy                      |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m KAFKA_SSL_KEYSTORE_PASSWORD=confluent
[35;1mschemaregistry                 |[0m 	client.id = 
[31;1mkafka1                         |[0m LANG=C.UTF-8
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[33mzookeeper                      |[0m [2020-05-20 20:03:56,232] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:searchprofiler@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m 	receive.buffer.bytes = 65536
[36;1mconnect                        |[0m CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[33;1mrestproxy                      |[0m 	receive.buffer.bytes = 65536
[34mstreams-demo                   |[0m KAFKA_SSL_KEY_PASSWORD=confluent
[35;1mschemaregistry                 |[0m 	connections.max.idle.ms = 300000
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[33mzookeeper                      |[0m [2020-05-20 20:03:56,232] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m KAFKA_ZOOKEEPER_SET_ACL=true
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:ml@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m CONNECT_PRODUCER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
[33;1mrestproxy                      |[0m 	reconnect.backoff.max.ms = 1000
[34mstreams-demo                   |[0m KAFKA_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[35;1mschemaregistry                 |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m PWD=/
[34;1mkafka2                         |[0m LANG=C.UTF-8
[33mzookeeper                      |[0m [2020-05-20 20:03:56,232] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:tilemap@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m CONNECT_PRODUCER_SASL_MECHANISM=PLAIN
[33;1mrestproxy                      |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m KAFKA_SSL_TRUSTSTORE_PASSWORD=confluent
[35;1mschemaregistry                 |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m PYTHON_PIP_VERSION=8.1.2
[34;1mkafka2                         |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[33mzookeeper                      |[0m [2020-05-20 20:03:56,233] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[35mksql-server                    |[0m 	request.timeout.ms = 120000
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:watcher@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from yellow to green - Ready","prevState":"yellow","prevMsg":"No existing Kibana index found"}
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	request.timeout.ms = 120000
[36;1mconnect                        |[0m CONNECT_PRODUCER_SECURITY_PROTOCOL=SASL_SSL
[34mstreams-demo                   |[0m KAFKA_VERSION=5.3.0
[35;1mschemaregistry                 |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m PYTHON_VERSION=2.7.9-1
[34;1mkafka2                         |[0m PWD=/
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:03:56,233] INFO Server environment:os.version=5.3.0-1017-aws (org.apache.zookeeper.server.ZooKeeperServer)
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["license","info","xpack"],"pid":1,"message":"Imported license information from Elasticsearch for [monitoring] cluster: mode: trial | status: active | expiry date: 2020-06-19T20:04:37+00:00"}
[33;1mrestproxy                      |[0m 	retries = 5
[36;1mconnect                        |[0m CONNECT_PRODUCER_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[34mstreams-demo                   |[0m KAFKA_ZOOKEEPER_CONNECT=
[35mksql-server                    |[0m 	retries = 5
[35;1mschemaregistry                 |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m SCALA_VERSION=2.12
[34;1mkafka2                         |[0m PYTHON_PIP_VERSION=8.1.2
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:03:56,233] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:48Z","tags":["status","plugin:monitoring@5.5.2","info"],"pid":1,"state":"yellow","message":"Status changed from green to yellow - Waiting for Monitoring Health Check","prevState":"green","prevMsg":"Ready"}
[33;1mrestproxy                      |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m CONNECT_PRODUCER_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[34mstreams-demo                   |[0m LANG=C.UTF-8
[35mksql-server                    |[0m 	retry.backoff.ms = 100
[35;1mschemaregistry                 |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m SHLVL=2
[34;1mkafka2                         |[0m PYTHON_VERSION=2.7.9-1
[32;1mkafka-client                   |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:03:56,233] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mrestproxy                      |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m MACHTYPE=x86_64-pc-linux-gnu
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:52Z","tags":["status","plugin:monitoring@5.5.2","error"],"pid":1,"state":"red","message":"Status changed from yellow to red - Request Timeout after 3000ms","prevState":"yellow","prevMsg":"Waiting for Monitoring Health Check"}
[36;1mconnect                        |[0m CONNECT_REPLICATION_FACTOR=2
[35;1mschemaregistry                 |[0m 	receive.buffer.bytes = 65536
[35mksql-server                    |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[34;1mkafka2                         |[0m SCALA_VERSION=2.12
[33mzookeeper                      |[0m [2020-05-20 20:03:56,233] INFO Server environment:user.dir=/ (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mrestproxy                      |[0m 	sasl.jaas.config = [hidden]
[34mstreams-demo                   |[0m OPTERR=1
[36;1mconnect                        |[0m CONNECT_REST_ADVERTISED_HOST_NAME=connect
[35;1mschemaregistry                 |[0m 	reconnect.backoff.max.ms = 1000
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:55Z","tags":["warning"],"pid":1,"kibanaVersion":"5.5.2","nodes":[{"version":"5.6.0","http":{"publish_address":"172.19.0.12:9200"},"ip":"172.19.0.12"}],"message":"You're running Kibana 5.5.2 with some different versions of Elasticsearch on a monitoring cluster. Update Kibana and Elasticsearch to the same version to prevent compatibility issues: v5.6.0 @ 172.19.0.12:9200 (172.19.0.12)"}
[35mksql-server                    |[0m 	sasl.jaas.config = [hidden]
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m _=/usr/bin/env
[32;1mkafka-client                   |[0m 	bootstrap.servers = [kafka2:9092]
[33mzookeeper                      |[0m [2020-05-20 20:03:56,242] INFO tickTime set to 2000 (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m SHLVL=2
[33;1mrestproxy                      |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mstreams-demo                   |[0m OPTIND=1
[36;1mconnect                        |[0m CONNECT_REST_PORT=8083
[35;1mschemaregistry                 |[0m 	reconnect.backoff.ms = 50
[36mkibana                         |[0m {"type":"log","@timestamp":"2020-05-20T20:04:55Z","tags":["status","plugin:monitoring@5.5.2","info"],"pid":1,"state":"green","message":"Status changed from red to green - Ready","prevState":"red","prevMsg":"Request Timeout after 3000ms"}
[35mksql-server                    |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m ===> User
[32;1mkafka-client                   |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[33mzookeeper                      |[0m [2020-05-20 20:03:56,242] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mrestproxy                      |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m OSTYPE=linux-gnu
[36;1mconnect                        |[0m CONNECT_SASL_MECHANISM=PLAIN
[35;1mschemaregistry                 |[0m 	request.timeout.ms = 120000
[36mkibana                         |[0m {"type":"response","@timestamp":"2020-05-20T20:05:44Z","tags":[],"pid":1,"method":"put","statusCode":201,"req":{"url":"/es_admin/.kibana/index-pattern/wikipediabot/_create","method":"put","headers":{"host":"localhost:5601","user-agent":"curl/7.58.0","accept":"*/*","kbn-version":"5.5.2","content-length":"75","content-type":"application/x-www-form-urlencoded"},"remoteAddress":"172.19.0.1","userAgent":"172.19.0.1"},"res":{"statusCode":201,"responseTime":55,"contentLength":9},"message":"PUT /es_admin/.kibana/index-pattern/wikipediabot/_create 201 55ms - 9.0B"}
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[35mksql-server                    |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m uid=0(root) gid=0(root) groups=0(root)
[34;1mkafka2                         |[0m _=/usr/bin/env
[32;1mkafka-client                   |[0m 	client.id = 
[33mzookeeper                      |[0m [2020-05-20 20:03:56,242] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mrestproxy                      |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect                        |[0m CONNECT_SECURITY_PROTOCOL=SASL_SSL
[35;1mschemaregistry                 |[0m 	retries = 5
[36mkibana                         |[0m {"type":"response","@timestamp":"2020-05-20T20:05:44Z","tags":[],"pid":1,"method":"post","statusCode":200,"req":{"url":"/api/kibana/settings/timelion:es.default_index","method":"post","headers":{"host":"localhost:5601","user-agent":"curl/7.58.0","accept":"*/*","kbn-version":"5.5.2","content-type":"application/json;charset=UTF-8","content-length":"24"},"remoteAddress":"172.19.0.1","userAgent":"172.19.0.1"},"res":{"statusCode":200,"responseTime":287,"contentLength":9},"message":"POST /api/kibana/settings/timelion:es.default_index 200 287ms - 9.0B"}
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[35mksql-server                    |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m ===> Configuring ...
[34;1mkafka2                         |[0m ===> User
[32;1mkafka-client                   |[0m 	connections.max.idle.ms = 300000
[33mzookeeper                      |[0m [2020-05-20 20:03:56,251] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[33;1mrestproxy                      |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m PIPESTATUS=([0]="0")
[36;1mconnect                        |[0m CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[35;1mschemaregistry                 |[0m 	retry.backoff.ms = 100
[36mkibana                         |[0m {"type":"response","@timestamp":"2020-05-20T20:05:44Z","tags":[],"pid":1,"method":"post","statusCode":200,"req":{"url":"/api/kibana/settings/timelion:es.timefield","method":"post","headers":{"host":"localhost:5601","user-agent":"curl/7.58.0","accept":"*/*","kbn-version":"5.5.2","content-type":"application/json;charset=UTF-8","content-length":"21"},"remoteAddress":"172.19.0.1","userAgent":"172.19.0.1"},"res":{"statusCode":200,"responseTime":172,"contentLength":9},"message":"POST /api/kibana/settings/timelion:es.timefield 200 172ms - 9.0B"}
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[35mksql-server                    |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m SSL is enabled.
[34;1mkafka2                         |[0m uid=0(root) gid=0(root) groups=0(root)
[33mzookeeper                      |[0m [2020-05-20 20:03:56,257] INFO Server successfully logged in. (org.apache.zookeeper.Login)
[33;1mrestproxy                      |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32;1mkafka-client                   |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m PPID=0
[36;1mconnect                        |[0m CONNECT_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[35;1mschemaregistry                 |[0m 	sasl.client.callback.handler.class = null
[36mkibana                         |[0m {"type":"response","@timestamp":"2020-05-20T20:05:44Z","tags":[],"pid":1,"method":"post","statusCode":200,"req":{"url":"/api/kibana/settings/defaultIndex","method":"post","headers":{"host":"localhost:5601","user-agent":"curl/7.58.0","accept":"*/*","kbn-version":"5.5.2","content-type":"application/json;charset=UTF-8","content-length":"24"},"remoteAddress":"172.19.0.1","userAgent":"172.19.0.1"},"res":{"statusCode":200,"responseTime":186,"contentLength":9},"message":"POST /api/kibana/settings/defaultIndex 200 186ms - 9.0B"}
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[35mksql-server                    |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m SASL is enabled.
[34;1mkafka2                         |[0m ===> Configuring ...
[33mzookeeper                      |[0m [2020-05-20 20:03:56,261] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mrestproxy                      |[0m 	sasl.login.callback.handler.class = null
[32;1mkafka-client                   |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m PS4='+ '
[36;1mconnect                        |[0m CONNECT_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[35;1mschemaregistry                 |[0m 	sasl.jaas.config = [hidden]
[36mkibana                         |[0m {"type":"response","@timestamp":"2020-05-20T20:05:44Z","tags":[],"pid":1,"method":"put","statusCode":201,"req":{"url":"/es_admin/.kibana/index-pattern/en_wikipedia_gt_1/_create","method":"put","headers":{"host":"localhost:5601","user-agent":"curl/7.58.0","accept":"*/*","kbn-version":"5.5.2","content-length":"50","content-type":"application/x-www-form-urlencoded"},"remoteAddress":"172.19.0.1","userAgent":"172.19.0.1"},"res":{"statusCode":201,"responseTime":14,"contentLength":9},"message":"PUT /es_admin/.kibana/index-pattern/en_wikipedia_gt_1/_create 201 14ms - 9.0B"}
[32mcontrol-center                 |[0m 	ssl.provider = null
[35mksql-server                    |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m SSL is enabled.
[31;1mkafka1                         |[0m ===> Running preflight checks ... 
[33mzookeeper                      |[0m [2020-05-20 20:04:07,209] INFO Accepted socket connection from /172.19.0.4:50046 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[33;1mrestproxy                      |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m PWD=/
[36;1mconnect                        |[0m CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=2
[32;1mkafka-client                   |[0m 	metrics.num.samples = 2
[35;1mschemaregistry                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkibana                         |[0m {"type":"response","@timestamp":"2020-05-20T20:05:44Z","tags":[],"pid":1,"method":"post","statusCode":200,"req":{"url":"/api/kibana/dashboards/import?force=false","method":"post","headers":{"host":"localhost:5601","user-agent":"curl/7.58.0","accept":"*/*","kbn-xsrf":"true","content-type":"application/json","content-length":"11086","expect":"100-continue"},"remoteAddress":"172.19.0.1","userAgent":"172.19.0.1"},"res":{"statusCode":200,"responseTime":160,"contentLength":9},"message":"POST /api/kibana/dashboards/import?force=false 200 160ms - 9.0B"}
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[35mksql-server                    |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m SASL is enabled.
[31;1mkafka1                         |[0m ===> Check if /var/lib/kafka/data is writable ...
[33;1mrestproxy                      |[0m 	sasl.login.refresh.buffer.seconds = 300
[33mzookeeper                      |[0m [2020-05-20 20:04:07,256] INFO Client attempting to establish new session at /172.19.0.4:50046 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m PYTHON_PIP_VERSION=8.1.2
[32;1mkafka-client                   |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m CONNECT_STATUS_STORAGE_TOPIC=connect-statuses
[35;1mschemaregistry                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m ===> Running preflight checks ... 
[35mksql-server                    |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m ===> Check if Zookeeper is healthy ...
[33;1mrestproxy                      |[0m 	sasl.login.refresh.min.period.seconds = 60
[33mzookeeper                      |[0m [2020-05-20 20:04:07,257] INFO Accepted socket connection from /172.19.0.5:50804 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[34mstreams-demo                   |[0m PYTHON_VERSION=2.7.9-1
[32;1mkafka-client                   |[0m 	metrics.sample.window.ms = 30000
[35;1mschemaregistry                 |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34;1mkafka2                         |[0m ===> Check if /var/lib/kafka/data is writable ...
[36;1mconnect                        |[0m CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
[31;1mkafka1                         |[0m [main] INFO io.confluent.admin.utils.ClusterStatus - SASL is enabled. java.security.auth.login.config=/etc/kafka/secrets/broker_jaas.conf
[33;1mrestproxy                      |[0m 	sasl.login.refresh.window.factor = 0.8
[35mksql-server                    |[0m 	sasl.login.refresh.min.period.seconds = 60
[33mzookeeper                      |[0m [2020-05-20 20:04:07,258] INFO Client attempting to establish new session at /172.19.0.5:50804 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m SCALA_VERSION=2.12
[32;1mkafka-client                   |[0m 	receive.buffer.bytes = 65536
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m ===> Check if Zookeeper is healthy ...
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[36;1mconnect                        |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[33;1mrestproxy                      |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m HOME=/root
[34mstreams-demo                   |[0m SHELL=/bin/bash
[33mzookeeper                      |[0m [2020-05-20 20:04:07,259] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[32;1mkafka-client                   |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [main] INFO io.confluent.admin.utils.ClusterStatus - SASL is enabled. java.security.auth.login.config=/etc/kafka/secrets/broker_jaas.conf
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:host.name=kafka1
[35mksql-server                    |[0m 	sasl.login.refresh.window.factor = 0.8
[33;1mrestproxy                      |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m HOSTNAME=f5178f8227f2
[34mstreams-demo                   |[0m SHELLOPTS=braceexpand:hashall:interactive-comments
[33mzookeeper                      |[0m [2020-05-20 20:04:07,271] INFO Established session 0x1000183079c0000 with negotiated timeout 40000 for client /172.19.0.4:50046 (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 
[32;1mkafka-client                   |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_212
[35;1mschemaregistry                 |[0m 	sasl.login.callback.handler.class = null
[35mksql-server                    |[0m 	sasl.login.refresh.window.jitter = 0.05
[33;1mrestproxy                      |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m SHLVL=1
[33mzookeeper                      |[0m [2020-05-20 20:04:07,272] INFO Established session 0x1000183079c0001 with negotiated timeout 40000 for client /172.19.0.5:50804 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m KAFKA_ADVERTISED_LISTENERS=
[32;1mkafka-client                   |[0m 	request.timeout.ms = 120000
[32mcontrol-center                 |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Azul Systems, Inc.
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:host.name=kafka2
[35;1mschemaregistry                 |[0m 	sasl.login.class = null
[33;1mrestproxy                      |[0m 	send.buffer.bytes = 131072
[35mksql-server                    |[0m 	sasl.mechanism = PLAIN
[35mksql-server                    |[0m 	security.protocol = SASL_SSL
[33mzookeeper                      |[0m [2020-05-20 20:04:07,288] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m KAFKA_OPTS=-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.connect.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.connect.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[32;1mkafka-client                   |[0m 	retries = 5
[32mcontrol-center                 |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_212
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[33;1mrestproxy                      |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m TERM=dumb
[35mksql-server                    |[0m 	send.buffer.bytes = 131072
[33mzookeeper                      |[0m [2020-05-20 20:04:07,295] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m KAFKA_VERSION=5.3.1
[32;1mkafka-client                   |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Azul Systems, Inc.
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[33;1mrestproxy                      |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m UID=0
[35mksql-server                    |[0m 	ssl.cipher.suites = null
[33mzookeeper                      |[0m [2020-05-20 20:04:07,307] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m KAFKA_ZOOKEEPER_CONNECT=
[32;1mkafka-client                   |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[32mcontrol-center                 |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'num.stream.threads' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre
[33;1mrestproxy                      |[0m 	ssl.endpoint.identification.algorithm = https
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34mstreams-demo                   |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[35mksql-server                    |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mzookeeper                      |[0m [2020-05-20 20:04:07,308] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m LANG=C.UTF-8
[32;1mkafka-client                   |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[32mcontrol-center                 |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/etc/confluent/docker/docker-utils.jar
[33;1mrestproxy                      |[0m 	ssl.key.password = [hidden]
[34mstreams-demo                   |[0m _=echo
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[33mzookeeper                      |[0m [2020-05-20 20:04:07,308] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[35mksql-server                    |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[32;1mkafka-client                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
[32mcontrol-center                 |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[33;1mrestproxy                      |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[35;1mschemaregistry                 |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m [main] INFO io.confluent.kafka.serializers.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
[33mzookeeper                      |[0m [2020-05-20 20:04:07,309] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[35mksql-server                    |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m PWD=/
[32;1mkafka-client                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
[32mcontrol-center                 |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005046551
[33;1mrestproxy                      |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.restproxy.keystore.jks
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[35;1mschemaregistry                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:04:07,311] INFO Processed session termination for sessionid: 0x1000183079c0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m PYTHON_PIP_VERSION=8.1.2
[32;1mkafka-client                   |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
[33;1mrestproxy                      |[0m 	ssl.keystore.password = [hidden]
[35;1mschemaregistry                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[33mzookeeper                      |[0m [2020-05-20 20:04:07,312] INFO Processed session termination for sessionid: 0x1000183079c0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[36;1mconnect                        |[0m PYTHON_VERSION=2.7.9-1
[32;1mkafka-client                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.version=5.3.0-1017-aws
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	ssl.keystore.type = JKS
[35;1mschemaregistry                 |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:04:07,315] INFO Closed socket connection for client /172.19.0.5:50804 which had sessionid 0x1000183079c0001 (org.apache.zookeeper.server.NIOServerCnxn)
[35mksql-server                    |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m SCALA_VERSION=2.12
[32;1mkafka-client                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.name=root
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mrestproxy                      |[0m 	ssl.protocol = TLS
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[33mzookeeper                      |[0m [2020-05-20 20:04:07,320] INFO Closed socket connection for client /172.19.0.4:50046 which had sessionid 0x1000183079c0000 (org.apache.zookeeper.server.NIOServerCnxn)
[35mksql-server                    |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m SCHEMA_REGISTRY_OPTS=-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.client.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.client.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[32;1mkafka-client                   |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.home=/root
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.version=5.3.0-1017-aws
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[33;1mrestproxy                      |[0m 	ssl.provider = null
[33mzookeeper                      |[0m [2020-05-20 20:04:09,817] INFO Accepted socket connection from /172.19.0.4:50178 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35mksql-server                    |[0m 	ssl.protocol = TLS
[32;1mkafka-client                   |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m SHLVL=1
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.name=root
[35;1mschemaregistry                 |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[33;1mrestproxy                      |[0m 	ssl.secure.random.implementation = null
[33mzookeeper                      |[0m [2020-05-20 20:04:09,821] INFO Client attempting to establish new session at /172.19.0.4:50178 (org.apache.zookeeper.server.ZooKeeperServer)
[35mksql-server                    |[0m 	ssl.provider = null
[32;1mkafka-client                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.home=/root
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@30dae81
[35;1mschemaregistry                 |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	ssl.trustmanager.algorithm = PKIX
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:04:09,823] INFO Established session 0x1000183079c0002 with negotiated timeout 6000 for client /172.19.0.4:50178 (org.apache.zookeeper.server.ZooKeeperServer)
[35mksql-server                    |[0m 	ssl.secure.random.implementation = null
[32;1mkafka-client                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m _=/usr/bin/env
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/
[31;1mkafka1                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.Login - Client successfully logged in.
[35;1mschemaregistry                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.restproxy.truststore.jks
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[33mzookeeper                      |[0m [2020-05-20 20:04:09,832] INFO Accepted socket connection from /172.19.0.5:50936 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32;1mkafka-client                   |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m ===> User
[35mksql-server                    |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@30dae81
[31;1mkafka1                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.client.ZooKeeperSaslClient - Client will use DIGEST-MD5 as SASL mechanism.
[35;1mschemaregistry                 |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	ssl.truststore.password = [hidden]
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[33mzookeeper                      |[0m [2020-05-20 20:04:09,895] INFO Client attempting to establish new session at /172.19.0.5:50936 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m uid=0(root) gid=0(root) groups=0(root)
[32;1mkafka-client                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server zookeeper/172.19.0.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
[35mksql-server                    |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.Login - Client successfully logged in.
[35;1mschemaregistry                 |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	ssl.truststore.type = JKS
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[33mzookeeper                      |[0m [2020-05-20 20:04:09,895] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[32;1mkafka-client                   |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m ===> Configuring ...
[31;1mkafka1                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to zookeeper/172.19.0.2:2181, initiating session
[35mksql-server                    |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.client.ZooKeeperSaslClient - Client will use DIGEST-MD5 as SASL mechanism.
[35;1mschemaregistry                 |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	security.protocol = SASL_SSL
[33mzookeeper                      |[0m [2020-05-20 20:04:09,896] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[31;1mkafka1                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server zookeeper/172.19.0.2:2181, sessionid = 0x1000183079c0001, negotiated timeout = 40000
[36;1mconnect                        |[0m ===> Running preflight checks ... 
[35mksql-server                    |[0m 	ssl.truststore.type = JKS
[35;1mschemaregistry                 |[0m 	ssl.secure.random.implementation = null
[35;1mschemaregistry                 |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mschemaregistry                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[34mstreams-demo                   |[0m [main] INFO io.confluent.kafka.serializers.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[32;1mkafka-client                   |[0m 	send.buffer.bytes = 131072
[33mzookeeper                      |[0m [2020-05-20 20:04:09,896] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m ===> Check if Kafka is healthy ...
[31;1mkafka1                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Session: 0x1000183079c0001 closed
[35mksql-server                    |[0m 
[34;1mkafka2                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server zookeeper/172.19.0.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
[33;1mrestproxy                      |[0m 
[35;1mschemaregistry                 |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[32;1mkafka-client                   |[0m 	ssl.cipher.suites = null
[33mzookeeper                      |[0m [2020-05-20 20:04:09,897] INFO Established session 0x1000183079c0003 with negotiated timeout 6000 for client /172.19.0.5:50936 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[31;1mkafka1                         |[0m [main-EventThread] INFO org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1000183079c0001
[35mksql-server                    |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[34;1mkafka2                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to zookeeper/172.19.0.2:2181, initiating session
[33;1mrestproxy                      |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[35;1mschemaregistry                 |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[32;1mkafka-client                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33mzookeeper                      |[0m [2020-05-20 20:04:09,915] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m ===> Launching ... 
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.interceptor.classes' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [main-SendThread(zookeeper:2181)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server zookeeper/172.19.0.2:2181, sessionid = 0x1000183079c0000, negotiated timeout = 40000
[33;1mrestproxy                      |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[35;1mschemaregistry                 |[0m 
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[32;1mkafka-client                   |[0m 	ssl.endpoint.identification.algorithm = https
[33mzookeeper                      |[0m [2020-05-20 20:04:09,915] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[31;1mkafka1                         |[0m ===> Launching kafka ... 
[34;1mkafka2                         |[0m [main] INFO org.apache.zookeeper.ZooKeeper - Session: 0x1000183079c0000 closed
[33;1mrestproxy                      |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[35;1mschemaregistry                 |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[32;1mkafka-client                   |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	client.id = 
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'ksql.schema.registry.ssl.truststore.location' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:09,915] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:08,418] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[34;1mkafka2                         |[0m [main-EventThread] INFO org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1000183079c0000
[33;1mrestproxy                      |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005048707
[35;1mschemaregistry                 |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m 	ssl.keymanager.algorithm = SunX509
[33mzookeeper                      |[0m [2020-05-20 20:04:10,022] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x3 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,394] INFO KafkaConfig values: 
[34;1mkafka2                         |[0m ===> Launching ... 
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'ksql.schema.registry.url' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m 	advertised.host.name = null
[33mzookeeper                      |[0m [2020-05-20 20:04:10,035] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:create cxid:0x4 zxid:0x9 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m ===> Launching kafka ... 
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[35;1mschemaregistry                 |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005046729
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m 	advertised.listeners = SASL_SSL://kafka1:9091,SASL_SSL_HOST://localhost:29091,PLAINTEXT://kafka1:10091,SSL://kafka1:11091
[34;1mkafka2                         |[0m [2020-05-20 20:04:08,422] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[33mzookeeper                      |[0m [2020-05-20 20:04:10,044] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:create cxid:0x8 zxid:0xd txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	metric.reporters = []
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	specific.avro.reader = true
[32mcontrol-center                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m 	advertised.port = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,324] INFO KafkaConfig values: 
[33mzookeeper                      |[0m [2020-05-20 20:04:10,049] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:create cxid:0xb zxid:0x10 txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m ===> Launching ... 
[32;1mkafka-client                   |[0m 	ssl.protocol = TLS
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'host.name' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	alter.config.policy.class.name = null
[34;1mkafka2                         |[0m 	advertised.host.name = null
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[33mzookeeper                      |[0m [2020-05-20 20:04:10,099] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x4 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[32mcontrol-center                 |[0m ===> Launching control-center ... 
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'config.dir' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	alter.log.dirs.replication.quota.window.num = 11
[34;1mkafka2                         |[0m 	advertised.listeners = SASL_SSL://kafka2:9092,SASL_SSL_HOST://localhost:29092,PLAINTEXT://kafka2:10092,SSL://kafka2:11092
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	ssl.secure.random.implementation = null
[33mzookeeper                      |[0m [2020-05-20 20:04:10,101] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x5 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[32mcontrol-center                 |[0m SLF4J: Class path contains multiple SLF4J bindings.
[31;1mkafka1                         |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[34;1mkafka2                         |[0m 	advertised.port = null
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	ssl.trustmanager.algorithm = PKIX
[33mzookeeper                      |[0m [2020-05-20 20:04:10,103] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x6 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'listeners' was supplied but isn't a known config.
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
[32mcontrol-center                 |[0m SLF4J: Found binding in [jar:file:/usr/share/java/acl/acl-5.3.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[31;1mkafka1                         |[0m 	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
[34;1mkafka2                         |[0m 	alter.config.policy.class.name = null
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[33mzookeeper                      |[0m [2020-05-20 20:04:10,105] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x7 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'classpath' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 	application.id = wikipedia-activity-monitor
[32mcontrol-center                 |[0m SLF4J: Found binding in [jar:file:/usr/share/java/confluent-control-center/slf4j-log4j12-1.7.26.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[31;1mkafka1                         |[0m 	auto.create.topics.enable = false
[34;1mkafka2                         |[0m 	alter.log.dirs.replication.quota.window.num = 11
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	ssl.truststore.password = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:04:10,108] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x8 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'ksql.schema.registry.ssl.truststore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[34mstreams-demo                   |[0m 	application.server = 
[31;1mkafka1                         |[0m 	auto.leader.rebalance.enable = true
[34;1mkafka2                         |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 	ssl.truststore.type = JKS
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:04:10,111] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x9 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'ksql.schema.registry.ssl.keystore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m 	background.threads = 10
[36;1mconnect                        |[0m 	retries = 5
[34;1mkafka2                         |[0m 	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m 
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:10,112] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0xa zxid:0x21 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m [2020-05-20 20:04:23,143] WARN Invalid value 2 for configuration confluent.controlcenter.internal.topics.replication: Value must be at least 3 (io.confluent.controlcenter.ControlCenterConfig)
[34mstreams-demo                   |[0m 	buffered.records.per.partition = 1000
[31;1mkafka1                         |[0m 	broker.id = 1
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m 	auto.create.topics.enable = false
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'ksql.schema.registry.ssl.keystore.location' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:10,114] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0xb zxid:0x22 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m [2020-05-20 20:04:23,144] WARN Invalid value 2 for configuration confluent.controlcenter.internal.topics.replication: Value must be at least 3 (io.confluent.controlcenter.ControlCenterConfig)
[34mstreams-demo                   |[0m 	cache.max.bytes.buffering = 10485760
[31;1mkafka1                         |[0m 	broker.id.generation.enable = true
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m 	auto.leader.rebalance.enable = true
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:04:10,116] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0xc zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'log4j.opts' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'listeners' was supplied but isn't a known config.
[32mcontrol-center                 |[0m [2020-05-20 20:04:23,145] INFO ControlCenterConfig values: 
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor
[31;1mkafka1                         |[0m 	broker.rack = r1
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	background.threads = 10
[33mzookeeper                      |[0m [2020-05-20 20:04:10,118] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0xd zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	auth.bearer.roles.claim = 
[34mstreams-demo                   |[0m 	commit.interval.ms = 30000
[33;1mrestproxy                      |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	broker.id = 2
[31;1mkafka1                         |[0m 	client.quota.callback.class = null
[33mzookeeper                      |[0m [2020-05-20 20:04:10,120] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0xe zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.interceptor.classes' was supplied but isn't a known config.
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'broker.id' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	broker.id.generation.enable = true
[33;1mrestproxy                      |[0m ===> Launching ... 
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	compression.type = producer
[33mzookeeper                      |[0m [2020-05-20 20:04:10,121] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0xf zxid:0x26 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.alert.cluster.down.autocreate = false
[34mstreams-demo                   |[0m 	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'zookeeper.set.acl' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	broker.rack = r1
[33;1mrestproxy                      |[0m ===> Launching kafka-rest ... 
[31;1mkafka1                         |[0m 	connection.failed.authentication.delay.ms = 100
[33mzookeeper                      |[0m [2020-05-20 20:04:10,519] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:create cxid:0x17 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'ksql.server.ui.enabled' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	confluent.controlcenter.alert.cluster.down.send.rate = 12
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	client.quota.callback.class = null
[33;1mrestproxy                      |[0m [2020-05-20 20:04:23,716] INFO KafkaRestConfig values: 
[31;1mkafka1                         |[0m 	connections.max.idle.ms = 600000
[33mzookeeper                      |[0m [2020-05-20 20:04:10,532] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:create cxid:0x11 zxid:0x2a txntype:-1 reqpath:n/a Error Path:/cluster/id Error:KeeperErrorCode = NodeExists for /cluster/id (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m 	confluent.controlcenter.alert.cluster.down.to.email = 
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'log.dirs' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	compression.type = producer
[33;1mrestproxy                      |[0m 	access.control.allow.headers = 
[35mksql-server                    |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[33mzookeeper                      |[0m [2020-05-20 20:04:18,200] INFO Accepted socket connection from /172.19.0.5:51040 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[34mstreams-demo                   |[0m 	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
[31;1mkafka1                         |[0m 	connections.max.reauth.ms = 0
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.alert.cluster.down.to.pagerduty.integrationkey = 
[35;1mschemaregistry                 |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[34;1mkafka2                         |[0m 	connection.failed.authentication.delay.ms = 100
[33;1mrestproxy                      |[0m 	access.control.allow.methods = 
[35mksql-server                    |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[33mzookeeper                      |[0m [2020-05-20 20:04:18,201] INFO Client attempting to establish new session at /172.19.0.5:51040 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m 	default.value.serde = class io.confluent.kafka.streams.serdes.avro.GenericAvroSerde
[31;1mkafka1                         |[0m 	control.plane.listener.name = null
[36;1mconnect                        |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.alert.cluster.down.to.webhookurl.slack = 
[35;1mschemaregistry                 |[0m ===> Launching ... 
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[34;1mkafka2                         |[0m 	connections.max.idle.ms = 600000
[33;1mrestproxy                      |[0m 	access.control.allow.origin = 
[35mksql-server                    |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005042471
[33mzookeeper                      |[0m [2020-05-20 20:04:18,203] INFO Established session 0x1000183079c0004 with negotiated timeout 6000 for client /172.19.0.5:51040 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m 	max.task.idle.ms = 0
[31;1mkafka1                         |[0m 	controlled.shutdown.enable = true
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[35;1mschemaregistry                 |[0m ===> Launching schema-registry ... 
[32;1mkafka-client                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005065335
[32mcontrol-center                 |[0m 	confluent.controlcenter.alert.max.trigger.events = 1000
[34;1mkafka2                         |[0m 	connections.max.reauth.ms = 0
[33;1mrestproxy                      |[0m 	authentication.method = NONE
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:04:18,206] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m 	controlled.shutdown.max.retries = 3
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:23,722] INFO SchemaRegistryConfig values: 
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[32;1mkafka-client                   |[0m Created topic users.
[34;1mkafka2                         |[0m 	control.plane.listener.name = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.auth.bearer.issuer = Confluent
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m 	authentication.realm = 
[33mzookeeper                      |[0m [2020-05-20 20:04:18,206] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[31;1mkafka1                         |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[34mstreams-demo                   |[0m 	metric.reporters = []
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[35;1mschemaregistry                 |[0m 	access.control.allow.headers = 
[32;1mkafka-client                   |[0m WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
[34;1mkafka2                         |[0m 	controlled.shutdown.enable = true
[33;1mrestproxy                      |[0m 	authentication.roles = [*]
[32mcontrol-center                 |[0m 	confluent.controlcenter.auth.bearer.public.key.path = 
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33mzookeeper                      |[0m [2020-05-20 20:04:18,207] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m 	controller.socket.timeout.ms = 30000
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[35;1mschemaregistry                 |[0m 	access.control.allow.methods = 
[32;1mkafka-client                   |[0m Created topic wikipedia.parsed.
[34;1mkafka2                         |[0m 	controlled.shutdown.max.retries = 3
[33;1mrestproxy                      |[0m 	authentication.skip.paths = []
[32mcontrol-center                 |[0m 	confluent.controlcenter.auth.restricted.roles = []
[33mzookeeper                      |[0m [2020-05-20 20:04:18,300] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0004 type:create cxid:0x9 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended Error:KeeperErrorCode = NoNode for /kafka-acl-extended (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	create.topic.policy.class.name = null
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[32;1mkafka-client                   |[0m WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
[33;1mrestproxy                      |[0m 	bootstrap.servers = SASL_SSL://kafka1:9091,SASL_SSL://kafka2:9092
[34;1mkafka2                         |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mcontrol-center                 |[0m 	confluent.controlcenter.auth.session.expiration.ms = 0
[33mzookeeper                      |[0m [2020-05-20 20:04:18,506] INFO Accepted socket connection from /172.19.0.4:50286 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	default.replication.factor = 1
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[35;1mschemaregistry                 |[0m 	access.control.allow.origin = 
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[32;1mkafka-client                   |[0m Created topic wikipedia.parsed.count-by-channel.
[33;1mrestproxy                      |[0m 	client.init.timeout.ms = 60000
[32mcontrol-center                 |[0m 	confluent.controlcenter.broker.config.edit.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:18,507] INFO Client attempting to establish new session at /172.19.0.4:50286 (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m 	controller.socket.timeout.ms = 30000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	num.standby.replicas = 0
[31;1mkafka1                         |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[35;1mschemaregistry                 |[0m 	authentication.method = NONE
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[33;1mrestproxy                      |[0m 	client.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32;1mkafka-client                   |[0m WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
[32mcontrol-center                 |[0m 	confluent.controlcenter.command.streams.start.timeout = 300000
[33mzookeeper                      |[0m [2020-05-20 20:04:18,509] INFO Established session 0x1000183079c0005 with negotiated timeout 6000 for client /172.19.0.4:50286 (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m 	create.topic.policy.class.name = null
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	num.stream.threads = 1
[31;1mkafka1                         |[0m 	delegation.token.expiry.time.ms = 86400000
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[35;1mschemaregistry                 |[0m 	authentication.realm = 
[33;1mrestproxy                      |[0m 	client.sasl.kerberos.min.time.before.relogin = 60000
[32;1mkafka-client                   |[0m Created topic wikipedia.failed.
[32mcontrol-center                 |[0m 	confluent.controlcenter.command.topic = _confluent-command
[33mzookeeper                      |[0m [2020-05-20 20:04:18,511] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[34;1mkafka2                         |[0m 	default.replication.factor = 1
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	delegation.token.master.key = null
[34mstreams-demo                   |[0m 	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35;1mschemaregistry                 |[0m 	authentication.roles = [*]
[33;1mrestproxy                      |[0m 	client.sasl.kerberos.service.name = 
[32;1mkafka-client                   |[0m Created topic WIKIPEDIABOT.
[32mcontrol-center                 |[0m 	confluent.controlcenter.command.topic.replication = 2
[33mzookeeper                      |[0m [2020-05-20 20:04:18,511] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[34;1mkafka2                         |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[31;1mkafka1                         |[0m 	delegation.token.max.lifetime.ms = 604800000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	poll.ms = 100
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[35;1mschemaregistry                 |[0m 	authentication.skip.paths = []
[33;1mrestproxy                      |[0m 	client.sasl.kerberos.ticket.renew.jitter = 0.05
[32;1mkafka-client                   |[0m Created topic WIKIPEDIANOBOT.
[32mcontrol-center                 |[0m 	confluent.controlcenter.command.topic.retention.ms = 259200000
[34;1mkafka2                         |[0m 	delegation.token.expiry.time.ms = 86400000
[31;1mkafka1                         |[0m 	delete.records.purgatory.purge.interval.requests = 1
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	processing.guarantee = at_least_once
[36;1mconnect                        |[0m 	ssl.key.password = null
[35;1mschemaregistry                 |[0m 	avro.compatibility.level = backward
[32;1mkafka-client                   |[0m WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
[33;1mrestproxy                      |[0m 	client.sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m 	confluent.controlcenter.connect.cluster = [https://connect:8083]
[33mzookeeper                      |[0m [2020-05-20 20:04:18,511] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[34;1mkafka2                         |[0m 	delegation.token.master.key = null
[31;1mkafka1                         |[0m 	delete.topic.enable = true
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 32768
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[35;1mschemaregistry                 |[0m 	compression.enable = true
[32;1mkafka-client                   |[0m Created topic EN_WIKIPEDIA_GT_1.
[33;1mrestproxy                      |[0m 	client.sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m 	confluent.controlcenter.consumers.view.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:18,512] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x3 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/kafka-acl Error:KeeperErrorCode = NodeExists for /kafka-acl (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	delegation.token.max.lifetime.ms = 604800000
[31;1mkafka1                         |[0m 	fetch.purgatory.purge.interval.requests = 1000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[35;1mschemaregistry                 |[0m 	debug = false
[32;1mkafka-client                   |[0m WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.
[33;1mrestproxy                      |[0m 	client.security.protocol = SASL_SSL
[32mcontrol-center                 |[0m 	confluent.controlcenter.data.dir = /var/lib/confluent-control-center
[33mzookeeper                      |[0m [2020-05-20 20:04:18,522] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x4 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/kafka-acl/Topic Error:KeeperErrorCode = NodeExists for /kafka-acl/Topic (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	delete.records.purgatory.purge.interval.requests = 1
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m 	group.initial.rebalance.delay.ms = 3000
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[35;1mschemaregistry                 |[0m 	host.name = schemaregistry
[33;1mrestproxy                      |[0m 	client.ssl.cipher.suites = 
[32;1mkafka-client                   |[0m Created topic EN_WIKIPEDIA_GT_1_COUNTS.
[32mcontrol-center                 |[0m 	confluent.controlcenter.deprecated.views.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:18,524] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x5 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/kafka-acl/Group Error:KeeperErrorCode = NodeExists for /kafka-acl/Group (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	delete.topic.enable = true
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	replication.factor = 1
[31;1mkafka1                         |[0m 	group.max.session.timeout.ms = 1800000
[35;1mschemaregistry                 |[0m 	idle.timeout.ms = 30000
[33;1mrestproxy                      |[0m 	client.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[32mcontrol-center                 |[0m 	confluent.controlcenter.disk.skew.warning.min.bytes = 1073741824
[33mzookeeper                      |[0m [2020-05-20 20:04:18,609] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x6 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/kafka-acl/Cluster Error:KeeperErrorCode = NodeExists for /kafka-acl/Cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	fetch.purgatory.purge.interval.requests = 1000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m 	group.max.size = 2147483647
[34mstreams-demo                   |[0m 	request.timeout.ms = 40000
[35;1mschemaregistry                 |[0m 	inter.instance.headers.whitelist = []
[33;1mrestproxy                      |[0m 	client.ssl.endpoint.identification.algorithm = 
[32mcontrol-center                 |[0m 	confluent.controlcenter.id = 1
[33mzookeeper                      |[0m [2020-05-20 20:04:18,613] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x7 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/kafka-acl/TransactionalId Error:KeeperErrorCode = NodeExists for /kafka-acl/TransactionalId (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	group.initial.rebalance.delay.ms = 3000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	group.min.session.timeout.ms = 6000
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34mstreams-demo                   |[0m 	retries = 0
[33;1mrestproxy                      |[0m 	client.ssl.key.password = [hidden]
[35;1mschemaregistry                 |[0m 	inter.instance.protocol = http
[32mcontrol-center                 |[0m 	confluent.controlcenter.internal.streams.start.timeout = 21600000
[34;1mkafka2                         |[0m 	group.max.session.timeout.ms = 1800000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	host.name = 
[36;1mconnect                        |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[33mzookeeper                      |[0m [2020-05-20 20:04:18,634] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x8 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/kafka-acl/DelegationToken Error:KeeperErrorCode = NodeExists for /kafka-acl/DelegationToken (org.apache.zookeeper.server.PrepRequestProcessor)
[32mcontrol-center                 |[0m 	confluent.controlcenter.internal.topics.changelog.segment.bytes = 134217728
[35;1mschemaregistry                 |[0m 	kafkastore.bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	group.max.size = 2147483647
[33;1mrestproxy                      |[0m 	client.ssl.keymanager.algorithm = SunX509
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	inter.broker.listener.name = SASL_SSL
[34mstreams-demo                   |[0m 	rocksdb.config.setter = null
[33mzookeeper                      |[0m [2020-05-20 20:04:18,636] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x9 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended/prefixed Error:KeeperErrorCode = NodeExists for /kafka-acl-extended/prefixed (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.internal.topics.partitions = 1
[35;1mschemaregistry                 |[0m 	kafkastore.connection.url = 
[34;1mkafka2                         |[0m 	group.min.session.timeout.ms = 6000
[31;1mkafka1                         |[0m 	inter.broker.protocol.version = 2.3-IV1
[33;1mrestproxy                      |[0m 	client.ssl.keystore.location = /etc/kafka/secrets/kafka.restproxy.keystore.jks
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[33mzookeeper                      |[0m [2020-05-20 20:04:18,638] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0xa zxid:0x4a txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended/prefixed/Topic Error:KeeperErrorCode = NodeExists for /kafka-acl-extended/prefixed/Topic (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	host.name = 
[35;1mschemaregistry                 |[0m 	kafkastore.group.id = 
[32mcontrol-center                 |[0m 	confluent.controlcenter.internal.topics.replication = 2
[31;1mkafka1                         |[0m 	kafka.metrics.polling.interval.secs = 10
[33;1mrestproxy                      |[0m 	client.ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[33mzookeeper                      |[0m [2020-05-20 20:04:18,640] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0xb zxid:0x4b txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended/prefixed/Group Error:KeeperErrorCode = NodeExists for /kafka-acl-extended/prefixed/Group (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	inter.broker.listener.name = SASL_SSL
[35;1mschemaregistry                 |[0m 	kafkastore.init.timeout.ms = 60000
[32mcontrol-center                 |[0m 	confluent.controlcenter.internal.topics.retention.bytes = -1
[31;1mkafka1                         |[0m 	kafka.metrics.reporters = []
[34mstreams-demo                   |[0m 	state.cleanup.delay.ms = 600000
[33;1mrestproxy                      |[0m 	client.ssl.keystore.type = JKS
[33mzookeeper                      |[0m [2020-05-20 20:04:18,641] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0xc zxid:0x4c txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended/prefixed/Cluster Error:KeeperErrorCode = NodeExists for /kafka-acl-extended/prefixed/Cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m 	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m 	inter.broker.protocol.version = 2.3-IV1
[32mcontrol-center                 |[0m 	confluent.controlcenter.internal.topics.retention.ms = 604800000
[31;1mkafka1                         |[0m 	leader.imbalance.check.interval.seconds = 300
[34mstreams-demo                   |[0m 	state.dir = /tmp/confluent5884559065339683570
[33;1mrestproxy                      |[0m 	client.ssl.protocol = TLS
[33mzookeeper                      |[0m [2020-05-20 20:04:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0xd zxid:0x4d txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended/prefixed/TransactionalId Error:KeeperErrorCode = NodeExists for /kafka-acl-extended/prefixed/TransactionalId (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[35;1mschemaregistry                 |[0m 	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	kafka.metrics.polling.interval.secs = 10
[32mcontrol-center                 |[0m 	confluent.controlcenter.ksql.advertised.url = [http://localhost:8088]
[31;1mkafka1                         |[0m 	leader.imbalance.per.broker.percentage = 10
[34mstreams-demo                   |[0m 	topology.optimization = none
[33;1mrestproxy                      |[0m 	client.ssl.provider = 
[33mzookeeper                      |[0m [2020-05-20 20:04:18,645] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0xe zxid:0x4e txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended/prefixed/DelegationToken Error:KeeperErrorCode = NodeExists for /kafka-acl-extended/prefixed/DelegationToken (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 
[35;1mschemaregistry                 |[0m 	kafkastore.sasl.kerberos.service.name = 
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	kafka.metrics.reporters = []
[32mcontrol-center                 |[0m 	confluent.controlcenter.ksql.enable = true
[31;1mkafka1                         |[0m 	listener.security.protocol.map = SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[34mstreams-demo                   |[0m 	upgrade.from = null
[33mzookeeper                      |[0m [2020-05-20 20:04:18,647] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0xf zxid:0x4f txntype:-1 reqpath:n/a Error Path:/kafka-acl-changes Error:KeeperErrorCode = NodeExists for /kafka-acl-changes (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	client.ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[35;1mschemaregistry                 |[0m 	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	confluent.controlcenter.ksql.url = [http://ksql-server:8088]
[31;1mkafka1                         |[0m 	listeners = SASL_SSL://0.0.0.0:9091,SASL_SSL_HOST://0.0.0.0:29091,PLAINTEXT://0.0.0.0:10091,SSL://0.0.0.0:11091
[34;1mkafka2                         |[0m 	leader.imbalance.check.interval.seconds = 300
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34mstreams-demo                   |[0m 	windowstore.changelog.additional.retention.ms = 86400000
[33mzookeeper                      |[0m [2020-05-20 20:04:18,649] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0005 type:create cxid:0x10 zxid:0x50 txntype:-1 reqpath:n/a Error Path:/kafka-acl-extended-changes Error:KeeperErrorCode = NodeExists for /kafka-acl-extended-changes (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	client.ssl.truststore.location = /etc/kafka/secrets/kafka.restproxy.truststore.jks
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'log4j.loggers' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m 	log.cleaner.backoff.ms = 15000
[35mksql-server                    |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	confluent.controlcenter.license.manager = _confluent-controlcenter-license-manager-5-3-1
[34;1mkafka2                         |[0m 	leader.imbalance.per.broker.percentage = 10
[34mstreams-demo                   |[0m 
[33mzookeeper                      |[0m [2020-05-20 20:04:19,539] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:multi cxid:0x36 zxid:0x51 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	client.ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[35;1mschemaregistry                 |[0m 	kafkastore.sasl.mechanism = PLAIN
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config.
[35mksql-server                    |[0m ===> Launching ... 
[32mcontrol-center                 |[0m 	confluent.controlcenter.license.manager.enable = true
[34;1mkafka2                         |[0m 	listener.security.protocol.map = SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[33mzookeeper                      |[0m [2020-05-20 20:04:20,638] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0003 type:setData cxid:0x2e zxid:0x52 txntype:-1 reqpath:n/a Error Path:/config/topics/__confluent.support.metrics Error:KeeperErrorCode = NoNode for /config/topics/__confluent.support.metrics (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	client.ssl.truststore.type = JKS
[31;1mkafka1                         |[0m 	log.cleaner.delete.retention.ms = 86400000
[35;1mschemaregistry                 |[0m 	kafkastore.security.protocol = SASL_SSL
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[35mksql-server                    |[0m ===> Launching ksql-server ... 
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.bounce.address = 
[34;1mkafka2                         |[0m 	listeners = SASL_SSL://0.0.0.0:9092,SASL_SSL_HOST://0.0.0.0:29092,PLAINTEXT://0.0.0.0:10092,SSL://0.0.0.0:11092
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[33mzookeeper                      |[0m [2020-05-20 20:04:21,323] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x4b zxid:0x58 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.enable = true
[33;1mrestproxy                      |[0m 	client.timeout.ms = 500
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.cipher.suites = 
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config.
[35mksql-server                    |[0m SLF4J: A number (104) of logging calls during the initialization phase have been intercepted and are
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.enabled = false
[34;1mkafka2                         |[0m 	log.cleaner.backoff.ms = 15000
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[33mzookeeper                      |[0m [2020-05-20 20:04:29,919] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0xef zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
[33;1mrestproxy                      |[0m 	client.zk.session.timeout.ms = 30000
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'status.storage.replication.factor' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.from = c3@confluent.io
[35mksql-server                    |[0m SLF4J: now being replayed. These are subject to the filtering rules of the underlying logging system.
[34;1mkafka2                         |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-admin
[33mzookeeper                      |[0m [2020-05-20 20:04:31,960] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0xfa zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.io.buffer.size = 524288
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.endpoint.identification.algorithm = HTTPS
[33;1mrestproxy                      |[0m 	compression.enable = true
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.ssl.key.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.host.name = localhost
[35mksql-server                    |[0m SLF4J: See also http://www.slf4j.org/codes.html#replay
[34;1mkafka2                         |[0m 	log.cleaner.delete.retention.ms = 86400000
[33mzookeeper                      |[0m [2020-05-20 20:04:32,015] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x105 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 300000
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.key.password = [hidden]
[33;1mrestproxy                      |[0m 	consumer.instance.timeout.ms = 300000
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.security.protocol' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.password = 
[35mksql-server                    |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m 	log.cleaner.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:32,137] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x110 zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.keymanager.algorithm = SunX509
[33;1mrestproxy                      |[0m 	consumer.iterator.backoff.ms = 50
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'offset.storage.topic' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.port = 587
[34;1mkafka2                         |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35mksql-server                    |[0m WARNING: A provider io.confluent.ksql.rest.server.resources.KsqlResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.ksql.rest.server.resources.KsqlResource will be ignored. 
[33mzookeeper                      |[0m [2020-05-20 20:04:32,221] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x11b zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.keystore.location = /etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[33;1mrestproxy                      |[0m 	consumer.iterator.timeout.ms = 1
[34mstreams-demo                   |[0m 	metric.reporters = []
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.ssl.checkserveridentity = false
[34;1mkafka2                         |[0m 	log.cleaner.io.buffer.size = 524288
[35mksql-server                    |[0m May 20, 2020 8:04:44 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[33mzookeeper                      |[0m [2020-05-20 20:04:32,350] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x126 zxid:0xde txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-cluster-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-cluster-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.min.compaction.lag.ms = 0
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.keystore.password = [hidden]
[33;1mrestproxy                      |[0m 	consumer.request.max.bytes = 67108864
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'key.converter' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.starttls.required = false
[34;1mkafka2                         |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[35mksql-server                    |[0m WARNING: A provider io.confluent.ksql.rest.server.resources.streaming.StreamedQueryResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.ksql.rest.server.resources.streaming.StreamedQueryResource will be ignored. 
[33mzookeeper                      |[0m [2020-05-20 20:04:32,455] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x131 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.cleaner.threads = 1
[33;1mrestproxy                      |[0m 	consumer.request.timeout.ms = 1000
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.keystore.type = JKS
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.mail.username = 
[34;1mkafka2                         |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[33mzookeeper                      |[0m [2020-05-20 20:04:32,558] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x13c zxid:0xea txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35mksql-server                    |[0m May 20, 2020 8:04:44 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[33;1mrestproxy                      |[0m 	consumer.threads = 50
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.protocol = TLS
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m 	log.cleanup.policy = [delete]
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.metadata.password = [hidden]
[34;1mkafka2                         |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[33mzookeeper                      |[0m [2020-05-20 20:04:32,737] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x147 zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	debug = false
[35mksql-server                    |[0m WARNING: A provider io.confluent.ksql.rest.server.resources.RootDocument registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.ksql.rest.server.resources.RootDocument will be ignored. 
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.provider = 
[31;1mkafka1                         |[0m 	log.dir = /tmp/kafka-logs
[32mcontrol-center                 |[0m 	confluent.controlcenter.metadata.urls = []
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'config.storage.topic' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:32,838] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x152 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	fetch.min.bytes = -1
[35mksql-server                    |[0m May 20, 2020 8:04:44 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	log.dirs = /var/lib/kafka/data
[34;1mkafka2                         |[0m 	log.cleaner.threads = 1
[32mcontrol-center                 |[0m 	confluent.controlcenter.metadata.username = 
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[33mzookeeper                      |[0m [2020-05-20 20:04:32,935] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x15d zxid:0xfc txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m 	host.name = restproxy
[35mksql-server                    |[0m WARNING: A provider io.confluent.ksql.rest.server.resources.ServerInfoResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.ksql.rest.server.resources.ServerInfoResource will be ignored. 
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.truststore.location = /etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[31;1mkafka1                         |[0m 	log.flush.interval.messages = 9223372036854775807
[34;1mkafka2                         |[0m 	log.cleanup.policy = [delete]
[32mcontrol-center                 |[0m 	confluent.controlcenter.name = _confluent-controlcenter-5-3-1
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[33mzookeeper                      |[0m [2020-05-20 20:04:33,049] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x168 zxid:0x102 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'rest.advertised.host.name' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m 	id = 
[35mksql-server                    |[0m May 20, 2020 8:04:44 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	log.flush.interval.ms = null
[34;1mkafka2                         |[0m 	log.dir = /tmp/kafka-logs
[32mcontrol-center                 |[0m 	confluent.controlcenter.rest.advertised.url = 
[33mzookeeper                      |[0m [2020-05-20 20:04:33,205] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x173 zxid:0x108 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-metrics Error:KeeperErrorCode = NoNode for /config/topics/_confluent-metrics (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	request.timeout.ms = 120000
[33;1mrestproxy                      |[0m 	idle.timeout.ms = 30000
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	kafkastore.ssl.truststore.type = JKS
[35mksql-server                    |[0m WARNING: A provider io.confluent.ksql.rest.server.resources.StatusResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.ksql.rest.server.resources.StatusResource will be ignored. 
[31;1mkafka1                         |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[34;1mkafka2                         |[0m 	log.dirs = /var/lib/kafka/data
[32mcontrol-center                 |[0m 	confluent.controlcenter.rest.compression.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:33,333] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x17e zxid:0x10e txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	retries = 5
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'config.storage.replication.factor' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m 	kafka.rest.resource.extension.class = []
[35;1mschemaregistry                 |[0m 	kafkastore.timeout.ms = 500
[31;1mkafka1                         |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[34;1mkafka2                         |[0m 	log.flush.interval.messages = 9223372036854775807
[32mcontrol-center                 |[0m 	confluent.controlcenter.rest.hsts.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:33,425] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x189 zxid:0x114 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	kafkastore.topic = _schemas
[33;1mrestproxy                      |[0m 	listeners = [https://0.0.0.0:8086]
[34;1mkafka2                         |[0m 	log.flush.interval.ms = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.rest.port = 9021
[31;1mkafka1                         |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[33mzookeeper                      |[0m [2020-05-20 20:04:33,526] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x194 zxid:0x11a txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'rest.port' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	kafkastore.topic.replication.factor = 3
[34;1mkafka2                         |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[33;1mrestproxy                      |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	confluent.controlcenter.schema.registry.enable = true
[31;1mkafka1                         |[0m 	log.index.interval.bytes = 4096
[33mzookeeper                      |[0m [2020-05-20 20:04:33,561] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x19f zxid:0x120 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	kafkastore.zk.session.timeout.ms = 30000
[34;1mkafka2                         |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[33;1mrestproxy                      |[0m 	metrics.jmx.prefix = kafka.rest
[32mcontrol-center                 |[0m 	confluent.controlcenter.schema.registry.url = [https://schemaregistry:8085]
[31;1mkafka1                         |[0m 	log.index.size.max.bytes = 10485760
[33mzookeeper                      |[0m [2020-05-20 20:04:33,712] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1aa zxid:0x126 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	listeners = [https://0.0.0.0:8085]
[34;1mkafka2                         |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[33;1mrestproxy                      |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.cache.max.bytes.buffering = 100000000
[31;1mkafka1                         |[0m 	log.message.downconversion.enable = true
[33mzookeeper                      |[0m [2020-05-20 20:04:33,763] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1b5 zxid:0x12c txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.ssl.key.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	master.eligibility = true
[34;1mkafka2                         |[0m 	log.index.interval.bytes = 4096
[33;1mrestproxy                      |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.consumer.session.timeout.ms = 60000
[33mzookeeper                      |[0m [2020-05-20 20:04:33,860] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1c0 zxid:0x132 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m 	log.message.format.version = 2.3-IV1
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	log.index.size.max.bytes = 10485760
[33;1mrestproxy                      |[0m 	metrics.tag.map = []
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.num.stream.threads = 1
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mzookeeper                      |[0m [2020-05-20 20:04:33,958] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1cb zxid:0x138 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'internal.value.converter' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	metrics.jmx.prefix = kafka.schema.registry
[34;1mkafka2                         |[0m 	log.message.downconversion.enable = true
[33;1mrestproxy                      |[0m 	port = 8082
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.producer.compression.type = lz4
[33mzookeeper                      |[0m [2020-05-20 20:04:34,047] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1d6 zxid:0x13e txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	log.message.timestamp.type = CreateTime
[34;1mkafka2                         |[0m 	log.message.format.version = 2.3-IV1
[35;1mschemaregistry                 |[0m 	metrics.num.samples = 2
[33;1mrestproxy                      |[0m 	producer.threads = 5
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.producer.delivery.timeout.ms = 2147483647
[33mzookeeper                      |[0m [2020-05-20 20:04:34,206] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1e1 zxid:0x144 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-command Error:KeeperErrorCode = NoNode for /config/topics/_confluent-command (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.preallocate = false
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[35;1mschemaregistry                 |[0m 	metrics.sample.window.ms = 30000
[33;1mrestproxy                      |[0m 	request.logger.name = io.confluent.rest-utils.requests
[34mstreams-demo                   |[0m 	sasl.login.class = null
[33mzookeeper                      |[0m [2020-05-20 20:04:34,250] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1ec zxid:0x14a txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[31;1mkafka1                         |[0m 	log.retention.bytes = -1
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.producer.linger.ms = 500
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'replication.factor' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	log.message.timestamp.type = CreateTime
[35;1mschemaregistry                 |[0m 	metrics.tag.map = []
[33;1mrestproxy                      |[0m 	resource.extension.classes = []
[33mzookeeper                      |[0m [2020-05-20 20:04:34,408] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x1f7 zxid:0x150 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	log.retention.check.interval.ms = 300000
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.producer.max.block.ms = 9223372036854775807
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	mode.mutability = false
[34;1mkafka2                         |[0m 	log.preallocate = false
[33mzookeeper                      |[0m [2020-05-20 20:04:34,509] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x202 zxid:0x156 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	response.mediatype.default = application/vnd.kafka.v1+json
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m 	log.retention.hours = 168
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.producer.retries = 2147483647
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.interceptor.classes' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	port = 8081
[33mzookeeper                      |[0m [2020-05-20 20:04:34,560] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x20d zxid:0x15c txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	response.mediatype.preferred = [application/vnd.kafka.v1+json, application/vnd.kafka+json, application/json]
[34;1mkafka2                         |[0m 	log.retention.bytes = -1
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	log.retention.minutes = null
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.producer.retry.backoff.ms = 100
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'group.id' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:34,658] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x218 zxid:0x162 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-monitoring Error:KeeperErrorCode = NoNode for /config/topics/_confluent-monitoring (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	request.logger.name = io.confluent.rest-utils.requests
[33;1mrestproxy                      |[0m 	rest.servlet.initializor.classes = []
[34;1mkafka2                         |[0m 	log.retention.check.interval.ms = 300000
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m 	log.retention.ms = null
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'plugin.path' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.streams.retries = 2147483647
[33mzookeeper                      |[0m [2020-05-20 20:04:34,757] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x223 zxid:0x168 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	resource.extension.class = []
[34;1mkafka2                         |[0m 	log.retention.hours = 168
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[33;1mrestproxy                      |[0m 	schema.registry.url = https://schemaregistry:8085
[31;1mkafka1                         |[0m 	log.roll.hours = 168
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.controlcenter.topic.inspection.enable = true
[35;1mschemaregistry                 |[0m 	resource.extension.classes = []
[33mzookeeper                      |[0m [2020-05-20 20:04:34,896] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x22e zxid:0x16e txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[33;1mrestproxy                      |[0m 	shutdown.graceful.ms = 1000
[34;1mkafka2                         |[0m 	log.retention.minutes = null
[31;1mkafka1                         |[0m 	log.roll.jitter.hours = 0
[32mcontrol-center                 |[0m 	confluent.controlcenter.webhook.enabled = true
[35;1mschemaregistry                 |[0m 	resource.static.locations = []
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[33mzookeeper                      |[0m [2020-05-20 20:04:35,004] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x239 zxid:0x174 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	log.retention.ms = null
[33;1mrestproxy                      |[0m 	simpleconsumer.pool.size.max = 25
[31;1mkafka1                         |[0m 	log.roll.jitter.ms = null
[32mcontrol-center                 |[0m 	confluent.license = 
[35;1mschemaregistry                 |[0m 	response.mediatype.default = application/vnd.schemaregistry.v1+json
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:35,125] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x244 zxid:0x17a txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	log.roll.hours = 168
[33;1mrestproxy                      |[0m 	simpleconsumer.pool.timeout.ms = 1000
[32mcontrol-center                 |[0m 	confluent.metrics.topic = _confluent-metrics
[35;1mschemaregistry                 |[0m 	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
[31;1mkafka1                         |[0m 	log.roll.ms = null
[33mzookeeper                      |[0m [2020-05-20 20:04:36,521] INFO Accepted socket connection from /172.19.0.7:42734 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.client.id' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m 	log.roll.jitter.hours = 0
[33;1mrestproxy                      |[0m 	ssl.cipher.suites = []
[32mcontrol-center                 |[0m 	confluent.metrics.topic.config.validate = false
[35;1mschemaregistry                 |[0m 	rest.servlet.initializor.classes = []
[31;1mkafka1                         |[0m 	log.segment.bytes = 1073741824
[33mzookeeper                      |[0m [2020-05-20 20:04:36,523] INFO Client attempting to establish new session at /172.19.0.7:42734 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m 	ssl.client.auth = false
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m 	log.roll.jitter.ms = null
[31;1mkafka1                         |[0m 	log.segment.delete.delay.ms = 60000
[32mcontrol-center                 |[0m 	confluent.metrics.topic.max.message.bytes = 10485760
[35;1mschemaregistry                 |[0m 	schema.registry.group.id = schema-registry
[33mzookeeper                      |[0m [2020-05-20 20:04:36,525] INFO Established session 0x1000183079c0006 with negotiated timeout 30000 for client /172.19.0.7:42734 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[33;1mrestproxy                      |[0m 	ssl.client.authentication = NONE
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m 	log.roll.ms = null
[31;1mkafka1                         |[0m 	max.connections = 2147483647
[32mcontrol-center                 |[0m 	confluent.metrics.topic.partitions = 1
[35;1mschemaregistry                 |[0m 	schema.registry.inter.instance.protocol = https
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'value.converter' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:36,613] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[33;1mrestproxy                      |[0m 	ssl.enabled.protocols = []
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	log.segment.bytes = 1073741824
[31;1mkafka1                         |[0m 	max.connections.per.ip = 2147483647
[32mcontrol-center                 |[0m 	confluent.metrics.topic.replication = 2
[35;1mschemaregistry                 |[0m 	schema.registry.resource.extension.class = []
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:36,613] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[33;1mrestproxy                      |[0m 	ssl.endpoint.identification.algorithm = null
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m 	log.segment.delete.delay.ms = 60000
[31;1mkafka1                         |[0m 	max.connections.per.ip.overrides = 
[32mcontrol-center                 |[0m 	confluent.metrics.topic.retention.bytes = -1
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	schema.registry.zk.namespace = schema_registry
[33mzookeeper                      |[0m [2020-05-20 20:04:36,614] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mrestproxy                      |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m 	max.connections = 2147483647
[31;1mkafka1                         |[0m 	max.incremental.fetch.session.cache.slots = 1000
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	confluent.metrics.topic.retention.ms = 259200000
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[35;1mschemaregistry                 |[0m 	shutdown.graceful.ms = 1000
[33mzookeeper                      |[0m [2020-05-20 20:04:38,003] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0006 type:setData cxid:0x7 zxid:0x181 txntype:-1 reqpath:n/a Error Path:/config/topics/users Error:KeeperErrorCode = NoNode for /config/topics/users (org.apache.zookeeper.server.PrepRequestProcessor)
[33;1mrestproxy                      |[0m 	ssl.keymanager.algorithm = 
[34;1mkafka2                         |[0m 	max.connections.per.ip = 2147483647
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.security.protocol' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	message.max.bytes = 1000012
[32mcontrol-center                 |[0m 	confluent.metrics.topic.skip.backlog.minutes = 15
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[33mzookeeper                      |[0m [2020-05-20 20:04:38,197] INFO Processed session termination for sessionid: 0x1000183079c0006 (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	ssl.cipher.suites = []
[33;1mrestproxy                      |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.restproxy.keystore.jks
[34;1mkafka2                         |[0m 	max.connections.per.ip.overrides = 
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[33mzookeeper                      |[0m [2020-05-20 20:04:38,199] INFO Closed socket connection for client /172.19.0.7:42734 which had sessionid 0x1000183079c0006 (org.apache.zookeeper.server.NIOServerCnxn)
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m 	ssl.client.auth = true
[34;1mkafka2                         |[0m 	max.incremental.fetch.session.cache.slots = 1000
[33;1mrestproxy                      |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'listeners' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:42,610] INFO Accepted socket connection from /172.19.0.7:42780 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic.config.validate = false
[34mstreams-demo                   |[0m 	ssl.provider = null
[35;1mschemaregistry                 |[0m 	ssl.client.authentication = NONE
[34;1mkafka2                         |[0m 	message.max.bytes = 1000012
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'status.storage.topic' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	metrics.recording.level = INFO
[33;1mrestproxy                      |[0m 	ssl.keystore.type = JKS
[33mzookeeper                      |[0m [2020-05-20 20:04:42,614] INFO Client attempting to establish new session at /172.19.0.7:42780 (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic.partitions = 1
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[35;1mschemaregistry                 |[0m 	ssl.enabled.protocols = []
[34;1mkafka2                         |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	metrics.sample.window.ms = 30000
[33;1mrestproxy                      |[0m 	ssl.protocol = TLS
[33mzookeeper                      |[0m [2020-05-20 20:04:42,616] INFO Established session 0x1000183079c0007 with negotiated timeout 30000 for client /172.19.0.7:42780 (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic.replication = 2
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mschemaregistry                 |[0m 	ssl.endpoint.identification.algorithm = null
[34;1mkafka2                         |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m 	min.insync.replicas = 1
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.sasl.mechanism' was supplied but isn't a known config.
[33mzookeeper                      |[0m [2020-05-20 20:04:42,703] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[33;1mrestproxy                      |[0m 	ssl.provider = 
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic.retention.bytes = -1
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[35;1mschemaregistry                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	num.io.threads = 8
[34;1mkafka2                         |[0m 	metrics.recording.level = INFO
[33mzookeeper                      |[0m [2020-05-20 20:04:42,704] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic.retention.ms = 259200000
[33;1mrestproxy                      |[0m 	ssl.trustmanager.algorithm = 
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[35;1mschemaregistry                 |[0m 	ssl.keymanager.algorithm = 
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'internal.key.converter' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	metrics.sample.window.ms = 30000
[33mzookeeper                      |[0m [2020-05-20 20:04:42,705] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	confluent.monitoring.interceptor.topic.skip.backlog.minutes = 15
[33;1mrestproxy                      |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.restproxy.truststore.jks
[31;1mkafka1                         |[0m 	num.network.threads = 3
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[35;1mschemaregistry                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[34;1mkafka2                         |[0m 	min.insync.replicas = 1
[32mcontrol-center                 |[0m 	confluent.support.metrics.customer.id = anonymous
[33;1mrestproxy                      |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	num.partitions = 1
[33mzookeeper                      |[0m [2020-05-20 20:04:44,114] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0007 type:setData cxid:0x8 zxid:0x18b txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia.parsed Error:KeeperErrorCode = NoNode for /config/topics/wikipedia.parsed (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.interceptor.classes' was supplied but isn't a known config.
[34mstreams-demo                   |[0m 
[35;1mschemaregistry                 |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	num.io.threads = 8
[32mcontrol-center                 |[0m 	confluent.support.metrics.enable = true
[33;1mrestproxy                      |[0m 	ssl.truststore.type = JKS
[33mzookeeper                      |[0m [2020-05-20 20:04:44,306] INFO Processed session termination for sessionid: 0x1000183079c0007 (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[31;1mkafka1                         |[0m 	num.recovery.threads.per.data.dir = 1
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'offset.storage.replication.factor' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	zookeeper.connect = zookeeper:2181
[35;1mschemaregistry                 |[0m 	ssl.keystore.type = JKS
[33;1mrestproxy                      |[0m 	websocket.path.prefix = /ws
[34;1mkafka2                         |[0m 	num.network.threads = 3
[33mzookeeper                      |[0m [2020-05-20 20:04:44,307] INFO Closed socket connection for client /172.19.0.7:42780 which had sessionid 0x1000183079c0007 (org.apache.zookeeper.server.NIOServerCnxn)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	num.replica.alter.log.dirs.threads = null
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m  (io.confluent.controlcenter.ControlCenterConfig)
[35;1mschemaregistry                 |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m 	num.partitions = 1
[33;1mrestproxy                      |[0m 	websocket.servlet.initializor.classes = []
[33mzookeeper                      |[0m [2020-05-20 20:04:45,238] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x262 zxid:0x194 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-ksql-default__command_topic Error:KeeperErrorCode = NoNode for /config/topics/_confluent-ksql-default__command_topic (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	num.replica.fetchers = 1
[36;1mconnect                        |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'log4j.root.loglevel' was supplied but isn't a known config.
[32mcontrol-center                 |[0m [2020-05-20 20:04:24,949] INFO StreamsConfig values: 
[35;1mschemaregistry                 |[0m 	ssl.provider = 
[34;1mkafka2                         |[0m 	num.recovery.threads.per.data.dir = 1
[33;1mrestproxy                      |[0m 	zookeeper.connect = 
[33mzookeeper                      |[0m [2020-05-20 20:04:45,418] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x26b zxid:0x19a txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog Error:KeeperErrorCode = NoNode for /config/topics/wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	offset.metadata.max.bytes = 4096
[32mcontrol-center                 |[0m 	application.id = _confluent-controlcenter-5-3-1-1
[36;1mconnect                        |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.1-ccs
[35;1mschemaregistry                 |[0m 	ssl.trustmanager.algorithm = 
[34;1mkafka2                         |[0m 	num.replica.alter.log.dirs.threads = null
[33;1mrestproxy                      |[0m  (io.confluent.kafkarest.KafkaRestConfig)
[33mzookeeper                      |[0m [2020-05-20 20:04:48,712] INFO Accepted socket connection from /172.19.0.7:42844 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[31;1mkafka1                         |[0m 	offsets.commit.required.acks = -1
[32mcontrol-center                 |[0m 	application.server = 
[36;1mconnect                        |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: d7ac44734b9cf5cc
[35;1mschemaregistry                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[34;1mkafka2                         |[0m 	num.replica.fetchers = 1
[33;1mrestproxy                      |[0m [2020-05-20 20:04:23,850] INFO Logging initialized @2124ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[33mzookeeper                      |[0m [2020-05-20 20:04:48,798] INFO Client attempting to establish new session at /172.19.0.7:42844 (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m 	offsets.commit.timeout.ms = 5000
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[36;1mconnect                        |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005048334
[35;1mschemaregistry                 |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	offset.metadata.max.bytes = 4096
[33;1mrestproxy                      |[0m [2020-05-20 20:04:23,927] WARN The configuration ssl.client.auth is deprecated and should be replaced with ssl.client.authentication (io.confluent.rest.Application)
[33mzookeeper                      |[0m [2020-05-20 20:04:48,799] INFO Established session 0x1000183079c0008 with negotiated timeout 30000 for client /172.19.0.7:42844 (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m 	offsets.load.buffer.size = 5242880
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005044601
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	buffered.records.per.partition = 100
[34;1mkafka2                         |[0m 	offsets.commit.required.acks = -1
[35;1mschemaregistry                 |[0m 	ssl.truststore.type = JKS
[33mzookeeper                      |[0m [2020-05-20 20:04:48,811] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Creating restore consumer client
[33;1mrestproxy                      |[0m [2020-05-20 20:04:25,155] INFO Registered kafka:type=kafka.Log4jController MBean (io.confluent.kafka.utils.Log4jControllerRegistration$)
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	cache.max.bytes.buffering = 100000000
[31;1mkafka1                         |[0m 	offsets.retention.check.interval.ms = 600000
[34;1mkafka2                         |[0m 	offsets.commit.timeout.ms = 5000
[35;1mschemaregistry                 |[0m 	websocket.path.prefix = /ws
[33mzookeeper                      |[0m [2020-05-20 20:04:48,811] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
[32mcontrol-center                 |[0m 	client.id = 
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,032] INFO Verifying properties (io.confluent.kafka.utils.VerifiableProperties)
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	offsets.retention.minutes = 10080
[34;1mkafka2                         |[0m 	offsets.load.buffer.size = 5242880
[34mstreams-demo                   |[0m 	allow.auto.create.topics = true
[35;1mschemaregistry                 |[0m 	websocket.servlet.initializor.classes = []
[33mzookeeper                      |[0m [2020-05-20 20:04:48,811] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	commit.interval.ms = 30000
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,224] WARN Property bootstrap.servers is not valid (io.confluent.kafka.utils.VerifiableProperties)
[31;1mkafka1                         |[0m 	offsets.topic.compression.codec = 0
[34;1mkafka2                         |[0m 	offsets.retention.check.interval.ms = 600000
[34mstreams-demo                   |[0m 	auto.commit.interval.ms = 5000
[33mzookeeper                      |[0m [2020-05-20 20:04:50,218] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0008 type:setData cxid:0x8 zxid:0x1a3 txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia.parsed.count-by-channel Error:KeeperErrorCode = NoNode for /config/topics/wikipedia.parsed.count-by-channel (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	zookeeper.set.acl = false
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,225] WARN Property client.sasl.jaas.config is not valid (io.confluent.kafka.utils.VerifiableProperties)
[31;1mkafka1                         |[0m 	offsets.topic.num.partitions = 50
[34;1mkafka2                         |[0m 	offsets.retention.minutes = 10080
[34mstreams-demo                   |[0m 	auto.offset.reset = none
[33mzookeeper                      |[0m [2020-05-20 20:04:50,332] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x278 zxid:0x1a5 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[32mcontrol-center                 |[0m 	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndContinueExceptionHandler
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	offsets.topic.replication.factor = 2
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,225] WARN Property client.sasl.mechanism is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34;1mkafka2                         |[0m 	offsets.topic.compression.codec = 0
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[33mzookeeper                      |[0m [2020-05-20 20:04:50,337] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x27f zxid:0x1a8 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:23,996] INFO Logging initialized @2264ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[32mcontrol-center                 |[0m 	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	offsets.topic.segment.bytes = 104857600
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,226] WARN Property client.security.protocol is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34;1mkafka2                         |[0m 	offsets.topic.num.partitions = 50
[34;1mkafka2                         |[0m 	offsets.topic.replication.factor = 2
[33mzookeeper                      |[0m [2020-05-20 20:04:50,397] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x28d zxid:0x1b2 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:24,051] WARN The configuration ssl.client.auth is deprecated and should be replaced with ssl.client.authentication (io.confluent.rest.Application)
[32mcontrol-center                 |[0m 	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
[31;1mkafka1                         |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,226] WARN Property client.ssl.key.password is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34;1mkafka2                         |[0m 	offsets.topic.segment.bytes = 104857600
[34;1mkafka2                         |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:27,006] INFO Initializing KafkaStore with broker endpoints: SASL_SSL://kafka1:9091,SASL_SSL://kafka2:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[34mstreams-demo                   |[0m 	check.crcs = true
[32mcontrol-center                 |[0m 	default.timestamp.extractor = class io.confluent.controlcenter.streams.WindowExtractor
[31;1mkafka1                         |[0m 	password.encoder.iterations = 4096
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,226] WARN Property client.ssl.keystore.location is not valid (io.confluent.kafka.utils.VerifiableProperties)
[33mzookeeper                      |[0m [2020-05-20 20:04:50,404] INFO Processed session termination for sessionid: 0x1000183079c0008 (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:27,039] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m 	password.encoder.iterations = 4096
[32mcontrol-center                 |[0m 	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[31;1mkafka1                         |[0m 	password.encoder.key.length = 128
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,226] WARN Property client.ssl.keystore.password is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-StreamThread-1-restore-consumer
[35;1mschemaregistry                 |[0m 	bootstrap.servers = [SASL_SSL://kafka1:9091, SASL_SSL://kafka2:9092]
[33mzookeeper                      |[0m [2020-05-20 20:04:50,405] INFO Closed socket connection for client /172.19.0.7:42844 which had sessionid 0x1000183079c0008 (org.apache.zookeeper.server.NIOServerCnxn)
[34;1mkafka2                         |[0m 	password.encoder.key.length = 128
[32mcontrol-center                 |[0m 	max.task.idle.ms = 0
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	password.encoder.keyfactory.algorithm = null
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,227] WARN Property client.ssl.truststore.location is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34mstreams-demo                   |[0m 	client.rack = 
[35;1mschemaregistry                 |[0m 	client.dns.lookup = default
[33mzookeeper                      |[0m [2020-05-20 20:04:50,420] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x296 zxid:0x1b7 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	client.id = 
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	password.encoder.old.secret = null
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,233] WARN Property client.ssl.truststore.password is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[33mzookeeper                      |[0m [2020-05-20 20:04:50,496] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x2a0 zxid:0x1be txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[34;1mkafka2                         |[0m 	password.encoder.keyfactory.algorithm = null
[35;1mschemaregistry                 |[0m 	connections.max.idle.ms = 300000
[32mcontrol-center                 |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m 	password.encoder.secret = null
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,234] INFO Property group.id is overridden to  (io.confluent.kafka.utils.VerifiableProperties)
[34mstreams-demo                   |[0m 	default.api.timeout.ms = 60000
[34;1mkafka2                         |[0m 	password.encoder.old.secret = null
[33mzookeeper                      |[0m [2020-05-20 20:04:50,528] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x2af zxid:0x1c7 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m 	port = 9092
[36;1mconnect                        |[0m [kafka-admin-client-thread | adminclient-1] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,235] WARN Property host.name is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34mstreams-demo                   |[0m 	enable.auto.commit = false
[34;1mkafka2                         |[0m 	password.encoder.secret = null
[33mzookeeper                      |[0m [2020-05-20 20:04:54,710] INFO Accepted socket connection from /172.19.0.7:42886 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[35;1mschemaregistry                 |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m 	principal.builder.class = null
[36;1mconnect                        |[0m ===> Launching ... 
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,235] WARN Property listeners is not valid (io.confluent.kafka.utils.VerifiableProperties)
[34mstreams-demo                   |[0m 	exclude.internal.topics = true
[34;1mkafka2                         |[0m 	port = 9092
[35;1mschemaregistry                 |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[33mzookeeper                      |[0m [2020-05-20 20:04:54,713] INFO Client attempting to establish new session at /172.19.0.7:42886 (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m 	producer.purgatory.purge.interval.requests = 1000
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,235] WARN Property schema.registry.url is not valid (io.confluent.kafka.utils.VerifiableProperties)
[36;1mconnect                        |[0m ===> Launching kafka-connect ... 
[34;1mkafka2                         |[0m 	principal.builder.class = null
[34mstreams-demo                   |[0m 	fetch.max.bytes = 52428800
[35;1mschemaregistry                 |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	num.standby.replicas = 0
[33mzookeeper                      |[0m [2020-05-20 20:04:54,715] INFO Established session 0x1000183079c0009 with negotiated timeout 30000 for client /172.19.0.7:42886 (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m 	queued.max.request.bytes = -1
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,236] WARN Property ssl.client.auth is not valid (io.confluent.kafka.utils.VerifiableProperties)
[36;1mconnect                        |[0m [2020-05-20 20:04:21,549] INFO WorkerInfo values: 
[34;1mkafka2                         |[0m 	producer.purgatory.purge.interval.requests = 1000
[34;1mkafka2                         |[0m 	queued.max.request.bytes = -1
[34;1mkafka2                         |[0m 	queued.max.requests = 500
[34;1mkafka2                         |[0m 	quota.consumer.default = 9223372036854775807
[33mzookeeper                      |[0m [2020-05-20 20:04:54,800] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[35;1mschemaregistry                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m 	queued.max.requests = 500
[31;1mkafka1                         |[0m 	quota.consumer.default = 9223372036854775807
[36;1mconnect                        |[0m 	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/var/log/kafka, -Dlog4j.configuration=file:/etc/kafka/connect-log4j.properties, -Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.connect.truststore.jks, -Djavax.net.ssl.trustStorePassword=confluent, -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.connect.keystore.jks, -Djavax.net.ssl.keyStorePassword=confluent
[34;1mkafka2                         |[0m 	quota.producer.default = 9223372036854775807
[33mzookeeper                      |[0m [2020-05-20 20:04:54,800] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[31;1mkafka1                         |[0m 	quota.producer.default = 9223372036854775807
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,236] WARN Property ssl.key.password is not valid (io.confluent.kafka.utils.VerifiableProperties)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,236] WARN Property ssl.keystore.location is not valid (io.confluent.kafka.utils.VerifiableProperties)
[32mcontrol-center                 |[0m 	num.stream.threads = 1
[34mstreams-demo                   |[0m 	fetch.max.wait.ms = 500
[36;1mconnect                        |[0m 	jvm.spec = Azul Systems, Inc., OpenJDK 64-Bit Server VM, 1.8.0_212, 25.212-b04
[33mzookeeper                      |[0m [2020-05-20 20:04:54,800] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[35;1mschemaregistry                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m 	quota.window.num = 11
[34mstreams-demo                   |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m 	quota.window.num = 11
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,237] WARN Property ssl.keystore.password is not valid (io.confluent.kafka.utils.VerifiableProperties)
[36;1mconnect                        |[0m 	jvm.classpath = /etc/kafka-connect/jars/*:/usr/share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/share/java/kafka/commons-logging-1.2.jar:/usr/share/java/kafka/plexus-utils-3.2.0.jar:/usr/share/java/kafka/slf4j-api-1.7.26.jar:/usr/share/java/kafka/metrics-core-2.2.0.jar:/usr/share/java/kafka/commons-codec-1.11.jar:/usr/share/java/kafka/avro-1.8.1.jar:/usr/share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/share/java/kafka/xz-1.5.jar:/usr/share/java/kafka/scala-reflect-2.12.8.jar:/usr/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/share/java/kafka/jersey-common-2.28.jar:/usr/share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/share/java/kafka/jersey-hk2-2.28.jar:/usr/share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/share/java/kafka/snappy-java-1.1.7.3.jar:/usr/share/java/kafka/jersey-client-2.28.jar:/usr/share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/share/java/kafka/activation-1.1.1.jar:/usr/share/java/kafka/javassist-3.22.0-CR2.jar:/usr/share/java/kafka/zkclient-0.11.jar:/usr/share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/share/java/kafka/jackson-annotations-2.9.9.jar:/usr/share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/share/java/kafka/argparse4j-0.7.0.jar:/usr/share/java/kafka/commons-compress-1.8.1.jar:/usr/share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/share/java/kafka/commons-lang3-3.8.1.jar:/usr/share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/share/java/kafka/rocksdbjni-5.18.3.jar:/usr/share/java/kafka/jaxb-api-2.3.0.jar:/usr/share/java/kafka/hk2-utils-2.5.0.jar:/usr/share/java/kafka/httpmime-4.5.7.jar:/usr/share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/share/java/kafka/lz4-java-1.6.0.jar:/usr/share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/share/java/kafka/jopt-simple-5.0.4.jar:/usr/share/java/kafka/jsr305-3.0.2.jar:/usr/share/java/kafka/guava-20.0.jar:/usr/share/java/kafka/jersey-server-2.28.jar:/usr/share/java/kafka/httpclient-4.5.7.jar:/usr/share/java/kafka/reflections-0.9.11.jar:/usr/share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/share/java/kafka/zookeeper-3.4.14.jar:/usr/share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/share/java/kafka/jackson-core-2.9.9.jar:/usr/share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/share/java/kafka/maven-artifact-3.6.1.jar:/usr/share/java/kafka/validation-api-2.0.1.Final.jar:/usr/share/java/kafka/hk2-locator-2.5.0.jar:/usr/share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/share/java/kafka/jakarta.inject-2.5.0.jar:/usr/share/java/kafka/httpcore-4.4.11.jar:/usr/share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/share/java/kafka/paranamer-2.8.jar:/usr/share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/share/java/kafka/scala-library-2.12.8.jar:/usr/share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/share/java/kafka/paranamer-2.7.jar:/usr/share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/share/java/kafka/kafka.jar:/usr/share/java/kafka/hk2-api-2.5.0.jar:/usr/share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/share/java/kafka/audience-annotations-0.5.0.jar:/usr/share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/share/java/kafka/jersey-container-servlet-2.28.jar:/usr/share/java/kafka/log4j-1.2.17.jar:/usr/share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/share/java/confluent-common/slf4j-api-1.7.26.jar:/usr/share/java/confluent-common/spotbugs-annotations-3.1.8.jar:/usr/share/java/confluent-common/jline-0.9.94.jar:/usr/share/java/confluent-common/common-config-5.3.1.jar:/usr/share/java/confluent-common/jsr305-3.0.2.jar:/usr/share/java/confluent-common/zookeeper-3.4.14.jar:/usr/share/java/confluent-common/common-utils-5.3.1.jar:/usr/share/java/confluent-common/zkclient-0.10.jar:/usr/share/java/confluent-common/netty-3.10.6.Final.jar:/usr/share/java/confluent-common/build-tools-5.3.1.jar:/usr/share/java/confluent-common/common-metrics-5.3.1.jar:/usr/share/java/confluent-common/audience-annotations-0.5.0.jar:/usr/share/java/kafka-serde-tools/avro-1.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-converter-5.3.1.jar:/usr/share/java/kafka-serde-tools/jackson-databind-2.9.9.3.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-5.3.1.jar:/usr/share/java/kafka-serde-tools/xz-1.5.jar:/usr/share/java/kafka-serde-tools/jackson-mapper-asl-1.9.13.jar:/usr/share/java/kafka-serde-tools/kafka-avro-serializer-5.3.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-serializer-5.3.1.jar:/usr/share/java/kafka-serde-tools/jackson-annotations-2.9.9.jar:/usr/share/java/kafka-serde-tools/kafka-streams-avro-serde-5.3.1.jar:/usr/share/java/kafka-serde-tools/commons-compress-1.8.1.jar:/usr/share/java/kafka-serde-tools/jackson-core-asl-1.9.13.jar:/usr/share/java/kafka-serde-tools/jackson-core-2.9.9.jar:/usr/share/java/kafka-serde-tools/paranamer-2.7.jar:/usr/share/java/kafka-serde-tools/snappy-java-1.1.1.3.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-5.3.1.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/*
[32mcontrol-center                 |[0m 	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
[33mzookeeper                      |[0m [2020-05-20 20:04:56,211] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0009 type:setData cxid:0x8 zxid:0x1d1 txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia.failed Error:KeeperErrorCode = NoNode for /config/topics/wikipedia.failed (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m 	quota.window.size.seconds = 1
[34mstreams-demo                   |[0m 	group.id = null
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,237] WARN Property ssl.truststore.location is not valid (io.confluent.kafka.utils.VerifiableProperties)
[31;1mkafka1                         |[0m 	quota.window.size.seconds = 1
[32mcontrol-center                 |[0m 	poll.ms = 100
[33mzookeeper                      |[0m [2020-05-20 20:04:56,399] INFO Processed session termination for sessionid: 0x1000183079c0009 (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m 	os.spec = Linux, amd64, 5.3.0-1017-aws
[35;1mschemaregistry                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	replica.fetch.backoff.ms = 1000
[34mstreams-demo                   |[0m 	group.instance.id = null
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,237] WARN Property ssl.truststore.password is not valid (io.confluent.kafka.utils.VerifiableProperties)
[31;1mkafka1                         |[0m 	replica.fetch.backoff.ms = 1000
[32mcontrol-center                 |[0m 	processing.guarantee = at_least_once
[33mzookeeper                      |[0m [2020-05-20 20:04:56,401] INFO Closed socket connection for client /172.19.0.7:42886 which had sessionid 0x1000183079c0009 (org.apache.zookeeper.server.NIOServerCnxn)
[36;1mconnect                        |[0m 	os.vcpus = 1
[35;1mschemaregistry                 |[0m 	request.timeout.ms = 120000
[34;1mkafka2                         |[0m 	replica.fetch.max.bytes = 1048576
[34mstreams-demo                   |[0m 	heartbeat.interval.ms = 3000
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,238] INFO Property zookeeper.connect is overridden to  (io.confluent.kafka.utils.VerifiableProperties)
[31;1mkafka1                         |[0m 	replica.fetch.max.bytes = 1048576
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[33mzookeeper                      |[0m [2020-05-20 20:05:00,719] INFO Accepted socket connection from /172.19.0.7:42916 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.WorkerInfo)
[35;1mschemaregistry                 |[0m 	retries = 5
[34;1mkafka2                         |[0m 	replica.fetch.min.bytes = 1
[34mstreams-demo                   |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,320] INFO KafkaAvroDeserializerConfig values: 
[31;1mkafka1                         |[0m 	replica.fetch.min.bytes = 1
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[33mzookeeper                      |[0m [2020-05-20 20:05:00,722] INFO Client attempting to establish new session at /172.19.0.7:42916 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:21,607] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed)
[35;1mschemaregistry                 |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m 	internal.leave.group.on.close = false
[34;1mkafka2                         |[0m 	replica.fetch.response.max.bytes = 10485760
[33;1mrestproxy                      |[0m 	bearer.auth.token = [hidden]
[31;1mkafka1                         |[0m 	replica.fetch.response.max.bytes = 10485760
[33mzookeeper                      |[0m [2020-05-20 20:05:00,730] INFO Established session 0x1000183079c000a with negotiated timeout 30000 for client /172.19.0.7:42916 (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m [2020-05-20 20:04:21,647] INFO Loading plugin from: /usr/share/java/kafka-connect-replicator (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	isolation.level = read_uncommitted
[34;1mkafka2                         |[0m 	replica.fetch.wait.max.ms = 500
[33;1mrestproxy                      |[0m 	schema.registry.url = [https://schemaregistry:8085]
[31;1mkafka1                         |[0m 	replica.fetch.wait.max.ms = 500
[33mzookeeper                      |[0m [2020-05-20 20:05:00,806] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,205] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-replicator/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	replication.factor = 2
[35;1mschemaregistry                 |[0m 	sasl.jaas.config = [hidden]
[34mstreams-demo                   |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[33;1mrestproxy                      |[0m 	basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[33mzookeeper                      |[0m [2020-05-20 20:05:00,807] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,205] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	request.timeout.ms = 40000
[35;1mschemaregistry                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mstreams-demo                   |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m 	replica.lag.time.max.ms = 10000
[33;1mrestproxy                      |[0m 	auto.register.schemas = true
[31;1mkafka1                         |[0m 	replica.lag.time.max.ms = 10000
[33mzookeeper                      |[0m [2020-05-20 20:05:00,807] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,205] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	retries = 2147483647
[35;1mschemaregistry                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	replica.socket.receive.buffer.bytes = 65536
[34mstreams-demo                   |[0m 	max.poll.interval.ms = 300000
[31;1mkafka1                         |[0m 	replica.socket.receive.buffer.bytes = 65536
[33;1mrestproxy                      |[0m 	max.schemas.per.subject = 1000
[36;1mconnect                        |[0m [2020-05-20 20:04:32,207] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33mzookeeper                      |[0m [2020-05-20 20:05:02,296] INFO Got user-level KeeperException when processing sessionid:0x1000183079c000a type:setData cxid:0x7 zxid:0x1db txntype:-1 reqpath:n/a Error Path:/config/topics/WIKIPEDIABOT Error:KeeperErrorCode = NoNode for /config/topics/WIKIPEDIABOT (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m 	replica.socket.timeout.ms = 30000
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m 	max.poll.records = 1000
[31;1mkafka1                         |[0m 	replica.socket.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:04:32,207] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m 	basic.auth.credentials.source = URL
[33mzookeeper                      |[0m [2020-05-20 20:05:02,417] INFO Processed session termination for sessionid: 0x1000183079c000a (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m 	replication.quota.window.num = 11
[32mcontrol-center                 |[0m 	rocksdb.config.setter = class io.confluent.controlcenter.streams.RocksDBConfigurator
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m 	replication.quota.window.num = 11
[36;1mconnect                        |[0m [2020-05-20 20:04:32,207] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m 	schema.registry.basic.auth.user.info = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:05:02,419] INFO Closed socket connection for client /172.19.0.7:42916 which had sessionid 0x1000183079c000a (org.apache.zookeeper.server.NIOServerCnxn)
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m 	replication.quota.window.size.seconds = 1
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m 	replication.quota.window.size.seconds = 1
[33;1mrestproxy                      |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[33mzookeeper                      |[0m [2020-05-20 20:05:06,803] INFO Accepted socket connection from /172.19.0.7:42956 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,207] INFO Added plugin 'io.confluent.connect.replicator.ReplicatorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m 	request.timeout.ms = 30000
[33;1mrestproxy                      |[0m 	specific.avro.reader = false
[33mzookeeper                      |[0m [2020-05-20 20:05:06,806] INFO Client attempting to establish new session at /172.19.0.7:42956 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,208] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m 	reserved.broker.max.id = 1000
[32mcontrol-center                 |[0m 	state.cleanup.delay.ms = 600000
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m 	reserved.broker.max.id = 1000
[33;1mrestproxy                      |[0m 	value.subject.name.strategy = class io.confluent.kafka.shaded.serializers.subject.TopicNameStrategy
[33mzookeeper                      |[0m [2020-05-20 20:05:06,808] INFO Established session 0x1000183079c000b with negotiated timeout 30000 for client /172.19.0.7:42956 (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,209] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	state.dir = /var/lib/confluent-control-center/1/kafka-streams
[34;1mkafka2                         |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m 	sasl.client.callback.handler.class = null
[33;1mrestproxy                      |[0m 	key.subject.name.strategy = class io.confluent.kafka.shaded.serializers.subject.TopicNameStrategy
[33mzookeeper                      |[0m [2020-05-20 20:05:06,899] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,209] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	topology.optimization = all
[34;1mkafka2                         |[0m 	sasl.enabled.mechanisms = [PLAIN]
[33mzookeeper                      |[0m [2020-05-20 20:05:06,899] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[31;1mkafka1                         |[0m 	sasl.enabled.mechanisms = [PLAIN]
[33;1mrestproxy                      |[0m  (io.confluent.kafka.shaded.serializers.KafkaAvroDeserializerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,209] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[32mcontrol-center                 |[0m 	upgrade.from = null
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m 	sasl.jaas.config = null
[31;1mkafka1                         |[0m 	sasl.jaas.config = null
[33mzookeeper                      |[0m [2020-05-20 20:05:06,899] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,347] INFO KafkaJsonDecoderConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:04:32,209] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 65536
[32mcontrol-center                 |[0m 	windowstore.changelog.additional.retention.ms = 86400000
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[33;1mrestproxy                      |[0m 	json.fail.unknown.properties = true
[33mzookeeper                      |[0m [2020-05-20 20:05:08,303] INFO Got user-level KeeperException when processing sessionid:0x1000183079c000b type:setData cxid:0x7 zxid:0x1e5 txntype:-1 reqpath:n/a Error Path:/config/topics/WIKIPEDIANOBOT Error:KeeperErrorCode = NoNode for /config/topics/WIKIPEDIANOBOT (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,210] INFO Added plugin 'io.confluent.connect.replicator.util.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m  (org.apache.kafka.streams.StreamsConfig)
[35;1mschemaregistry                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[33;1mrestproxy                      |[0m  (io.confluent.kafka.shaded.serializers.KafkaJsonDecoderConfig)
[33mzookeeper                      |[0m [2020-05-20 20:05:08,417] INFO Processed session termination for sessionid: 0x1000183079c000b (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,210] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,333] INFO setting topic names _confluent-monitoring (io.confluent.controlcenter.streams.WindowExtractor)
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[35;1mschemaregistry                 |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[33;1mrestproxy                      |[0m [2020-05-20 20:04:26,826] INFO Adding listener: https://0.0.0.0:8086 (io.confluent.rest.Application)
[31;1mkafka1                         |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[33mzookeeper                      |[0m [2020-05-20 20:05:08,419] INFO Closed socket connection for client /172.19.0.7:42956 which had sessionid 0x1000183079c000b (org.apache.zookeeper.server.NIOServerCnxn)
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:04:32,210] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,354] INFO transformerStore=MonitoringVerifierStore (io.confluent.controlcenter.streams.StreamsModule)
[35;1mschemaregistry                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m 	sasl.kerberos.service.name = null
[33;1mrestproxy                      |[0m [2020-05-20 20:04:27,901] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_212-b04 (org.eclipse.jetty.server.Server)
[31;1mkafka1                         |[0m 	sasl.kerberos.service.name = null
[33mzookeeper                      |[0m [2020-05-20 20:05:12,809] INFO Accepted socket connection from /172.19.0.7:42978 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m [2020-05-20 20:04:32,210] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35;1mschemaregistry                 |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,360] INFO transformerStore=MonitoringTriggerStore (io.confluent.controlcenter.streams.StreamsModule)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:28,227] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[33mzookeeper                      |[0m [2020-05-20 20:05:12,813] INFO Client attempting to establish new session at /172.19.0.7:42978 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35;1mschemaregistry                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,360] INFO transformerStore=TriggerActionsStore (io.confluent.controlcenter.streams.StreamsModule)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:28,295] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33mzookeeper                      |[0m [2020-05-20 20:05:12,814] INFO Established session 0x1000183079c000c with negotiated timeout 30000 for client /172.19.0.7:42978 (org.apache.zookeeper.server.ZooKeeperServer)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	sasl.login.callback.handler.class = null
[35;1mschemaregistry                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,360] INFO transformerStore=TriggerEventsStore (io.confluent.controlcenter.streams.StreamsModule)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:28,298] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	sasl.login.callback.handler.class = null
[33mzookeeper                      |[0m [2020-05-20 20:05:12,899] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	ssl.key.password = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:05:12,899] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[33;1mrestproxy                      |[0m May 20, 2020 8:04:31 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,360] INFO transformerStore=AlertHistoryStore (io.confluent.controlcenter.streams.StreamsModule)
[33;1mrestproxy                      |[0m WARNING: A provider io.confluent.kafkarest.resources.TopicsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafkarest.resources.TopicsResource will be ignored. 
[33mzookeeper                      |[0m [2020-05-20 20:05:12,899] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,426] INFO ProducerConfig values: 
[33;1mrestproxy                      |[0m May 20, 2020 8:04:31 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[33mzookeeper                      |[0m [2020-05-20 20:05:14,315] INFO Got user-level KeeperException when processing sessionid:0x1000183079c000c type:setData cxid:0x8 zxid:0x1ef txntype:-1 reqpath:n/a Error Path:/config/topics/EN_WIKIPEDIA_GT_1 Error:KeeperErrorCode = NoNode for /config/topics/EN_WIKIPEDIA_GT_1 (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	acks = all
[35;1mschemaregistry                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[31;1mkafka1                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m WARNING: A provider io.confluent.kafkarest.resources.ConsumersResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafkarest.resources.ConsumersResource will be ignored. 
[33mzookeeper                      |[0m [2020-05-20 20:05:14,500] INFO Processed session termination for sessionid: 0x1000183079c000c (org.apache.zookeeper.server.PrepRequestProcessor)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	batch.size = 16384
[35;1mschemaregistry                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m May 20, 2020 8:04:31 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[33mzookeeper                      |[0m [2020-05-20 20:05:14,502] INFO Closed socket connection for client /172.19.0.7:42978 which had sessionid 0x1000183079c000c (org.apache.zookeeper.server.NIOServerCnxn)
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[35;1mschemaregistry                 |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[33;1mrestproxy                      |[0m WARNING: A provider io.confluent.kafkarest.resources.BrokersResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafkarest.resources.BrokersResource will be ignored. 
[34;1mkafka2                         |[0m 	sasl.mechanism.inter.broker.protocol = PLAIN
[33mzookeeper                      |[0m [2020-05-20 20:05:18,909] INFO Accepted socket connection from /172.19.0.7:42996 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[32mcontrol-center                 |[0m 	buffer.memory = 33554432
[34mstreams-demo                   |[0m 	sasl.login.class = null
[35;1mschemaregistry                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	sasl.mechanism.inter.broker.protocol = PLAIN
[33;1mrestproxy                      |[0m May 20, 2020 8:04:31 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m 	sasl.server.callback.handler.class = null
[33mzookeeper                      |[0m [2020-05-20 20:05:18,913] INFO Client attempting to establish new session at /172.19.0.7:42996 (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[35;1mschemaregistry                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	sasl.server.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m WARNING: A provider io.confluent.kafkarest.resources.PartitionsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafkarest.resources.PartitionsResource will be ignored. 
[34;1mkafka2                         |[0m 	security.inter.broker.protocol = PLAINTEXT
[33mzookeeper                      |[0m [2020-05-20 20:05:18,914] INFO Established session 0x1000183079c000d with negotiated timeout 30000 for client /172.19.0.7:42996 (org.apache.zookeeper.server.ZooKeeperServer)
[32mcontrol-center                 |[0m 	client.id = confluent-control-center-heartbeat-sender-1
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[35;1mschemaregistry                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	security.inter.broker.protocol = PLAINTEXT
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m May 20, 2020 8:04:31 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m 	socket.receive.buffer.bytes = 102400
[32mcontrol-center                 |[0m 	compression.type = lz4
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[33mzookeeper                      |[0m [2020-05-20 20:05:18,999] INFO Successfully authenticated client: authenticationID=kafka;  authorizationID=kafka. (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[35;1mschemaregistry                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	socket.receive.buffer.bytes = 102400
[36;1mconnect                        |[0m [2020-05-20 20:04:32,214] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m WARNING: A provider io.confluent.kafkarest.resources.v2.PartitionsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafkarest.resources.v2.PartitionsResource will be ignored. 
[34;1mkafka2                         |[0m 	socket.request.max.bytes = 104857600
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[33mzookeeper                      |[0m [2020-05-20 20:05:19,000] INFO Setting authorizedID: kafka (org.apache.zookeeper.server.auth.SaslServerCallbackHandler)
[35;1mschemaregistry                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[31;1mkafka1                         |[0m 	socket.request.max.bytes = 104857600
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	delivery.timeout.ms = 2147483647
[33;1mrestproxy                      |[0m May 20, 2020 8:04:31 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m 	socket.send.buffer.bytes = 102400
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[33mzookeeper                      |[0m [2020-05-20 20:05:19,000] INFO adding SASL authorization for authorizationID: kafka (org.apache.zookeeper.server.ZooKeeperServer)
[31;1mkafka1                         |[0m 	socket.send.buffer.bytes = 102400
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	enable.idempotence = false
[33;1mrestproxy                      |[0m WARNING: A provider io.confluent.kafkarest.resources.v2.ConsumersResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafkarest.resources.v2.ConsumersResource will be ignored. 
[34;1mkafka2                         |[0m 	ssl.cipher.suites = []
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m 	ssl.cipher.suites = []
[33mzookeeper                      |[0m [2020-05-20 20:05:20,505] INFO Got user-level KeeperException when processing sessionid:0x1000183079c000d type:setData cxid:0x8 zxid:0x1f9 txntype:-1 reqpath:n/a Error Path:/config/topics/EN_WIKIPEDIA_GT_1_COUNTS Error:KeeperErrorCode = NoNode for /config/topics/EN_WIKIPEDIA_GT_1_COUNTS (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[33;1mrestproxy                      |[0m [2020-05-20 20:04:32,299] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[34;1mkafka2                         |[0m 	ssl.client.auth = required
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m 	ssl.client.auth = required
[35;1mschemaregistry                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[33mzookeeper                      |[0m [2020-05-20 20:05:20,619] INFO Processed session termination for sessionid: 0x1000183079c000d (org.apache.zookeeper.server.PrepRequestProcessor)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:33,599] INFO Started o.e.j.s.ServletContextHandler@5e17553a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[32mcontrol-center                 |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m 	session.timeout.ms = 10000
[31;1mkafka1                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:27,242] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[33mzookeeper                      |[0m [2020-05-20 20:05:20,621] INFO Closed socket connection for client /172.19.0.7:42996 which had sessionid 0x1000183079c000d (org.apache.zookeeper.server.NIOServerCnxn)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:33,718] INFO Started o.e.j.s.ServletContextHandler@3b5fad2d{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[32mcontrol-center                 |[0m 	linger.ms = 500
[34;1mkafka2                         |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[33mzookeeper                      |[0m [2020-05-20 20:05:24,599] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x2ef zxid:0x202 txntype:-1 reqpath:n/a Error Path:/config/topics/connect-offsets Error:KeeperErrorCode = NoNode for /config/topics/connect-offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:27,913] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:36,818] INFO x509=X509@3eed0f5(restproxy,h=[restproxy, localhost],w=[]) for Server@8a62297[provider=null,keyStore=file:///etc/kafka/secrets/kafka.restproxy.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.restproxy.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	max.block.ms = 9223372036854775807
[34;1mkafka2                         |[0m 	ssl.key.password = [hidden]
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m 	ssl.key.password = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:05:28,401] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x341 zxid:0x238 txntype:-1 reqpath:n/a Error Path:/config/topics/connect-statuses Error:KeeperErrorCode = NoNode for /config/topics/connect-statuses (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:27,914] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:36,819] INFO x509=X509@64030b91(caroot,h=[ca1.test.confluent.io],w=[]) for Server@8a62297[provider=null,keyStore=file:///etc/kafka/secrets/kafka.restproxy.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.restproxy.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	max.in.flight.requests.per.connection = 1
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	ssl.keymanager.algorithm = SunX509
[33mzookeeper                      |[0m [2020-05-20 20:05:30,219] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x357 zxid:0x246 txntype:-1 reqpath:n/a Error Path:/config/topics/connect-configs Error:KeeperErrorCode = NoNode for /config/topics/connect-configs (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:27,914] INFO Kafka startTimeMs: 1590005067907 (org.apache.kafka.common.utils.AppInfoParser)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:37,329] INFO Started NetworkTrafficServerConnector@49c90a9c{SSL,[ssl, http/1.1]}{0.0.0.0:8086} (org.eclipse.jetty.server.AbstractConnector)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	max.request.size = 10485760
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.kafka1.keystore.jks
[34;1mkafka2                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.kafka2.keystore.jks
[33mzookeeper                      |[0m [2020-05-20 20:05:52,946] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x363 zxid:0x24c txntype:-1 reqpath:n/a Error Path:/config/topics/wikipedia.parsed.replica Error:KeeperErrorCode = NoNode for /config/topics/wikipedia.parsed.replica (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:29,843] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:37,330] INFO Started @15616ms (org.eclipse.jetty.server.Server)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	ssl.keystore.password = [hidden]
[33mzookeeper                      |[0m [2020-05-20 20:06:47,135] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x391 zxid:0x254 txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition Error:KeeperErrorCode = NoNode for /config/topics/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:29,848] WARN Creating the schema topic _schemas using a replication factor of 2, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[33;1mrestproxy                      |[0m [2020-05-20 20:04:37,330] INFO Server started, listening for requests... (io.confluent.kafkarest.KafkaRestMain)
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	ssl.keystore.type = JKS
[33mzookeeper                      |[0m [2020-05-20 20:06:47,205] INFO Got user-level KeeperException when processing sessionid:0x1000183079c0002 type:setData cxid:0x39e zxid:0x25c txntype:-1 reqpath:n/a Error Path:/config/topics/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog Error:KeeperErrorCode = NoNode for /config/topics/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:30,063] INFO ProducerConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m 	ssl.principal.mapping.rules = [DEFAULT]
[34;1mkafka2                         |[0m 	ssl.principal.mapping.rules = [DEFAULT]
[35;1mschemaregistry                 |[0m 	acks = -1
[36;1mconnect                        |[0m [2020-05-20 20:04:32,215] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:04:32,216] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m 	ssl.provider = null
[35;1mschemaregistry                 |[0m 	bootstrap.servers = [SASL_SSL://kafka1:9091, SASL_SSL://kafka2:9092]
[32mcontrol-center                 |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect                        |[0m [2020-05-20 20:04:32,218] INFO Loading plugin from: /usr/share/java/kafka-connect-elasticsearch (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mschemaregistry                 |[0m 	buffer.memory = 33554432
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m [2020-05-20 20:04:32,934] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-elasticsearch/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.kafka2.truststore.jks
[31;1mkafka1                         |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mschemaregistry                 |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m [2020-05-20 20:04:32,934] INFO Added plugin 'io.confluent.connect.elasticsearch.ElasticsearchSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.kafka1.truststore.jks
[35;1mschemaregistry                 |[0m 	client.id = 
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m [2020-05-20 20:04:32,934] INFO Added plugin 'io.confluent.transforms.NullFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	ssl.truststore.type = JKS
[35;1mschemaregistry                 |[0m 	compression.type = none
[31;1mkafka1                         |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:04:32,936] INFO Loading plugin from: /usr/share/java/kafka-connect-jms (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[31;1mkafka1                         |[0m 	ssl.truststore.type = JKS
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	retries = 10
[36;1mconnect                        |[0m [2020-05-20 20:04:33,622] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jms/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m 	transaction.max.timeout.ms = 900000
[31;1mkafka1                         |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[34mstreams-demo                   |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect                        |[0m [2020-05-20 20:04:33,622] INFO Added plugin 'io.confluent.connect.jms.JmsSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	enable.idempotence = false
[32mcontrol-center                 |[0m 	retry.backoff.ms = 500
[34;1mkafka2                         |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[31;1mkafka1                         |[0m 	transaction.max.timeout.ms = 900000
[34mstreams-demo                   |[0m 
[36;1mconnect                        |[0m [2020-05-20 20:04:33,625] INFO Loading plugin from: /usr/share/java/kafka-connect-storage-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	interceptor.classes = []
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[31;1mkafka1                         |[0m 	transaction.state.log.load.buffer.size = 5242880
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m 	transaction.state.log.load.buffer.size = 5242880
[36;1mconnect                        |[0m [2020-05-20 20:04:37,407] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-storage-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	transaction.state.log.min.isr = 2
[35;1mschemaregistry                 |[0m 	linger.ms = 0
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:04:37,407] INFO Added plugin 'io.confluent.connect.storage.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	transaction.state.log.min.isr = 2
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	transaction.state.log.num.partitions = 50
[35;1mschemaregistry                 |[0m 	max.block.ms = 60000
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	transaction.state.log.num.partitions = 50
[36;1mconnect                        |[0m [2020-05-20 20:04:37,407] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	max.in.flight.requests.per.connection = 5
[31;1mkafka1                         |[0m 	transaction.state.log.replication.factor = 3
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	transaction.state.log.replication.factor = 3
[36;1mconnect                        |[0m [2020-05-20 20:04:37,408] INFO Loading plugin from: /usr/share/java/kafka-connect-activemq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	transaction.state.log.segment.bytes = 104857600
[35;1mschemaregistry                 |[0m 	max.request.size = 1048576
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	transaction.state.log.segment.bytes = 104857600
[36;1mconnect                        |[0m [2020-05-20 20:04:39,613] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-activemq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m 	transactional.id.expiration.ms = 604800000
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	transactional.id.expiration.ms = 604800000
[36;1mconnect                        |[0m [2020-05-20 20:04:39,613] INFO Added plugin 'io.confluent.connect.activemq.ActiveMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m 	unclean.leader.election.enable = false
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	unclean.leader.election.enable = false
[36;1mconnect                        |[0m [2020-05-20 20:04:39,621] INFO Loading plugin from: /usr/share/java/kafka-connect-ibmmq (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m 	zookeeper.connect = zookeeper:2181
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	zookeeper.connect = zookeeper:2181
[35;1mschemaregistry                 |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m 	zookeeper.connection.timeout.ms = null
[36;1mconnect                        |[0m [2020-05-20 20:04:40,997] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-ibmmq/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	zookeeper.connection.timeout.ms = null
[35;1mschemaregistry                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m 	zookeeper.max.in.flight.requests = 10
[36;1mconnect                        |[0m [2020-05-20 20:04:40,998] INFO Added plugin 'io.confluent.connect.ibm.mq.IbmMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m 	zookeeper.max.in.flight.requests = 10
[36;1mconnect                        |[0m [2020-05-20 20:04:41,001] INFO Loading plugin from: /usr/share/java/kafka-connect-s3 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31;1mkafka1                         |[0m 	zookeeper.session.timeout.ms = 6000
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m [2020-05-20 20:04:44,339] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-s3/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	zookeeper.session.timeout.ms = 6000
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m 	zookeeper.set.acl = true
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:04:44,339] INFO Added plugin 'io.confluent.connect.s3.S3SinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m 	zookeeper.set.acl = true
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m 	zookeeper.sync.time.ms = 2000
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:04:44,341] INFO Loading plugin from: /usr/share/java/kafka-connect-jdbc (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	zookeeper.sync.time.ms = 2000
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m  (kafka.server.KafkaConfig)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:04:45,006] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-jdbc/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m  (kafka.server.KafkaConfig)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,613] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:04:45,006] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	retries = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,609] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,696] WARN Please note that the support metrics collection feature ("Metrics") of Proactive Support is enabled.  With Metrics enabled, this broker is configured to collect and report certain broker and cluster metadata ("Metadata") about your use of the Confluent Platform (including without limitation, your remote internet protocol address) to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every 24hours.  This Metadata may be transferred to any country in which Confluent maintains facilities.  For a more in depth discussion of how Confluent processes such information, please read our Privacy Policy located at http://www.confluent.io/privacy. By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer, storage and use of Metadata by Confluent.  You can turn the Metrics feature off by setting `confluent.support.metrics.enable=false` in the broker configuration and restarting the broker.  See the Confluent Platform documentation for further information. (io.confluent.support.metrics.SupportedServerStartable)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,620] WARN Please note that the support metrics collection feature ("Metrics") of Proactive Support is enabled.  With Metrics enabled, this broker is configured to collect and report certain broker and cluster metadata ("Metadata") about your use of the Confluent Platform (including without limitation, your remote internet protocol address) to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every 24hours.  This Metadata may be transferred to any country in which Confluent maintains facilities.  For a more in depth discussion of how Confluent processes such information, please read our Privacy Policy located at http://www.confluent.io/privacy. By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer, storage and use of Metadata by Confluent.  You can turn the Metrics feature off by setting `confluent.support.metrics.enable=false` in the broker configuration and restarting the broker.  See the Confluent Platform documentation for further information. (io.confluent.support.metrics.SupportedServerStartable)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,698] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[36;1mconnect                        |[0m [2020-05-20 20:04:45,006] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[35;1mschemaregistry                 |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,623] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,699] INFO starting (kafka.server.KafkaServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:45,033] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,624] INFO starting (kafka.server.KafkaServer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,700] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[36;1mconnect                        |[0m [2020-05-20 20:04:53,113] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[35;1mschemaregistry                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,625] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,724] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[36;1mconnect                        |[0m [2020-05-20 20:04:53,113] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[35;1mschemaregistry                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,707] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:53,114] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[35;1mschemaregistry                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,712] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:host.name=kafka1 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:53,114] INFO Added plugin 'io.confluent.kafka.secretregistry.client.config.provider.SecretConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[35;1mschemaregistry                 |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,712] INFO Client environment:host.name=kafka2 (org.apache.zookeeper.ZooKeeper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,712] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:53,114] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005046157
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,712] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:53,114] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Creating shared producer client
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,712] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:54,800] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.home=/usr/lib/jvm/zulu-8-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:54,800] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[32mcontrol-center                 |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m 	acks = 1
[36;1mconnect                        |[0m [2020-05-20 20:04:55,400] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/kafka-streams-scala_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/spotbugs-annotations-3.1.9.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.26.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/commons-codec-1.11.jar:/usr/bin/../share/java/kafka/avro-1.8.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/usr/bin/../share/java/kafka/jackson-databind-2.9.9.3.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-scaladoc.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/xz-1.5.jar:/usr/bin/../share/java/kafka/scala-reflect-2.12.8.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.28.jar:/usr/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.28.jar:/usr/bin/../share/java/kafka/jackson-mapper-asl-1.9.13.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/usr/bin/../share/java/kafka/jersey-client-2.28.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/usr/bin/../share/java/kafka/zkclient-0.11.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.9.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/commons-compress-1.8.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/usr/bin/../share/java/kafka/httpmime-4.5.7.jar:/usr/bin/../share/java/kafka/connect-file-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/slf4j-log4j12-1.7.26.jar:/usr/bin/../share/java/kafka/lz4-java-1.6.0.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.9.jar:/usr/bin/../share/java/kafka/connect-json-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/guava-20.0.jar:/usr/bin/../share/java/kafka/jersey-server-2.28.jar:/usr/bin/../share/java/kafka/httpclient-4.5.7.jar:/usr/bin/../share/java/kafka/reflections-0.9.11.jar:/usr/bin/../share/java/kafka/kafka-streams-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.4.14.jar:/usr/bin/../share/java/kafka/jackson-core-asl-1.9.13.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-javadoc.jar:/usr/bin/../share/java/kafka/kafka-tools-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/usr/bin/../share/java/kafka/jackson-core-2.9.9.jar:/usr/bin/../share/java/kafka/connect-runtime-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/usr/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/usr/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/usr/bin/../share/java/kafka/support-metrics-client-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/usr/bin/../share/java/kafka/httpcore-4.4.11.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-clients-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/scala-library-2.12.8.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-sources.jar:/usr/bin/../share/java/kafka/paranamer-2.7.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.4.0-1.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test.jar:/usr/bin/../share/java/kafka/scala-logging_2.12-3.9.0.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-paranamer-2.9.9.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.9.jar:/usr/bin/../share/java/kafka/kafka_2.12-5.3.1-ccs-test-sources.jar:/usr/bin/../share/java/kafka/support-metrics-common-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.9.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.18.v20190429.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/hk2-api-2.5.0.jar:/usr/bin/../share/java/kafka/connect-api-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-5.3.1-ccs.jar:/usr/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.9.9.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/usr/bin/../share/java/kafka/log4j-1.2.17.jar:/usr/bin/../share/java/kafka/confluent-metrics-5.3.1-ce.jar:/usr/bin/../support-metrics-client/build/dependant-libs-2.12/*:/usr/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34mstreams-demo                   |[0m 	batch.size = 16384
[36;1mconnect                        |[0m [2020-05-20 20:04:55,400] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m [2020-05-20 20:04:59,595] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	buffer.memory = 33554432
[36;1mconnect                        |[0m [2020-05-20 20:04:59,596] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:59,995] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[35;1mschemaregistry                 |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-StreamThread-1-producer
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:04:59,995] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	transaction.timeout.ms = 60000
[35;1mschemaregistry                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	compression.type = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:05:01,735] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:os.version=5.3.0-1017-aws (org.apache.zookeeper.ZooKeeper)
[32mcontrol-center                 |[0m 	transactional.id = null
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:os.version=5.3.0-1017-aws (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m [2020-05-20 20:05:01,735] INFO Loading plugin from: /usr/share/java/confluent-rebalancer (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[32mcontrol-center                 |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	delivery.timeout.ms = 120000
[36;1mconnect                        |[0m [2020-05-20 20:05:04,538] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-rebalancer/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	enable.idempotence = false
[35;1mschemaregistry                 |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m [2020-05-20 20:05:04,539] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m [2020-05-20 20:04:25,541] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,713] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,730] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[35;1mschemaregistry                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m [2020-05-20 20:05:04,933] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m [2020-05-20 20:04:26,601] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,714] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@74e52303 (org.apache.zookeeper.ZooKeeper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,732] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@74e52303 (org.apache.zookeeper.ZooKeeper)
[34mstreams-demo                   |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[35;1mschemaregistry                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m [2020-05-20 20:05:04,933] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,727] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mcontrol-center                 |[0m [2020-05-20 20:04:26,601] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,745] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[34mstreams-demo                   |[0m 	linger.ms = 100
[35;1mschemaregistry                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:08,416] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,733] INFO Client successfully logged in. (org.apache.zookeeper.Login)
[32mcontrol-center                 |[0m [2020-05-20 20:04:26,601] INFO Kafka startTimeMs: 1590005066599 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,802] INFO Client successfully logged in. (org.apache.zookeeper.Login)
[34mstreams-demo                   |[0m 	max.block.ms = 60000
[35;1mschemaregistry                 |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,735] INFO Client will use DIGEST-MD5 as SASL mechanism. (org.apache.zookeeper.client.ZooKeeperSaslClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,416] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m [2020-05-20 20:04:26,745] INFO StreamsConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,804] INFO Client will use DIGEST-MD5 as SASL mechanism. (org.apache.zookeeper.client.ZooKeeperSaslClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,812] INFO Opening socket connection to server zookeeper/172.19.0.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client' (org.apache.zookeeper.ClientCnxn)
[34mstreams-demo                   |[0m 	max.in.flight.requests.per.connection = 5
[32mcontrol-center                 |[0m 	application.id = _confluent-controlcenter-5-3-1-1-command
[35;1mschemaregistry                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:08,416] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	max.request.size = 1048576
[35;1mschemaregistry                 |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,817] INFO Socket connection established to zookeeper/172.19.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[32mcontrol-center                 |[0m 	application.server = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,827] INFO Opening socket connection to server zookeeper/172.19.0.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client' (org.apache.zookeeper.ClientCnxn)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,417] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,824] INFO Session establishment complete on server zookeeper/172.19.0.2:2181, sessionid = 0x1000183079c0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[35;1mschemaregistry                 |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,832] INFO Socket connection established to zookeeper/172.19.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,417] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:09,828] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[35;1mschemaregistry                 |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	buffered.records.per.partition = 1000
[34mstreams-demo                   |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,904] INFO Session establishment complete on server zookeeper/172.19.0.2:2181, sessionid = 0x1000183079c0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,845] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,525] INFO Cluster ID = lbUe4hq7QeWfnY0W4R-PhA (kafka.server.KafkaServer)
[35;1mschemaregistry                 |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m 	cache.max.bytes.buffering = 0
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:09,908] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,845] INFO Loading plugin from: /connect-plugins/WikiEditTransformation-3.3.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,529] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[32mcontrol-center                 |[0m 	client.id = 
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[35;1mschemaregistry                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,609] INFO Cluster ID = lbUe4hq7QeWfnY0W4R-PhA (kafka.server.KafkaServer)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,896] INFO Registered loader: PluginClassLoader{pluginLocation=file:/connect-plugins/WikiEditTransformation-3.3.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,727] INFO KafkaConfig values: 
[32mcontrol-center                 |[0m 	commit.interval.ms = 30000
[35;1mschemaregistry                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,612] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[36;1mconnect                        |[0m [2020-05-20 20:05:08,896] INFO Added plugin 'com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	advertised.host.name = null
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[35;1mschemaregistry                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[34mstreams-demo                   |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,811] INFO KafkaConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:08,897] INFO Loading plugin from: /connect-plugins/kafka-connect-transform-nullfilter (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	advertised.listeners = SASL_SSL://kafka2:9092,SASL_SSL_HOST://localhost:29092,PLAINTEXT://kafka2:10092,SSL://kafka2:11092
[32mcontrol-center                 |[0m 	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m 	advertised.host.name = null
[35;1mschemaregistry                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:08,899] INFO Registered loader: PluginClassLoader{pluginLocation=file:/connect-plugins/kafka-connect-transform-nullfilter/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	advertised.port = null
[32mcontrol-center                 |[0m 	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m 	advertised.listeners = SASL_SSL://kafka1:9091,SASL_SSL_HOST://localhost:29091,PLAINTEXT://kafka1:10091,SSL://kafka1:11091
[35;1mschemaregistry                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:08,900] INFO Loading plugin from: /connect-plugins/kafka-connect-irc (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	alter.config.policy.class.name = null
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m 	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
[31;1mkafka1                         |[0m 	advertised.port = null
[35;1mschemaregistry                 |[0m 	transaction.timeout.ms = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:09,127] INFO Registered loader: PluginClassLoader{pluginLocation=file:/connect-plugins/kafka-connect-irc/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mcontrol-center                 |[0m 	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[35;1mschemaregistry                 |[0m 	transactional.id = null
[31;1mkafka1                         |[0m 	alter.config.policy.class.name = null
[36;1mconnect                        |[0m [2020-05-20 20:05:09,127] INFO Added plugin 'com.github.cjmatta.kafka.connect.irc.IrcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
[34;1mkafka2                         |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[34mstreams-demo                   |[0m 	retries = 2147483647
[35;1mschemaregistry                 |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m 	alter.log.dirs.replication.quota.window.num = 11
[36;1mconnect                        |[0m [2020-05-20 20:05:17,100] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
[35;1mschemaregistry                 |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	max.task.idle.ms = 0
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'IrcSourceConnector' and 'IrcSource' to plugin 'com.github.cjmatta.kafka.connect.irc.IrcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	auto.create.topics.enable = false
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:30,128] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'ActiveMQSourceConnector' and 'ActiveMQSource' to plugin 'io.confluent.connect.activemq.ActiveMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	auto.leader.rebalance.enable = true
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:31,436] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'ElasticsearchSinkConnector' and 'ElasticsearchSink' to plugin 'io.confluent.connect.elasticsearch.ElasticsearchSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m 	background.threads = 10
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'IbmMQSourceConnector' and 'IbmMQSource' to plugin 'io.confluent.connect.ibm.mq.IbmMQSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:31,436] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	auto.create.topics.enable = false
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m 	broker.id = 2
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	auto.leader.rebalance.enable = true
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:31,436] INFO Kafka startTimeMs: 1590005071436 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	broker.id.generation.enable = true
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	background.threads = 10
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:31,839] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m 	broker.rack = r1
[32mcontrol-center                 |[0m 	num.standby.replicas = 0
[36;1mconnect                        |[0m [2020-05-20 20:05:17,101] INFO Added aliases 'JmsSourceConnector' and 'JmsSource' to plugin 'io.confluent.connect.jms.JmsSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	broker.id = 1
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:31,927] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[34;1mkafka2                         |[0m 	client.quota.callback.class = null
[32mcontrol-center                 |[0m 	num.stream.threads = 1
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'ReplicatorSourceConnector' and 'ReplicatorSource' to plugin 'io.confluent.connect.replicator.ReplicatorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	broker.id.generation.enable = true
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:31,999] INFO ConsumerConfig values: 
[34;1mkafka2                         |[0m 	compression.type = producer
[32mcontrol-center                 |[0m 	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'S3SinkConnector' and 'S3Sink' to plugin 'io.confluent.connect.s3.S3SinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m 	broker.rack = r1
[35;1mschemaregistry                 |[0m 	allow.auto.create.topics = true
[34;1mkafka2                         |[0m 	connection.failed.authentication.delay.ms = 100
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	poll.ms = 100
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m 	client.quota.callback.class = null
[35;1mschemaregistry                 |[0m 	auto.commit.interval.ms = 5000
[34;1mkafka2                         |[0m 	connections.max.idle.ms = 600000
[34mstreams-demo                   |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	processing.guarantee = at_least_once
[31;1mkafka1                         |[0m 	compression.type = producer
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	connections.max.reauth.ms = 0
[35;1mschemaregistry                 |[0m 	auto.offset.reset = earliest
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m 	connection.failed.authentication.delay.ms = 100
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	control.plane.listener.name = null
[35;1mschemaregistry                 |[0m 	bootstrap.servers = [SASL_SSL://kafka1:9091, SASL_SSL://kafka2:9092]
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m 	connections.max.idle.ms = 600000
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m 	controlled.shutdown.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	check.crcs = true
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	connections.max.reauth.ms = 0
[34;1mkafka2                         |[0m 	controlled.shutdown.max.retries = 3
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[35;1mschemaregistry                 |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m 	control.plane.listener.name = null
[32mcontrol-center                 |[0m 	replication.factor = 1
[34;1mkafka2                         |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[35;1mschemaregistry                 |[0m 	client.id = KafkaStore-reader-_schemas
[36;1mconnect                        |[0m [2020-05-20 20:05:17,102] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m 	controlled.shutdown.enable = true
[32mcontrol-center                 |[0m 	request.timeout.ms = 40000
[34;1mkafka2                         |[0m 	controller.socket.timeout.ms = 30000
[35;1mschemaregistry                 |[0m 	client.rack = 
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	controlled.shutdown.max.retries = 3
[32mcontrol-center                 |[0m 	retries = 2147483647
[35;1mschemaregistry                 |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m 	create.topic.policy.class.name = null
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[35;1mschemaregistry                 |[0m 	default.api.timeout.ms = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m 	default.replication.factor = 1
[32mcontrol-center                 |[0m 	rocksdb.config.setter = null
[31;1mkafka1                         |[0m 	controller.socket.timeout.ms = 30000
[35;1mschemaregistry                 |[0m 	enable.auto.commit = false
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m 	create.topic.policy.class.name = null
[35;1mschemaregistry                 |[0m 	exclude.internal.topics = true
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m 	delegation.token.expiry.time.ms = 86400000
[31;1mkafka1                         |[0m 	default.replication.factor = 1
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[35;1mschemaregistry                 |[0m 	fetch.max.bytes = 52428800
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m 	delegation.token.master.key = null
[31;1mkafka1                         |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[32mcontrol-center                 |[0m 	state.cleanup.delay.ms = 600000
[35;1mschemaregistry                 |[0m 	fetch.max.wait.ms = 500
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mcontrol-center                 |[0m 	state.dir = /var/lib/confluent-control-center/1/cp-command
[31;1mkafka1                         |[0m 	delegation.token.expiry.time.ms = 86400000
[35;1mschemaregistry                 |[0m 	fetch.min.bytes = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mcontrol-center                 |[0m 	topology.optimization = all
[31;1mkafka1                         |[0m 	delegation.token.master.key = null
[35;1mschemaregistry                 |[0m 	group.id = schema-registry-schemaregistry-8085
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	delete.topic.enable = true
[32mcontrol-center                 |[0m 	upgrade.from = null
[31;1mkafka1                         |[0m 	delegation.token.max.lifetime.ms = 604800000
[35;1mschemaregistry                 |[0m 	group.instance.id = null
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mcontrol-center                 |[0m 	windowstore.changelog.additional.retention.ms = 86400000
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m 	delete.records.purgatory.purge.interval.requests = 1
[35;1mschemaregistry                 |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	group.initial.rebalance.delay.ms = 3000
[32mcontrol-center                 |[0m  (org.apache.kafka.streams.StreamsConfig)
[31;1mkafka1                         |[0m 	delete.topic.enable = true
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m 	group.max.session.timeout.ms = 1800000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m [2020-05-20 20:04:27,011] INFO AdminClientConfig values: 
[35;1mschemaregistry                 |[0m 	internal.leave.group.on.close = true
[31;1mkafka1                         |[0m 	fetch.purgatory.purge.interval.requests = 1000
[34;1mkafka2                         |[0m 	group.max.size = 2147483647
[34mstreams-demo                   |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m [2020-05-20 20:05:17,103] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m 	group.initial.rebalance.delay.ms = 3000
[34;1mkafka2                         |[0m 	group.min.session.timeout.ms = 6000
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[35;1mschemaregistry                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m 	group.max.session.timeout.ms = 1800000
[34;1mkafka2                         |[0m 	host.name = 
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-admin
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mschemaregistry                 |[0m 	max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m 	group.max.size = 2147483647
[34;1mkafka2                         |[0m 	inter.broker.listener.name = SASL_SSL
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	max.poll.interval.ms = 300000
[31;1mkafka1                         |[0m 	group.min.session.timeout.ms = 6000
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	inter.broker.protocol.version = 2.3-IV1
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	host.name = 
[35;1mschemaregistry                 |[0m 	max.poll.records = 500
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	kafka.metrics.polling.interval.secs = 10
[31;1mkafka1                         |[0m 	inter.broker.listener.name = SASL_SSL
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	kafka.metrics.reporters = []
[31;1mkafka1                         |[0m 	inter.broker.protocol.version = 2.3-IV1
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added aliases 'WikiEditTransformation' and 'WikiEdit' to plugin 'com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m 	leader.imbalance.check.interval.seconds = 300
[31;1mkafka1                         |[0m 	kafka.metrics.polling.interval.secs = 10
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added alias 'NullFilter' to plugin 'io.confluent.transforms.NullFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	transaction.timeout.ms = 60000
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m 	leader.imbalance.per.broker.percentage = 10
[31;1mkafka1                         |[0m 	kafka.metrics.reporters = []
[36;1mconnect                        |[0m [2020-05-20 20:05:17,104] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	transactional.id = null
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m 	listener.security.protocol.map = SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[31;1mkafka1                         |[0m 	leader.imbalance.check.interval.seconds = 300
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m 	leader.imbalance.per.broker.percentage = 10
[34;1mkafka2                         |[0m 	listeners = SASL_SSL://0.0.0.0:9092,SASL_SSL_HOST://0.0.0.0:29092,PLAINTEXT://0.0.0.0:10092,SSL://0.0.0.0:11092
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added alias 'ConnectSecurityExtension' to plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[31;1mkafka1                         |[0m 	listener.security.protocol.map = SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	log.cleaner.backoff.ms = 15000
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[35;1mschemaregistry                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[34;1mkafka2                         |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[31;1mkafka1                         |[0m 	listeners = SASL_SSL://0.0.0.0:9091,SASL_SSL_HOST://0.0.0.0:29091,PLAINTEXT://0.0.0.0:10091,SSL://0.0.0.0:11091
[32mcontrol-center                 |[0m 	retries = 2147483647
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m 	log.cleaner.delete.retention.ms = 86400000
[31;1mkafka1                         |[0m 	log.cleaner.backoff.ms = 15000
[31;1mkafka1                         |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m 	log.cleaner.enable = true
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m 	log.cleaner.delete.retention.ms = 86400000
[31;1mkafka1                         |[0m 	log.cleaner.enable = true
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:17,105] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[35;1mschemaregistry                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:17,209] INFO DistributedConfig values: 
[35;1mschemaregistry                 |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m 	log.cleaner.io.buffer.size = 524288
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	log.cleaner.io.buffer.size = 524288
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	access.control.allow.methods = 
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m 	access.control.allow.origin = 
[31;1mkafka1                         |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[31;1mkafka1                         |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[31;1mkafka1                         |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[34;1mkafka2                         |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36;1mconnect                        |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m 	client.id = 
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[34;1mkafka2                         |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[31;1mkafka1                         |[0m 	log.cleaner.threads = 1
[36;1mconnect                        |[0m 	config.providers = []
[35;1mschemaregistry                 |[0m 	sasl.jaas.config = [hidden]
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[31;1mkafka1                         |[0m 	log.cleanup.policy = [delete]
[36;1mconnect                        |[0m 	config.storage.replication.factor = 2
[35;1mschemaregistry                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m 	log.cleaner.min.compaction.lag.ms = 0
[31;1mkafka1                         |[0m 	log.dir = /tmp/kafka-logs
[36;1mconnect                        |[0m 	config.storage.topic = connect-configs
[36;1mconnect                        |[0m 	connect.protocol = compatible
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m 	log.dirs = /var/lib/kafka/data
[34;1mkafka2                         |[0m 	log.cleaner.threads = 1
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[35;1mschemaregistry                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m 	log.flush.interval.messages = 9223372036854775807
[31;1mkafka1                         |[0m 	log.flush.interval.ms = null
[34;1mkafka2                         |[0m 	log.cleanup.policy = [delete]
[36;1mconnect                        |[0m 	connector.client.config.override.policy = None
[35;1mschemaregistry                 |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[31;1mkafka1                         |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[34;1mkafka2                         |[0m 	log.dir = /tmp/kafka-logs
[36;1mconnect                        |[0m 	group.id = connect
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35;1mschemaregistry                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[31;1mkafka1                         |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[34;1mkafka2                         |[0m 	log.dirs = /var/lib/kafka/data
[36;1mconnect                        |[0m 	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m 	log.index.interval.bytes = 4096
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005047036
[34;1mkafka2                         |[0m 	log.flush.interval.messages = 9223372036854775807
[34;1mkafka2                         |[0m 	log.flush.interval.ms = null
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	log.index.size.max.bytes = 10485760
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[34;1mkafka2                         |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36;1mconnect                        |[0m 	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m 	log.message.downconversion.enable = true
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m 	log.message.format.version = 2.3-IV1
[34;1mkafka2                         |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Creating consumer client
[36;1mconnect                        |[0m 	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
[35;1mschemaregistry                 |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[34;1mkafka2                         |[0m 	log.index.interval.bytes = 4096
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	log.index.size.max.bytes = 10485760
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m 	log.message.timestamp.type = CreateTime
[36;1mconnect                        |[0m 	key.converter = class org.apache.kafka.connect.storage.StringConverter
[36;1mconnect                        |[0m 	listeners = [https://0.0.0.0:8083]
[34;1mkafka2                         |[0m 	log.message.downconversion.enable = true
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m 	log.preallocate = false
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	log.message.format.version = 2.3-IV1
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	log.retention.bytes = -1
[36;1mconnect                        |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[31;1mkafka1                         |[0m 	log.retention.check.interval.ms = 300000
[35;1mschemaregistry                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[35;1mschemaregistry                 |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m 	allow.auto.create.topics = true
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m 	log.message.timestamp.type = CreateTime
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m 	log.retention.hours = 168
[35;1mschemaregistry                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	auto.commit.interval.ms = 5000
[34mstreams-demo                   |[0m 	auto.offset.reset = earliest
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	log.preallocate = false
[34;1mkafka2                         |[0m 	log.retention.bytes = -1
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	check.crcs = true
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m 	log.retention.minutes = null
[34;1mkafka2                         |[0m 	log.retention.check.interval.ms = 300000
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[35;1mschemaregistry                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m 	log.retention.ms = null
[34;1mkafka2                         |[0m 	log.retention.hours = 168
[36;1mconnect                        |[0m 	offset.flush.interval.ms = 60000
[35;1mschemaregistry                 |[0m 	session.timeout.ms = 10000
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-StreamThread-1-consumer
[34;1mkafka2                         |[0m 	log.retention.minutes = null
[36;1mconnect                        |[0m 	offset.flush.timeout.ms = 5000
[35;1mschemaregistry                 |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m 	client.rack = 
[31;1mkafka1                         |[0m 	log.roll.hours = 168
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	log.retention.ms = null
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[35;1mschemaregistry                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m 	log.roll.jitter.hours = 0
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m 	offset.storage.partitions = 25
[34;1mkafka2                         |[0m 	log.roll.hours = 168
[34mstreams-demo                   |[0m 	default.api.timeout.ms = 60000
[35;1mschemaregistry                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m 	log.roll.jitter.ms = null
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m 	offset.storage.replication.factor = 2
[34;1mkafka2                         |[0m 	log.roll.jitter.hours = 0
[34mstreams-demo                   |[0m 	enable.auto.commit = false
[35;1mschemaregistry                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m 	log.roll.ms = null
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m 	offset.storage.topic = connect-offsets
[34;1mkafka2                         |[0m 	log.roll.jitter.ms = null
[34mstreams-demo                   |[0m 	exclude.internal.topics = true
[35;1mschemaregistry                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m 	log.segment.bytes = 1073741824
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	plugin.path = [/usr/share/java, /connect-plugins]
[34;1mkafka2                         |[0m 	log.roll.ms = null
[34mstreams-demo                   |[0m 	fetch.max.bytes = 52428800
[35;1mschemaregistry                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.schemaregistry.keystore.jks
[31;1mkafka1                         |[0m 	log.segment.delete.delay.ms = 60000
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34;1mkafka2                         |[0m 	log.segment.bytes = 1073741824
[36;1mconnect                        |[0m 	rebalance.timeout.ms = 60000
[34mstreams-demo                   |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m 	max.connections = 2147483647
[35;1mschemaregistry                 |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m 	log.segment.delete.delay.ms = 60000
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[34mstreams-demo                   |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m 	max.connections.per.ip = 2147483647
[35;1mschemaregistry                 |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m 	max.connections = 2147483647
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34mstreams-demo                   |[0m 	group.id = wikipedia-activity-monitor
[31;1mkafka1                         |[0m 	max.connections.per.ip.overrides = 
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m 	max.connections.per.ip = 2147483647
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mcontrol-center                 |[0m [2020-05-20 20:04:28,448] INFO [Producer clientId=confluent-control-center-heartbeat-sender-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[35;1mschemaregistry                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m 	request.timeout.ms = 40000
[34;1mkafka2                         |[0m 	max.connections.per.ip.overrides = 
[34mstreams-demo                   |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m 	message.max.bytes = 1000012
[32mcontrol-center                 |[0m [2020-05-20 20:04:28,507] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[35;1mschemaregistry                 |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m 	rest.advertised.host.name = connect
[34;1mkafka2                         |[0m 	max.incremental.fetch.session.cache.slots = 1000
[34mstreams-demo                   |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[31;1mkafka1                         |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[35;1mschemaregistry                 |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m [2020-05-20 20:04:28,636] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	rest.advertised.listener = null
[34;1mkafka2                         |[0m 	message.max.bytes = 1000012
[34mstreams-demo                   |[0m 	internal.leave.group.on.close = false
[31;1mkafka1                         |[0m 	metrics.num.samples = 2
[35;1mschemaregistry                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.schemaregistry.truststore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:04:28,636] INFO Kafka startTimeMs: 1590005068507 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	rest.advertised.port = null
[34;1mkafka2                         |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[34mstreams-demo                   |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m 	metrics.recording.level = INFO
[35;1mschemaregistry                 |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:04:28,640] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m 	rest.extension.classes = []
[34;1mkafka2                         |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m 	metrics.sample.window.ms = 30000
[35;1mschemaregistry                 |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:28,646] INFO ConsumerConfig values: 
[36;1mconnect                        |[0m 	rest.host.name = null
[34;1mkafka2                         |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m 	min.insync.replicas = 1
[34mstreams-demo                   |[0m 	max.partition.fetch.bytes = 1048576
[35;1mschemaregistry                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[36;1mconnect                        |[0m 	rest.port = 8083
[34;1mkafka2                         |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m 	num.io.threads = 8
[34mstreams-demo                   |[0m 	max.poll.interval.ms = 300000
[35;1mschemaregistry                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m 	min.insync.replicas = 1
[34mstreams-demo                   |[0m 	max.poll.records = 1000
[31;1mkafka1                         |[0m 	num.network.threads = 3
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:32,116] INFO [Producer clientId=producer-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[32mcontrol-center                 |[0m 	auto.offset.reset = none
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m 	num.io.threads = 8
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m 	num.partitions = 1
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,025] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m 	num.network.threads = 3
[31;1mkafka1                         |[0m 	num.recovery.threads.per.data.dir = 1
[34mstreams-demo                   |[0m 	metric.reporters = []
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,028] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	check.crcs = true
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m 	num.partitions = 1
[31;1mkafka1                         |[0m 	num.replica.alter.log.dirs.threads = null
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,028] INFO Kafka startTimeMs: 1590005073025 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	num.recovery.threads.per.data.dir = 1
[31;1mkafka1                         |[0m 	num.replica.fetchers = 1
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-restore-consumer
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,207] INFO [Consumer clientId=KafkaStore-reader-_schemas, groupId=schema-registry-schemaregistry-8085] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m 	num.replica.alter.log.dirs.threads = null
[31;1mkafka1                         |[0m 	offset.metadata.max.bytes = 4096
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	client.rack = 
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,214] INFO [Consumer clientId=KafkaStore-reader-_schemas, groupId=schema-registry-schemaregistry-8085] Subscribed to partition(s): _schemas-0 (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m 	num.replica.fetchers = 1
[31;1mkafka1                         |[0m 	offsets.commit.required.acks = -1
[34mstreams-demo                   |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,219] INFO [Consumer clientId=KafkaStore-reader-_schemas, groupId=schema-registry-schemaregistry-8085] Seeking to EARLIEST offset of partition _schemas-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m 	offset.metadata.max.bytes = 4096
[31;1mkafka1                         |[0m 	offsets.commit.timeout.ms = 5000
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 65536
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,226] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m 	offsets.commit.required.acks = -1
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m 	offsets.load.buffer.size = 5242880
[32mcontrol-center                 |[0m 	enable.auto.commit = false
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,435] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[34;1mkafka2                         |[0m 	offsets.commit.timeout.ms = 5000
[36;1mconnect                        |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m 	offsets.retention.check.interval.ms = 600000
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:33,967] INFO [Consumer clientId=KafkaStore-reader-_schemas, groupId=schema-registry-schemaregistry-8085] Resetting offset for partition _schemas-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m 	offsets.load.buffer.size = 5242880
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:34,105] INFO Wait to catch up until the offset of the last message at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m 	offsets.retention.minutes = 10080
[34;1mkafka2                         |[0m 	offsets.retention.check.interval.ms = 600000
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:34,303] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m 	offsets.topic.compression.codec = 0
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	offsets.retention.minutes = 10080
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:34,926] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[32mcontrol-center                 |[0m 	group.id = null
[31;1mkafka1                         |[0m 	offsets.topic.num.partitions = 50
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	offsets.topic.compression.codec = 0
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:34,928] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m 	offsets.topic.replication.factor = 2
[36;1mconnect                        |[0m 	scheduled.rebalance.max.delay.ms = 300000
[34;1mkafka2                         |[0m 	offsets.topic.num.partitions = 50
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:34,928] INFO Kafka startTimeMs: 1590005074926 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m 	offsets.topic.segment.bytes = 104857600
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m 	offsets.topic.replication.factor = 2
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:35,137] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:35,142] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator kafka2:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m 	offsets.topic.segment.bytes = 104857600
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = false
[31;1mkafka1                         |[0m 	password.encoder.iterations = 4096
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:35,153] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m 	password.encoder.key.length = 128
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:35,453] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m 	password.encoder.iterations = 4096
[31;1mkafka1                         |[0m 	password.encoder.keyfactory.algorithm = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:38,615] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect                        |[0m 	ssl.client.auth = none
[34mstreams-demo                   |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m 	password.encoder.key.length = 128
[31;1mkafka1                         |[0m 	password.encoder.old.secret = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:38,624] INFO Finished rebalance with master election result: Assignment{version=1, error=0, master='sr-1-c8b7a812-56d2-4908-9d8b-9bd1575ad52e', masterIdentity=version=1,host=schemaregistry,port=8085,scheme=https,masterEligibility=true} (io.confluent.kafka.schemaregistry.masterelector.kafka.KafkaGroupMasterElector)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m 	password.encoder.keyfactory.algorithm = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:38,701] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[31;1mkafka1                         |[0m 	password.encoder.secret = null
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	max.poll.records = 1000
[34;1mkafka2                         |[0m 	password.encoder.old.secret = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:39,312] INFO Adding listener: https://0.0.0.0:8085 (io.confluent.rest.Application)
[31;1mkafka1                         |[0m 	port = 9092
[36;1mconnect                        |[0m 	ssl.key.password = null
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	password.encoder.secret = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:40,303] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_212-b04 (org.eclipse.jetty.server.Server)
[31;1mkafka1                         |[0m 	principal.builder.class = null
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	port = 9092
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:40,507] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	producer.purgatory.purge.interval.requests = 1000
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	principal.builder.class = null
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:40,507] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	queued.max.request.bytes = -1
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m 	producer.purgatory.purge.interval.requests = 1000
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m 	queued.max.requests = 500
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:40,509] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m 	queued.max.request.bytes = -1
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m 	quota.consumer.default = 9223372036854775807
[35;1mschemaregistry                 |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34mstreams-demo                   |[0m 	session.timeout.ms = 10000
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34;1mkafka2                         |[0m 	queued.max.requests = 500
[35;1mschemaregistry                 |[0m WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.ConfigResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.ConfigResource will be ignored. 
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	quota.producer.default = 9223372036854775807
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m 	quota.consumer.default = 9223372036854775807
[35;1mschemaregistry                 |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	quota.window.num = 11
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m 	quota.producer.default = 9223372036854775807
[31;1mkafka1                         |[0m 	quota.window.size.seconds = 1
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[35;1mschemaregistry                 |[0m WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.SubjectsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.SubjectsResource will be ignored. 
[34;1mkafka2                         |[0m 	quota.window.num = 11
[31;1mkafka1                         |[0m 	replica.fetch.backoff.ms = 1000
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m 	request.timeout.ms = 960032
[35;1mschemaregistry                 |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m 	quota.window.size.seconds = 1
[31;1mkafka1                         |[0m 	replica.fetch.max.bytes = 1048576
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[35;1mschemaregistry                 |[0m WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.SchemasResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.SchemasResource will be ignored. 
[31;1mkafka1                         |[0m 	replica.fetch.min.bytes = 1
[34;1mkafka2                         |[0m 	replica.fetch.backoff.ms = 1000
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m 	replica.fetch.max.bytes = 1048576
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[35;1mschemaregistry                 |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[31;1mkafka1                         |[0m 	replica.fetch.response.max.bytes = 10485760
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	status.storage.partitions = 5
[34;1mkafka2                         |[0m 	replica.fetch.min.bytes = 1
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	replica.fetch.wait.max.ms = 500
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[35;1mschemaregistry                 |[0m WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.CompatibilityResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.CompatibilityResource will be ignored. 
[36;1mconnect                        |[0m 	status.storage.replication.factor = 2
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[34;1mkafka2                         |[0m 	replica.fetch.response.max.bytes = 10485760
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[36;1mconnect                        |[0m 	status.storage.topic = connect-statuses
[31;1mkafka1                         |[0m 	replica.lag.time.max.ms = 10000
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	replica.fetch.wait.max.ms = 500
[34mstreams-demo                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	replica.socket.receive.buffer.bytes = 65536
[35;1mschemaregistry                 |[0m WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource will be ignored. 
[36;1mconnect                        |[0m 	task.shutdown.graceful.timeout.ms = 5000
[31;1mkafka1                         |[0m 	replica.socket.timeout.ms = 30000
[34;1mkafka2                         |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[35;1mschemaregistry                 |[0m May 20, 2020 8:04:43 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[36;1mconnect                        |[0m 	value.converter = class org.apache.kafka.connect.json.JsonConverter
[31;1mkafka1                         |[0m 	replication.quota.window.num = 11
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m 	replica.lag.time.max.ms = 10000
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mschemaregistry                 |[0m WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.ModeResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.ModeResource will be ignored. 
[36;1mconnect                        |[0m 	worker.sync.timeout.ms = 3000
[31;1mkafka1                         |[0m 	replication.quota.window.size.seconds = 1
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m 	replica.socket.receive.buffer.bytes = 65536
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m 	worker.unsync.backoff.ms = 300000
[31;1mkafka1                         |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:44,327] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[34;1mkafka2                         |[0m 	replica.socket.timeout.ms = 30000
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.distributed.DistributedConfig)
[31;1mkafka1                         |[0m 	reserved.broker.max.id = 1000
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m 	replication.quota.window.num = 11
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:45,528] INFO Started o.e.j.s.ServletContextHandler@658c5a19{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[31;1mkafka1                         |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m 	replication.quota.window.size.seconds = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:17,209] INFO Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig)
[31;1mkafka1                         |[0m 	sasl.enabled.mechanisms = [PLAIN]
[31;1mkafka1                         |[0m 	sasl.jaas.config = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,209] INFO Worker configuration property 'internal.key.converter.schemas.enable' (along with all configuration for 'internal.key.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig)
[31;1mkafka1                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m 	reserved.broker.max.id = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:17,209] INFO Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig)
[31;1mkafka1                         |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:45,610] INFO Started o.e.j.s.ServletContextHandler@6c61a903{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:17,209] INFO Worker configuration property 'internal.value.converter.schemas.enable' (along with all configuration for 'internal.value.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig)
[31;1mkafka1                         |[0m 	sasl.kerberos.service.name = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:46,405] INFO x509=X509@62ddd21b(schemaregistry,h=[schemaregistry, localhost],w=[]) for Server@10ec523c[provider=null,keyStore=file:///etc/kafka/secrets/kafka.schemaregistry.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.schemaregistry.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	sasl.enabled.mechanisms = [PLAIN]
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m [2020-05-20 20:05:17,211] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils)
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:46,406] INFO x509=X509@16c3ca31(caroot,h=[ca1.test.confluent.io],w=[]) for Server@10ec523c[provider=null,keyStore=file:///etc/kafka/secrets/kafka.schemaregistry.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.schemaregistry.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[34;1mkafka2                         |[0m 	sasl.jaas.config = null
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:17,214] INFO AdminClientConfig values: 
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:46,624] INFO Started NetworkTrafficServerConnector@2f666ebb{SSL,[ssl, http/1.1]}{0.0.0.0:8085} (org.eclipse.jetty.server.AbstractConnector)
[34;1mkafka2                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	session.timeout.ms = 60000
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m 	sasl.login.callback.handler.class = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:46,696] INFO Started @25034ms (org.eclipse.jetty.server.Server)
[34;1mkafka2                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m 	sasl.login.class = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:04:46,696] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[34;1mkafka2                         |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	client.id = 
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[35;1mschemaregistry                 |[0m [2020-05-20 20:05:53,911] INFO Wait to catch up until the offset of the last message at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[34;1mkafka2                         |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[31;1mkafka1                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[35;1mschemaregistry                 |[0m [2020-05-20 20:05:54,217] INFO 172.19.0.10 - - [20/May/2020:20:05:52 +0000] "POST /subjects/wikipedia.parsed-value/versions HTTP/1.1" 200 8  2105 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.factor = 0.8
[35;1mschemaregistry                 |[0m [2020-05-20 20:05:55,906] INFO 172.19.0.9 - - [20/May/2020:20:05:55 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  8 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[35;1mschemaregistry                 |[0m [2020-05-20 20:05:56,912] INFO 172.19.0.9 - - [20/May/2020:20:05:56 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  5 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	sasl.mechanism.inter.broker.protocol = PLAIN
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:02,425] INFO 172.19.0.11 - - [20/May/2020:20:06:02 +0000] "POST /compatibility/subjects/WIKIPEDIANOBOT-value/versions/latest HTTP/1.1" 404 51  18 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	sasl.server.callback.handler.class = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:02,911] INFO 172.19.0.11 - - [20/May/2020:20:06:02 +0000] "POST /compatibility/subjects/WIKIPEDIABOT-value/versions/latest HTTP/1.1" 404 51  5 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	security.inter.broker.protocol = PLAINTEXT
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:03,515] INFO 172.19.0.11 - - [20/May/2020:20:06:03 +0000] "POST /compatibility/subjects/EN_WIKIPEDIA_GT_1-value/versions/latest HTTP/1.1" 404 51  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:03,813] INFO 172.19.0.11 - - [20/May/2020:20:06:03 +0000] "POST /compatibility/subjects/EN_WIKIPEDIA_GT_1_COUNTS-value/versions/latest HTTP/1.1" 404 51  4 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	socket.receive.buffer.bytes = 102400
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:12,312] INFO 172.19.0.11 - - [20/May/2020:20:06:12 +0000] "POST /compatibility/subjects/WIKIPEDIANOBOT-value/versions/latest HTTP/1.1" 404 51  5 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:12,503] INFO Wait to catch up until the offset of the last message at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[34;1mkafka2                         |[0m 	sasl.mechanism.inter.broker.protocol = PLAIN
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[36;1mconnect                        |[0m 	retries = 5
[31;1mkafka1                         |[0m 	socket.request.max.bytes = 104857600
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:12,522] INFO 172.19.0.9 - - [20/May/2020:20:06:12 +0000] "POST /subjects/wikipedia.parsed.count-by-channel-value/versions HTTP/1.1" 200 8  22 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	sasl.server.callback.handler.class = null
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	socket.send.buffer.bytes = 102400
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:21,806] INFO 172.19.0.11 - - [20/May/2020:20:06:21 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	security.inter.broker.protocol = PLAINTEXT
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	ssl.cipher.suites = []
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:21,806] INFO 172.19.0.11 - - [20/May/2020:20:06:21 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	socket.receive.buffer.bytes = 102400
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	ssl.client.auth = required
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:21,899] INFO 172.19.0.11 - - [20/May/2020:20:06:21 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	socket.request.max.bytes = 104857600
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:21,899] INFO 172.19.0.11 - - [20/May/2020:20:06:21 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	socket.send.buffer.bytes = 102400
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:22,211] INFO 172.19.0.11 - - [20/May/2020:20:06:22 +0000] "POST /subjects/wikipedia.parsed-value?deleted=true HTTP/1.1" 200 2193  12 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	ssl.cipher.suites = []
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m 	ssl.key.password = [hidden]
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:22,296] INFO 172.19.0.11 - - [20/May/2020:20:06:22 +0000] "POST /subjects/wikipedia.parsed-value?deleted=true HTTP/1.1" 200 2193  97 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m 	ssl.client.auth = required
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005047932
[31;1mkafka1                         |[0m 	ssl.keymanager.algorithm = SunX509
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:22,407] INFO Wait to catch up until the offset of the last message at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,606] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.kafka1.keystore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,607] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:22,504] INFO Wait to catch up until the offset of the last message at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[34;1mkafka2                         |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] State transition from CREATED to REBALANCING
[31;1mkafka1                         |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,607] INFO Kafka startTimeMs: 1590005069606 (org.apache.kafka.common.utils.AppInfoParser)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:22,505] INFO 172.19.0.11 - - [20/May/2020:20:06:22 +0000] "POST /subjects/WIKIPEDIANOBOT-value/versions HTTP/1.1" 200 8  103 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	ssl.key.password = [hidden]
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Starting
[36;1mconnect                        |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,614] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] Creating shared producer client (org.apache.kafka.streams.processor.internals.StreamThread)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:22,505] INFO 172.19.0.11 - - [20/May/2020:20:06:22 +0000] "POST /subjects/WIKIPEDIANOBOT-value/versions HTTP/1.1" 200 8  10 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from CREATED to STARTING
[31;1mkafka1                         |[0m 	ssl.principal.mapping.rules = [DEFAULT]
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,615] INFO ProducerConfig values: 
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:25,619] INFO 172.19.0.11 - - [20/May/2020:20:06:25 +0000] "POST /compatibility/subjects/WIKIPEDIABOT-value/versions/latest HTTP/1.1" 404 51  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.kafka2.keystore.jks
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	acks = all
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Subscribed to pattern: 'wikipedia.parsed'
[31;1mkafka1                         |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	batch.size = 16384
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	ssl.keystore.password = [hidden]
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:26,703] INFO 172.19.0.6 - - [20/May/2020:20:06:26 +0000] "GET /subjects HTTP/1.1" 200 91  208 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	ssl.provider = null
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	ssl.keystore.type = JKS
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:27,827] INFO 172.19.0.6 - - [20/May/2020:20:06:27 +0000] "GET /subjects/wikipedia.parsed-value/versions/latest HTTP/1.1" 200 2193  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m 	buffer.memory = 33554432
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	ssl.principal.mapping.rules = [DEFAULT]
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:28,914] INFO Wait to catch up until the offset of the last message at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[31;1mkafka1                         |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:29,002] INFO 172.19.0.6 - - [20/May/2020:20:06:28 +0000] "POST /subjects/wikipedia.parsed.replica-value/versions HTTP/1.1" 200 8  93 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.kafka1.truststore.jks
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,416] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  6 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-producer
[34;1mkafka2                         |[0m 	ssl.provider = null
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m 	ssl.truststore.password = [hidden]
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,422] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  4 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	compression.type = lz4
[34;1mkafka2                         |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m 	ssl.truststore.type = JKS
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,504] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "POST /subjects/wikipedia.parsed-value?deleted=true HTTP/1.1" 200 2193  4 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	delivery.timeout.ms = 2147483647
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,526] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.kafka2.truststore.jks
[31;1mkafka1                         |[0m 	transaction.max.timeout.ms = 900000
[32mcontrol-center                 |[0m 	enable.idempotence = false
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,600] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.key.password = null
[34;1mkafka2                         |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	interceptor.classes = []
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,703] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "POST /subjects/wikipedia.parsed-value?deleted=true HTTP/1.1" 200 2193  6 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,713] INFO Wait to catch up until the offset of the last message at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[31;1mkafka1                         |[0m 	transaction.state.log.load.buffer.size = 5242880
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[32mcontrol-center                 |[0m 	linger.ms = 500
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,799] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "POST /subjects/WIKIPEDIABOT-value/versions HTTP/1.1" 200 8  89 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	transaction.state.log.min.isr = 2
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	transaction.max.timeout.ms = 900000
[32mcontrol-center                 |[0m 	max.block.ms = 9223372036854775807
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	transaction.state.log.num.partitions = 50
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:34,910] INFO 172.19.0.11 - - [20/May/2020:20:06:34 +0000] "POST /subjects/WIKIPEDIABOT-value/versions HTTP/1.1" 200 8  9 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mcontrol-center                 |[0m 	max.in.flight.requests.per.connection = 5
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	transaction.state.log.replication.factor = 3
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:37,604] INFO 172.19.0.10 - - [20/May/2020:20:06:37 +0000] "GET /schemas/ids/3 HTTP/1.1" 200 925  3 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m 	transaction.state.log.load.buffer.size = 5242880
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	transaction.state.log.segment.bytes = 104857600
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:37,702] INFO 172.19.0.10 - - [20/May/2020:20:06:37 +0000] "GET /schemas/ids/3 HTTP/1.1" 200 925  3 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	transaction.state.log.min.isr = 2
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	transactional.id.expiration.ms = 604800000
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:38,308] INFO 172.19.0.10 - - [20/May/2020:20:06:38 +0000] "POST /subjects/WIKIPEDIABOT-value?deleted=true HTTP/1.1" 200 975  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m 	transaction.state.log.num.partitions = 50
[32mcontrol-center                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	unclean.leader.election.enable = false
[34;1mkafka2                         |[0m 	transaction.state.log.replication.factor = 3
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:40,707] INFO 172.19.0.11 - - [20/May/2020:20:06:40 +0000] "POST /compatibility/subjects/EN_WIKIPEDIA_GT_1-value/versions/latest HTTP/1.1" 404 51  4 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m 	zookeeper.connect = zookeeper:2181
[34;1mkafka2                         |[0m 	transaction.state.log.segment.bytes = 104857600
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:48,006] INFO 172.19.0.10 - - [20/May/2020:20:06:48 +0000] "GET /schemas/ids/3 HTTP/1.1" 200 925  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	zookeeper.connection.timeout.ms = null
[34;1mkafka2                         |[0m 	transactional.id.expiration.ms = 604800000
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:52,808] INFO 172.19.0.11 - - [20/May/2020:20:06:52 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m 	zookeeper.max.in.flight.requests = 10
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m 	unclean.leader.election.enable = false
[31;1mkafka1                         |[0m 	zookeeper.session.timeout.ms = 6000
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:52,899] INFO 172.19.0.11 - - [20/May/2020:20:06:52 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  2 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m 	zookeeper.connect = zookeeper:2181
[31;1mkafka1                         |[0m 	zookeeper.set.acl = true
[36;1mconnect                        |[0m [2020-05-20 20:05:17,499] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:52,910] INFO 172.19.0.11 - - [20/May/2020:20:06:52 +0000] "POST /subjects/wikipedia.parsed-value?deleted=true HTTP/1.1" 200 2193  4 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[34;1mkafka2                         |[0m 	zookeeper.connection.timeout.ms = null
[31;1mkafka1                         |[0m 	zookeeper.sync.time.ms = 2000
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:52,910] INFO 172.19.0.11 - - [20/May/2020:20:06:52 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  2 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	zookeeper.max.in.flight.requests = 10
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m  (kafka.server.KafkaConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:52,998] INFO 172.19.0.11 - - [20/May/2020:20:06:52 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 2139  3 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m 	zookeeper.session.timeout.ms = 6000
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,824] INFO KafkaConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:53,006] INFO 172.19.0.11 - - [20/May/2020:20:06:53 +0000] "POST /subjects/wikipedia.parsed-value?deleted=true HTTP/1.1" 200 2193  5 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	retries = 2147483647
[34;1mkafka2                         |[0m 	zookeeper.set.acl = true
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[31;1mkafka1                         |[0m 	advertised.host.name = null
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:53,009] INFO Wait to catch up until the offset of the last message at 6 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m 	zookeeper.sync.time.ms = 2000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	advertised.listeners = SASL_SSL://kafka1:9091,SASL_SSL_HOST://localhost:29091,PLAINTEXT://kafka1:10091,SSL://kafka1:11091
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:53,094] INFO 172.19.0.11 - - [20/May/2020:20:06:53 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-value/versions HTTP/1.1" 200 8  13 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m  (kafka.server.KafkaConfig)
[34mstreams-demo                   |[0m [kafka-admin-client-thread | wikipedia-activity-monitor-admin] WARN org.apache.kafka.clients.NetworkClient - [AdminClient clientId=wikipedia-activity-monitor-admin] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	advertised.port = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:54,901] INFO 172.19.0.11 - - [20/May/2020:20:06:54 +0000] "GET /schemas/ids/4 HTTP/1.1" 200 377  3 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,800] INFO KafkaConfig values: 
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Connection to node -1 (kafka1/172.19.0.5:9091) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	alter.config.policy.class.name = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:54,903] INFO 172.19.0.11 - - [20/May/2020:20:06:54 +0000] "GET /schemas/ids/4 HTTP/1.1" 200 377  1 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m 	advertised.host.name = null
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Connection to node -2 (kafka2/172.19.0.4:9092) could not be established. Broker may not be available.
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	alter.log.dirs.replication.quota.window.num = 11
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:54,911] INFO 172.19.0.11 - - [20/May/2020:20:06:54 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-value?deleted=true HTTP/1.1" 200 499  3 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	advertised.listeners = SASL_SSL://kafka2:9092,SASL_SSL_HOST://localhost:29092,PLAINTEXT://kafka2:10092,SSL://kafka2:11092
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.clients.Metadata - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:55,021] INFO Wait to catch up until the offset of the last message at 7 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m 	advertised.port = null
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:55,032] INFO 172.19.0.11 - - [20/May/2020:20:06:55 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-value/versions HTTP/1.1" 200 8  13 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m 	alter.config.policy.class.name = null
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null)
[36;1mconnect                        |[0m [2020-05-20 20:05:19,098] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	auto.create.topics.enable = false
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:56,407] INFO 172.19.0.11 - - [20/May/2020:20:06:56 +0000] "GET /schemas/ids/4 HTTP/1.1" 200 377  2 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Revoking previously assigned partitions []
[31;1mkafka1                         |[0m 	auto.leader.rebalance.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:56,411] INFO 172.19.0.11 - - [20/May/2020:20:06:56 +0000] "GET /schemas/ids/4 HTTP/1.1" 200 377  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:56,504] INFO 172.19.0.11 - - [20/May/2020:20:06:56 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-value?deleted=true HTTP/1.1" 200 499  5 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m 	background.threads = 10
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
[35;1mschemaregistry                 |[0m [2020-05-20 20:06:56,598] INFO 172.19.0.11 - - [20/May/2020:20:06:56 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-value/versions HTTP/1.1" 200 8  84 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	broker.id = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	auto.create.topics.enable = false
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:35,109] INFO 172.19.0.11 - - [20/May/2020:20:07:35 +0000] "GET /schemas/ids/5 HTTP/1.1" 200 539  3 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] partition revocation took 1 ms.
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m 	broker.id.generation.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	auto.leader.rebalance.enable = true
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:35,112] INFO 172.19.0.11 - - [20/May/2020:20:07:35 +0000] "GET /schemas/ids/5 HTTP/1.1" 200 539  2 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m 	suspended active tasks: []
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	broker.rack = r1
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	background.threads = 10
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:35,120] INFO 172.19.0.11 - - [20/May/2020:20:07:35 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-value?deleted=true HTTP/1.1" 200 661  3 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m 	suspended standby tasks: []
[31;1mkafka1                         |[0m 	client.quota.callback.class = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	broker.id = 2
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:35,197] INFO Wait to catch up until the offset of the last message at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] (Re-)joining group
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	compression.type = producer
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	broker.id.generation.enable = true
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:35,208] INFO 172.19.0.11 - - [20/May/2020:20:07:35 +0000] "POST /subjects/EN_WIKIPEDIA_GT_1-value/versions HTTP/1.1" 200 8  13 (io.confluent.rest-utils.requests)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] (Re-)joining group
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	connection.failed.authentication.delay.ms = 100
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m 	broker.rack = r1
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:44,092] INFO 172.19.0.11 - - [20/May/2020:20:07:44 +0000] "GET /schemas/ids/5 HTTP/1.1" 200 539  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:44,095] INFO 172.19.0.11 - - [20/May/2020:20:07:44 +0000] "GET /schemas/ids/5 HTTP/1.1" 200 539  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	connections.max.idle.ms = 600000
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m 	client.quota.callback.class = null
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] ERROR org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wikipedia-activity-monitor-StreamThread-1-consumer] Missing source topic wikipedia.parsed durign assignment. Returning error INCOMPLETE_SOURCE_TOPIC_METADATA.
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:44,100] INFO 172.19.0.11 - - [20/May/2020:20:07:44 +0000] "POST /subjects/_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-value?deleted=true HTTP/1.1" 200 661  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	connections.max.reauth.ms = 0
[31;1mkafka1                         |[0m 	control.plane.listener.name = null
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m 	compression.type = producer
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[35;1mschemaregistry                 |[0m [2020-05-20 20:07:44,109] INFO 172.19.0.11 - - [20/May/2020:20:07:44 +0000] "POST /subjects/EN_WIKIPEDIA_GT_1-value/versions HTTP/1.1" 200 8  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m 	controlled.shutdown.enable = true
[31;1mkafka1                         |[0m 	controlled.shutdown.max.retries = 3
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] ERROR org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wikipedia-activity-monitor-StreamThread-1-consumer] wikipedia.parsed is unknown yet during rebalance, please make sure they have been pre-created before starting the Streams application.
[34;1mkafka2                         |[0m 	connection.failed.authentication.delay.ms = 100
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[31;1mkafka1                         |[0m 	controller.socket.timeout.ms = 30000
[34;1mkafka2                         |[0m 	connections.max.idle.ms = 600000
[34;1mkafka2                         |[0m 	connections.max.reauth.ms = 0
[31;1mkafka1                         |[0m 	create.topic.policy.class.name = null
[31;1mkafka1                         |[0m 	default.replication.factor = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	control.plane.listener.name = null
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m 	delegation.token.expiry.time.ms = 86400000
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	controlled.shutdown.enable = true
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Successfully joined group with generation 1
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	delegation.token.master.key = null
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Setting newly assigned partitions: 
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[34;1mkafka2                         |[0m 	controlled.shutdown.max.retries = 3
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] ERROR org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Received error code 1 - shutdown
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	delete.topic.enable = true
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Informed to shut down
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	controller.socket.timeout.ms = 30000
[31;1mkafka1                         |[0m 	fetch.purgatory.purge.interval.requests = 1000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from PARTITIONS_REVOKED to PENDING_SHUTDOWN
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	create.topic.policy.class.name = null
[31;1mkafka1                         |[0m 	group.initial.rebalance.delay.ms = 3000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Shutting down
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	default.replication.factor = 1
[31;1mkafka1                         |[0m 	group.max.session.timeout.ms = 1800000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	group.max.size = 2147483647
[34;1mkafka2                         |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	group.min.session.timeout.ms = 6000
[34;1mkafka2                         |[0m 	delegation.token.expiry.time.ms = 86400000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	host.name = 
[34;1mkafka2                         |[0m 	delegation.token.master.key = null
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] State transition from REBALANCING to ERROR
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	inter.broker.listener.name = SASL_SSL
[34;1mkafka2                         |[0m 	delegation.token.max.lifetime.ms = 604800000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] ERROR org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] All stream threads have died. The instance will be in error state and should be closed.
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	inter.broker.protocol.version = 2.3-IV1
[34;1mkafka2                         |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mcontrol-center                 |[0m 	transaction.timeout.ms = 60000
[31;1mkafka1                         |[0m 	kafka.metrics.polling.interval.secs = 10
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Shutdown complete
[34;1mkafka2                         |[0m 	delete.topic.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	transactional.id = null
[31;1mkafka1                         |[0m 	kafka.metrics.reporters = []
[34mstreams-demo                   |[0m [Thread-2] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] State transition from ERROR to PENDING_SHUTDOWN
[34;1mkafka2                         |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m 	leader.imbalance.check.interval.seconds = 300
[34mstreams-demo                   |[0m [kafka-streams-close-thread] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Informed to shut down
[34;1mkafka2                         |[0m 	group.initial.rebalance.delay.ms = 3000
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	leader.imbalance.per.broker.percentage = 10
[34;1mkafka2                         |[0m 	group.max.session.timeout.ms = 1800000
[34mstreams-demo                   |[0m [kafka-streams-close-thread] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] State transition from PENDING_SHUTDOWN to NOT_RUNNING
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,951] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	listener.security.protocol.map = SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[34mstreams-demo                   |[0m [Thread-2] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] Streams client stopped completely
[34;1mkafka2                         |[0m 	group.max.size = 2147483647
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,951] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	listeners = SASL_SSL://0.0.0.0:9091,SASL_SSL_HOST://0.0.0.0:29091,PLAINTEXT://0.0.0.0:10091,SSL://0.0.0.0:11091
[34;1mkafka2                         |[0m 	group.min.session.timeout.ms = 6000
[34mstreams-demo                   |[0m -Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.control-center.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.control-center.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:29,951] INFO Kafka startTimeMs: 1590005069951 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	log.cleaner.backoff.ms = 15000
[34;1mkafka2                         |[0m 	host.name = 
[34mstreams-demo                   |[0m 
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,006] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[34;1mkafka2                         |[0m 	inter.broker.listener.name = SASL_SSL
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m ALLOW_UNSIGNED=false
[31;1mkafka1                         |[0m 	log.cleaner.delete.retention.ms = 86400000
[34;1mkafka2                         |[0m 	inter.broker.protocol.version = 2.3-IV1
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,008] INFO ConsumerConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m BASH=/bin/bash
[31;1mkafka1                         |[0m 	log.cleaner.enable = true
[34;1mkafka2                         |[0m 	kafka.metrics.polling.interval.secs = 10
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m BASHOPTS=cmdhist:complete_fullquote:extquote:force_fignore:hostcomplete:interactive_comments:progcomp:promptvars:sourcepath
[31;1mkafka1                         |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[34;1mkafka2                         |[0m 	kafka.metrics.reporters = []
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[32mcontrol-center                 |[0m 	auto.offset.reset = none
[31;1mkafka1                         |[0m 	log.cleaner.io.buffer.size = 524288
[34;1mkafka2                         |[0m 	leader.imbalance.check.interval.seconds = 300
[34mstreams-demo                   |[0m BASH_ALIASES=()
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[34;1mkafka2                         |[0m 	leader.imbalance.per.broker.percentage = 10
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m BASH_ARGC=()
[32mcontrol-center                 |[0m 	check.crcs = true
[34;1mkafka2                         |[0m 	listener.security.protocol.map = SASL_SSL:SASL_SSL,SSL:SSL,SASL_SSL_HOST:SASL_SSL,PLAINTEXT:PLAINTEXT
[34mstreams-demo                   |[0m BASH_ARGV=()
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[34;1mkafka2                         |[0m 	listeners = SASL_SSL://0.0.0.0:9092,SASL_SSL_HOST://0.0.0.0:29092,PLAINTEXT://0.0.0.0:10092,SSL://0.0.0.0:11092
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m BASH_CMDS=()
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[34;1mkafka2                         |[0m 	log.cleaner.backoff.ms = 15000
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer
[34mstreams-demo                   |[0m BASH_LINENO=([0]="0")
[34mstreams-demo                   |[0m BASH_SOURCE=([0]="/app/start.sh")
[31;1mkafka1                         |[0m 	log.cleaner.min.compaction.lag.ms = 0
[34;1mkafka2                         |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mcontrol-center                 |[0m 	client.rack = 
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	log.cleaner.delete.retention.ms = 86400000
[31;1mkafka1                         |[0m 	log.cleaner.threads = 1
[34mstreams-demo                   |[0m BASH_VERSINFO=([0]="4" [1]="3" [2]="30" [3]="1" [4]="release" [5]="x86_64-pc-linux-gnu")
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m 	log.cleanup.policy = [delete]
[34;1mkafka2                         |[0m 	log.cleaner.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:19,099] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m BASH_VERSION='4.3.30(1)-release'
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[31;1mkafka1                         |[0m 	log.dir = /tmp/kafka-logs
[34;1mkafka2                         |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36;1mconnect                        |[0m [2020-05-20 20:05:19,100] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m COMPONENT=kafka
[32mcontrol-center                 |[0m 	enable.auto.commit = false
[31;1mkafka1                         |[0m 	log.dirs = /var/lib/kafka/data
[34;1mkafka2                         |[0m 	log.cleaner.io.buffer.size = 524288
[36;1mconnect                        |[0m [2020-05-20 20:05:19,100] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m CONFLUENT_DEB_VERSION=1
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m 	log.flush.interval.messages = 9223372036854775807
[34;1mkafka2                         |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36;1mconnect                        |[0m [2020-05-20 20:05:19,100] INFO Kafka startTimeMs: 1590005119100 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m CONFLUENT_MAJOR_VERSION=5
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[31;1mkafka1                         |[0m 	log.flush.interval.ms = null
[36;1mconnect                        |[0m [2020-05-20 20:05:20,400] INFO Kafka cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.connect.util.ConnectUtils)
[34;1mkafka2                         |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[34mstreams-demo                   |[0m CONFLUENT_MINOR_VERSION=3
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[34;1mkafka2                         |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36;1mconnect                        |[0m [2020-05-20 20:05:20,419] INFO Logging initialized @59947ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[34mstreams-demo                   |[0m CONFLUENT_MVN_LABEL=
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[34;1mkafka2                         |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36;1mconnect                        |[0m [2020-05-20 20:05:20,704] INFO Added connector for https://0.0.0.0:8083 (org.apache.kafka.connect.runtime.rest.RestServer)
[34mstreams-demo                   |[0m CONFLUENT_PATCH_VERSION=0
[32mcontrol-center                 |[0m 	group.id = _confluent-controlcenter-5-3-1-1-command
[31;1mkafka1                         |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[34;1mkafka2                         |[0m 	log.cleaner.threads = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:20,704] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer)
[34mstreams-demo                   |[0m CONFLUENT_PLATFORM_LABEL=
[32mcontrol-center                 |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m 	log.index.interval.bytes = 4096
[34;1mkafka2                         |[0m 	log.cleanup.policy = [delete]
[34mstreams-demo                   |[0m CONFLUENT_VERSION=5.3.0
[36;1mconnect                        |[0m [2020-05-20 20:05:20,712] INFO jetty-9.4.18.v20190429; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_212-b04 (org.eclipse.jetty.server.Server)
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m 	log.index.size.max.bytes = 10485760
[34;1mkafka2                         |[0m 	log.dir = /tmp/kafka-logs
[36;1mconnect                        |[0m [2020-05-20 20:05:21,395] INFO x509=X509@3a230001(connect,h=[connect, localhost],w=[]) for Server@5ac6c4f2[provider=null,keyStore=file:///etc/kafka/secrets/kafka.connect.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.connect.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[34mstreams-demo                   |[0m CUB_CLASSPATH=/etc/confluent/docker/docker-utils.jar
[32mcontrol-center                 |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m 	log.dirs = /var/lib/kafka/data
[31;1mkafka1                         |[0m 	log.message.downconversion.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:21,397] INFO x509=X509@2aa6311a(caroot,h=[ca1.test.confluent.io],w=[]) for Server@5ac6c4f2[provider=null,keyStore=file:///etc/kafka/secrets/kafka.connect.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.connect.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[34mstreams-demo                   |[0m DIRSTACK=()
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = false
[34;1mkafka2                         |[0m 	log.flush.interval.messages = 9223372036854775807
[31;1mkafka1                         |[0m 	log.message.format.version = 2.3-IV1
[36;1mconnect                        |[0m [2020-05-20 20:05:21,620] INFO Started https_0.0.0.08083@184fb68d{SSL,[ssl, http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector)
[34mstreams-demo                   |[0m EUID=0
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[34;1mkafka2                         |[0m 	log.flush.interval.ms = null
[36;1mconnect                        |[0m [2020-05-20 20:05:21,694] INFO Started @61149ms (org.eclipse.jetty.server.Server)
[31;1mkafka1                         |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[34mstreams-demo                   |[0m GROUPS=()
[34;1mkafka2                         |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m 	log.message.timestamp.type = CreateTime
[34mstreams-demo                   |[0m HOME=/root
[36;1mconnect                        |[0m [2020-05-20 20:05:21,716] INFO Advertised URI: https://connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[34;1mkafka2                         |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m 	log.preallocate = false
[31;1mkafka1                         |[0m 	log.retention.bytes = -1
[36;1mconnect                        |[0m [2020-05-20 20:05:21,717] INFO REST server listening at https://0.0.0.0:8083/, advertising URL https://connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[34;1mkafka2                         |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 300000
[31;1mkafka1                         |[0m 	log.retention.check.interval.ms = 300000
[34mstreams-demo                   |[0m HOSTNAME=streams-demo
[36;1mconnect                        |[0m [2020-05-20 20:05:21,717] INFO Advertised URI: https://connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[31;1mkafka1                         |[0m 	log.retention.hours = 168
[34mstreams-demo                   |[0m HOSTTYPE=x86_64
[36;1mconnect                        |[0m [2020-05-20 20:05:21,722] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy)
[34;1mkafka2                         |[0m 	log.index.interval.bytes = 4096
[32mcontrol-center                 |[0m 	max.poll.records = 1000
[31;1mkafka1                         |[0m 	log.retention.minutes = null
[36;1mconnect                        |[0m [2020-05-20 20:05:21,800] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m IFS=$' \t\n'
[34;1mkafka2                         |[0m 	log.index.size.max.bytes = 10485760
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m 	log.retention.ms = null
[36;1mconnect                        |[0m [2020-05-20 20:05:21,801] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m JAVA_OPTS='-Djavax.net.ssl.trustStore=/etc/kafka/secrets/kafka.control-center.truststore.jks -Djavax.net.ssl.trustStorePassword=confluent -Djavax.net.ssl.keyStore=/etc/kafka/secrets/kafka.control-center.keystore.jks -Djavax.net.ssl.keyStorePassword=confluent'
[34;1mkafka2                         |[0m 	log.message.downconversion.enable = true
[31;1mkafka1                         |[0m 	log.roll.hours = 168
[32mcontrol-center                 |[0m 	metric.reporters = []
[36;1mconnect                        |[0m [2020-05-20 20:05:21,801] INFO Kafka startTimeMs: 1590005121800 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m KAFKA_ADVERTISED_LISTENERS=
[31;1mkafka1                         |[0m 	log.roll.jitter.hours = 0
[34;1mkafka2                         |[0m 	log.message.format.version = 2.3-IV1
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m [2020-05-20 20:05:22,032] INFO JsonConverterConfig values: 
[34mstreams-demo                   |[0m KAFKA_BOOTSTRAP_SERVERS=kafka1:9091,kafka2:9092
[31;1mkafka1                         |[0m 	log.roll.jitter.ms = null
[34;1mkafka2                         |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	converter.type = key
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG='org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'
[31;1mkafka1                         |[0m 	log.roll.ms = null
[34;1mkafka2                         |[0m 	log.message.timestamp.type = CreateTime
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m 	schemas.cache.size = 1000
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[34;1mkafka2                         |[0m 	log.preallocate = false
[31;1mkafka1                         |[0m 	log.segment.bytes = 1073741824
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
[36;1mconnect                        |[0m 	schemas.enable = false
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=SASL_SSL
[34;1mkafka2                         |[0m 	log.retention.bytes = -1
[31;1mkafka1                         |[0m 	log.segment.delete.delay.ms = 60000
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[36;1mconnect                        |[0m  (org.apache.kafka.connect.json.JsonConverterConfig)
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m 	log.retention.check.interval.ms = 300000
[31;1mkafka1                         |[0m 	max.connections = 2147483647
[36;1mconnect                        |[0m [2020-05-20 20:05:22,033] INFO JsonConverterConfig values: 
[34;1mkafka2                         |[0m 	log.retention.hours = 168
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_PASSWORD=confluent
[31;1mkafka1                         |[0m 	max.connections.per.ip = 2147483647
[36;1mconnect                        |[0m 	converter.type = value
[34;1mkafka2                         |[0m 	log.retention.minutes = null
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEY_PASSWORD=confluent
[36;1mconnect                        |[0m 	schemas.cache.size = 1000
[31;1mkafka1                         |[0m 	max.connections.per.ip.overrides = 
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[32mcontrol-center                 |[0m 	request.timeout.ms = 960032
[34;1mkafka2                         |[0m 	log.retention.ms = null
[36;1mconnect                        |[0m 	schemas.enable = false
[31;1mkafka1                         |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m  (org.apache.kafka.connect.json.JsonConverterConfig)
[34mstreams-demo                   |[0m KAFKA_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_PASSWORD=confluent
[34;1mkafka2                         |[0m 	log.roll.hours = 168
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m 	message.max.bytes = 1000012
[34mstreams-demo                   |[0m KAFKA_CONSUMER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
[34;1mkafka2                         |[0m 	log.roll.jitter.hours = 0
[36;1mconnect                        |[0m [2020-05-20 20:05:22,103] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[34;1mkafka2                         |[0m 	log.roll.jitter.ms = null
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_JAAS_CONFIG='org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'
[36;1mconnect                        |[0m [2020-05-20 20:05:22,533] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	log.roll.ms = null
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SASL_MECHANISM=PLAIN
[36;1mconnect                        |[0m [2020-05-20 20:05:22,533] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m 	log.segment.bytes = 1073741824
[36;1mconnect                        |[0m [2020-05-20 20:05:22,533] INFO Kafka startTimeMs: 1590005122533 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SECURITY_PROTOCOL=SASL_SSL
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m 	log.segment.delete.delay.ms = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:22,536] INFO Kafka Connect distributed worker initialization took 60928ms (org.apache.kafka.connect.cli.ConnectDistributed)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.keystore.jks
[31;1mkafka1                         |[0m 	min.insync.replicas = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:22,536] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEYSTORE_PASSWORD=confluent
[34;1mkafka2                         |[0m 	max.connections = 2147483647
[31;1mkafka1                         |[0m 	num.io.threads = 8
[36;1mconnect                        |[0m [2020-05-20 20:05:22,536] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_KEY_PASSWORD=confluent
[34;1mkafka2                         |[0m 	max.connections.per.ip = 2147483647
[31;1mkafka1                         |[0m 	num.network.threads = 3
[32mcontrol-center                 |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:22,536] INFO [Worker clientId=connect-1, groupId=connect] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m 	num.partitions = 1
[34;1mkafka2                         |[0m 	max.connections.per.ip.overrides = 
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m [2020-05-20 20:05:22,537] INFO Worker starting (org.apache.kafka.connect.runtime.Worker)
[34mstreams-demo                   |[0m KAFKA_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_SSL_TRUSTSTORE_PASSWORD=confluent
[31;1mkafka1                         |[0m 	num.recovery.threads.per.data.dir = 1
[34;1mkafka2                         |[0m 	max.incremental.fetch.session.cache.slots = 1000
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m 	num.replica.alter.log.dirs.threads = null
[36;1mconnect                        |[0m [2020-05-20 20:05:22,537] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
[34;1mkafka2                         |[0m 	message.max.bytes = 1000012
[34mstreams-demo                   |[0m KAFKA_PRODUCER_INTERCEPTOR_CLASSES=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	num.replica.fetchers = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:22,537] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog)
[34;1mkafka2                         |[0m 	metric.reporters = [io.confluent.metrics.reporter.ConfluentMetricsReporter]
[34mstreams-demo                   |[0m KAFKA_SASL_JAAS_CONFIG='org.apache.kafka.common.security.plain.PlainLoginModule required username="client" password="client-secret";'
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m 	offset.metadata.max.bytes = 4096
[36;1mconnect                        |[0m [2020-05-20 20:05:22,537] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m 	offsets.commit.required.acks = -1
[34mstreams-demo                   |[0m KAFKA_SASL_MECHANISM=PLAIN
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m 	offsets.commit.timeout.ms = 5000
[34mstreams-demo                   |[0m KAFKA_SCHEMA_REGISTRY_URL=https://schemaregistry:8085
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m KAFKA_SECURITY_PROTOCOL=SASL_SSL
[36;1mconnect                        |[0m 	client.id = 
[31;1mkafka1                         |[0m 	offsets.load.buffer.size = 5242880
[32mcontrol-center                 |[0m 	session.timeout.ms = 60000
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[34;1mkafka2                         |[0m 	min.insync.replicas = 1
[34mstreams-demo                   |[0m KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM=HTTPS
[31;1mkafka1                         |[0m 	offsets.retention.check.interval.ms = 600000
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	num.io.threads = 8
[34mstreams-demo                   |[0m KAFKA_SSL_KEYSTORE_LOCATION=/etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m 	offsets.retention.minutes = 10080
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	num.network.threads = 3
[34mstreams-demo                   |[0m KAFKA_SSL_KEYSTORE_PASSWORD=confluent
[31;1mkafka1                         |[0m 	offsets.topic.compression.codec = 0
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	num.partitions = 1
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m KAFKA_SSL_KEY_PASSWORD=confluent
[31;1mkafka1                         |[0m 	offsets.topic.num.partitions = 50
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	num.recovery.threads.per.data.dir = 1
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m KAFKA_SSL_TRUSTSTORE_LOCATION=/etc/kafka/secrets/kafka.client.truststore.jks
[31;1mkafka1                         |[0m 	offsets.topic.replication.factor = 2
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[34;1mkafka2                         |[0m 	num.replica.alter.log.dirs.threads = null
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34mstreams-demo                   |[0m KAFKA_SSL_TRUSTSTORE_PASSWORD=confluent
[31;1mkafka1                         |[0m 	offsets.topic.segment.bytes = 104857600
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m KAFKA_VERSION=5.3.0
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	num.replica.fetchers = 1
[31;1mkafka1                         |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m KAFKA_ZOOKEEPER_CONNECT=
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m 	offset.metadata.max.bytes = 4096
[31;1mkafka1                         |[0m 	password.encoder.iterations = 4096
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[34mstreams-demo                   |[0m LANG=C.UTF-8
[32mcontrol-center                 |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m 	offsets.commit.required.acks = -1
[34mstreams-demo                   |[0m MACHTYPE=x86_64-pc-linux-gnu
[31;1mkafka1                         |[0m 	password.encoder.key.length = 128
[36;1mconnect                        |[0m 	retries = 5
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34mstreams-demo                   |[0m OPTERR=1
[31;1mkafka1                         |[0m 	password.encoder.keyfactory.algorithm = null
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m OPTIND=1
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	password.encoder.old.secret = null
[34;1mkafka2                         |[0m 	offsets.commit.timeout.ms = 5000
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34mstreams-demo                   |[0m OSTYPE=linux-gnu
[31;1mkafka1                         |[0m 	password.encoder.secret = null
[34;1mkafka2                         |[0m 	offsets.load.buffer.size = 5242880
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	port = 9092
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m 	offsets.retention.check.interval.ms = 600000
[34mstreams-demo                   |[0m PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	principal.builder.class = null
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m 	offsets.retention.minutes = 10080
[34mstreams-demo                   |[0m PIPESTATUS=([0]="0")
[31;1mkafka1                         |[0m 	producer.purgatory.purge.interval.requests = 1000
[31;1mkafka1                         |[0m 	queued.max.request.bytes = -1
[34;1mkafka2                         |[0m 	offsets.topic.compression.codec = 0
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m 	queued.max.requests = 500
[34mstreams-demo                   |[0m PPID=0
[34;1mkafka2                         |[0m 	offsets.topic.num.partitions = 50
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,205] INFO [Producer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[31;1mkafka1                         |[0m 	quota.consumer.default = 9223372036854775807
[34mstreams-demo                   |[0m PS4='+ '
[34;1mkafka2                         |[0m 	offsets.topic.replication.factor = 2
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,539] WARN The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m 	quota.producer.default = 9223372036854775807
[34mstreams-demo                   |[0m PWD=/
[34;1mkafka2                         |[0m 	offsets.topic.segment.bytes = 104857600
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,540] WARN The configuration 'admin.retries' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m 	quota.window.num = 11
[34mstreams-demo                   |[0m PYTHON_PIP_VERSION=8.1.2
[34;1mkafka2                         |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,541] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m PYTHON_VERSION=2.7.9-1
[31;1mkafka1                         |[0m 	quota.window.size.seconds = 1
[34;1mkafka2                         |[0m 	password.encoder.iterations = 4096
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,541] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m 	replica.fetch.backoff.ms = 1000
[34mstreams-demo                   |[0m SCALA_VERSION=2.12
[34;1mkafka2                         |[0m 	password.encoder.key.length = 128
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	replica.fetch.max.bytes = 1048576
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,541] INFO Kafka startTimeMs: 1590005070540 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m SHELL=/bin/bash
[34;1mkafka2                         |[0m 	password.encoder.keyfactory.algorithm = null
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,546] INFO ProducerConfig values: 
[31;1mkafka1                         |[0m 	replica.fetch.min.bytes = 1
[34mstreams-demo                   |[0m SHELLOPTS=braceexpand:hashall:interactive-comments
[34;1mkafka2                         |[0m 	password.encoder.old.secret = null
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	replica.fetch.response.max.bytes = 10485760
[32mcontrol-center                 |[0m 	acks = all
[34mstreams-demo                   |[0m SHLVL=1
[34;1mkafka2                         |[0m 	password.encoder.secret = null
[31;1mkafka1                         |[0m 	replica.fetch.wait.max.ms = 500
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	batch.size = 16384
[34mstreams-demo                   |[0m TERM=dumb
[34;1mkafka2                         |[0m 	port = 9092
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34mstreams-demo                   |[0m UID=0
[34;1mkafka2                         |[0m 	principal.builder.class = null
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m 	replica.lag.time.max.ms = 10000
[32mcontrol-center                 |[0m 	buffer.memory = 33554432
[34mstreams-demo                   |[0m ZULU_OPENJDK_VERSION=8=8.38.0.13
[34;1mkafka2                         |[0m 	producer.purgatory.purge.interval.requests = 1000
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m _=echo
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m 	queued.max.request.bytes = -1
[31;1mkafka1                         |[0m 	replica.socket.receive.buffer.bytes = 65536
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m [main] INFO io.confluent.kafka.serializers.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
[32mcontrol-center                 |[0m 	client.id = c3-command
[34;1mkafka2                         |[0m 	queued.max.requests = 500
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m 	compression.type = lz4
[34;1mkafka2                         |[0m 	quota.consumer.default = 9223372036854775807
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m 	ssl.key.password = null
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m 	quota.producer.default = 9223372036854775807
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[31;1mkafka1                         |[0m 	replica.socket.timeout.ms = 30000
[32mcontrol-center                 |[0m 	delivery.timeout.ms = 2147483647
[34;1mkafka2                         |[0m 	quota.window.num = 11
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m 	replication.quota.window.num = 11
[34;1mkafka2                         |[0m 	quota.window.size.seconds = 1
[34;1mkafka2                         |[0m 	replica.fetch.backoff.ms = 1000
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m 	replica.fetch.max.bytes = 1048576
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	replica.fetch.min.bytes = 1
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m 	replication.quota.window.size.seconds = 1
[32mcontrol-center                 |[0m 	key.serializer = class io.confluent.serializers.ProtoSerde
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m 	replica.fetch.response.max.bytes = 10485760
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[31;1mkafka1                         |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m 	linger.ms = 500
[34;1mkafka2                         |[0m 	replica.fetch.wait.max.ms = 500
[36;1mconnect                        |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	reserved.broker.max.id = 1000
[32mcontrol-center                 |[0m 	max.block.ms = 9223372036854775807
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m 	replica.lag.time.max.ms = 10000
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m 	sasl.enabled.mechanisms = [PLAIN]
[34;1mkafka2                         |[0m 	replica.socket.receive.buffer.bytes = 65536
[34mstreams-demo                   |[0m [main] INFO io.confluent.kafka.serializers.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
[32mcontrol-center                 |[0m 	max.request.size = 10485760
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	sasl.jaas.config = null
[34;1mkafka2                         |[0m 	replica.socket.timeout.ms = 30000
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m 	replication.quota.window.num = 11
[32mcontrol-center                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m 	replication.quota.window.size.seconds = 1
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[34;1mkafka2                         |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,195] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[34;1mkafka2                         |[0m 	reserved.broker.max.id = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,195] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:23,197] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m 	sasl.enabled.mechanisms = [PLAIN]
[36;1mconnect                        |[0m [2020-05-20 20:05:23,802] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m 	sasl.jaas.config = null
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[34;1mkafka2                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	specific.avro.reader = true
[34;1mkafka2                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m 	retries = 2147483647
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.factor = 0.8
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.StreamsConfig - StreamsConfig values: 
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m 	sasl.mechanism.inter.broker.protocol = PLAIN
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	application.id = wikipedia-activity-monitor
[34;1mkafka2                         |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	sasl.server.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	application.server = 
[34;1mkafka2                         |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	security.inter.broker.protocol = PLAINTEXT
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	socket.receive.buffer.bytes = 102400
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	socket.request.max.bytes = 104857600
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m 	buffered.records.per.partition = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	socket.send.buffer.bytes = 102400
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m 	cache.max.bytes.buffering = 10485760
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.cipher.suites = []
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.client.auth = required
[34;1mkafka2                         |[0m 	sasl.mechanism.inter.broker.protocol = PLAIN
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m 	commit.interval.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m 	sasl.server.callback.handler.class = null
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m 	security.inter.broker.protocol = PLAINTEXT
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m 	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
[34;1mkafka2                         |[0m 	socket.receive.buffer.bytes = 102400
[34;1mkafka2                         |[0m 	socket.request.max.bytes = 104857600
[34;1mkafka2                         |[0m 	socket.send.buffer.bytes = 102400
[34;1mkafka2                         |[0m 	ssl.cipher.suites = []
[34;1mkafka2                         |[0m 	ssl.client.auth = required
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.kafka1.keystore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m 	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m 	ssl.keystore.type = JKS
[34mstreams-demo                   |[0m 	default.value.serde = class io.confluent.kafka.streams.serdes.avro.GenericAvroSerde
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	max.task.idle.ms = 0
[31;1mkafka1                         |[0m 	ssl.principal.mapping.rules = [DEFAULT]
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.kafka2.keystore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m 	ssl.principal.mapping.rules = [DEFAULT]
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.kafka1.truststore.jks
[34mstreams-demo                   |[0m 	num.standby.replicas = 0
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m 	ssl.truststore.password = [hidden]
[34mstreams-demo                   |[0m 	num.stream.threads = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m 	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
[34;1mkafka2                         |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34mstreams-demo                   |[0m 	poll.ms = 100
[34;1mkafka2                         |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m 	transaction.max.timeout.ms = 900000
[34mstreams-demo                   |[0m 	processing.guarantee = at_least_once
[34;1mkafka2                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.kafka2.truststore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:23,803] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 32768
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	transaction.state.log.load.buffer.size = 5242880
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	transaction.state.log.min.isr = 2
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m 	transaction.state.log.num.partitions = 50
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	replication.factor = 1
[34;1mkafka2                         |[0m 	transaction.max.timeout.ms = 900000
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	transaction.state.log.replication.factor = 3
[34mstreams-demo                   |[0m 	request.timeout.ms = 40000
[34;1mkafka2                         |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m 	transaction.state.log.segment.bytes = 104857600
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	retries = 0
[34;1mkafka2                         |[0m 	transaction.state.log.load.buffer.size = 5242880
[32mcontrol-center                 |[0m 	transaction.timeout.ms = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	transactional.id.expiration.ms = 604800000
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m 	transaction.state.log.min.isr = 2
[32mcontrol-center                 |[0m 	transactional.id = null
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	rocksdb.config.setter = null
[34;1mkafka2                         |[0m 	transaction.state.log.num.partitions = 50
[31;1mkafka1                         |[0m 	unclean.leader.election.enable = false
[32mcontrol-center                 |[0m 	value.serializer = class io.confluent.serializers.ProtoSerde
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m 	zookeeper.connect = zookeeper:2181
[34;1mkafka2                         |[0m 	transaction.state.log.replication.factor = 3
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m 	zookeeper.connection.timeout.ms = null
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	transaction.state.log.segment.bytes = 104857600
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	state.cleanup.delay.ms = 600000
[31;1mkafka1                         |[0m 	zookeeper.max.in.flight.requests = 10
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,952] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	transactional.id.expiration.ms = 604800000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	state.dir = /tmp/confluent8669268115094932419
[31;1mkafka1                         |[0m 	zookeeper.session.timeout.ms = 6000
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,952] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	unclean.leader.election.enable = false
[34mstreams-demo                   |[0m 	topology.optimization = none
[31;1mkafka1                         |[0m 	zookeeper.set.acl = true
[32mcontrol-center                 |[0m [2020-05-20 20:04:30,952] INFO Kafka startTimeMs: 1590005070952 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m 	zookeeper.connect = zookeeper:2181
[34mstreams-demo                   |[0m 	upgrade.from = null
[31;1mkafka1                         |[0m 	zookeeper.sync.time.ms = 2000
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,029] INFO RestConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	windowstore.changelog.additional.retention.ms = 86400000
[31;1mkafka1                         |[0m  (kafka.server.KafkaConfig)
[34;1mkafka2                         |[0m 	zookeeper.connection.timeout.ms = null
[32mcontrol-center                 |[0m 	access.control.allow.headers = 
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,915] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[34;1mkafka2                         |[0m 	zookeeper.max.in.flight.requests = 10
[32mcontrol-center                 |[0m 	access.control.allow.methods = 
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,915] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
[34;1mkafka2                         |[0m 	zookeeper.session.timeout.ms = 6000
[32mcontrol-center                 |[0m 	access.control.allow.origin = 
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,916] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	zookeeper.set.acl = true
[32mcontrol-center                 |[0m 	authentication.method = NONE
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:10,946] INFO Loading logs. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m 	zookeeper.sync.time.ms = 2000
[32mcontrol-center                 |[0m 	authentication.realm = 
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:11,001] INFO Logs loading complete in 55 ms. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-admin
[34;1mkafka2                         |[0m  (kafka.server.KafkaConfig)
[32mcontrol-center                 |[0m 	authentication.roles = [*]
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:11,017] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,832] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[32mcontrol-center                 |[0m 	authentication.skip.paths = []
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 300000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,832] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:11,020] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	compression.enable = true
[36;1mconnect                        |[0m [2020-05-20 20:05:23,804] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,833] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	debug = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:11,024] INFO Starting the log cleaner (kafka.log.LogCleaner)
[36;1mconnect                        |[0m [2020-05-20 20:05:23,894] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,917] INFO Loading logs. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:11,218] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
[32mcontrol-center                 |[0m 	idle.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:23,895] INFO Kafka startTimeMs: 1590005123804 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,926] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:12,025] INFO Awaiting socket connections on 0.0.0.0:9091. (kafka.network.Acceptor)
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	listeners = [http://0.0.0.0:9021, https://0.0.0.0:9022]
[36;1mconnect                        |[0m [2020-05-20 20:05:24,997] INFO Created topic (name=connect-offsets, numPartitions=25, replicationFactor=2, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at kafka1:9091,kafka2:9092 (org.apache.kafka.connect.util.TopicAdmin)
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,941] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:12,044] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[32mcontrol-center                 |[0m 	metric.reporters = []
[36;1mconnect                        |[0m [2020-05-20 20:05:25,096] INFO ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:10,995] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:15,097] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9091,ListenerName(SASL_SSL),SASL_SSL) (kafka.network.SocketServer)
[32mcontrol-center                 |[0m 	metrics.jmx.prefix = rest-utils
[36;1mconnect                        |[0m 	acks = all
[34;1mkafka2                         |[0m [2020-05-20 20:04:11,006] INFO Starting the log cleaner (kafka.log.LogCleaner)
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:15,101] INFO Awaiting socket connections on 0.0.0.0:29091. (kafka.network.Acceptor)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	batch.size = 16384
[34;1mkafka2                         |[0m [2020-05-20 20:04:11,156] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:16,211] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,29091,ListenerName(SASL_SSL_HOST),SASL_SSL) (kafka.network.SocketServer)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:11,929] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:16,211] INFO Awaiting socket connections on 0.0.0.0:10091. (kafka.network.Acceptor)
[32mcontrol-center                 |[0m 	metrics.tag.map = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:12,018] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[34mstreams-demo                   |[0m 	request.timeout.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:04:16,221] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,10091,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[32mcontrol-center                 |[0m 	port = 9021
[34;1mkafka2                         |[0m [2020-05-20 20:04:14,905] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(SASL_SSL),SASL_SSL) (kafka.network.SocketServer)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:16,221] INFO Awaiting socket connections on 0.0.0.0:11091. (kafka.network.Acceptor)
[34mstreams-demo                   |[0m 	retries = 5
[34;1mkafka2                         |[0m [2020-05-20 20:04:14,907] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.Acceptor)
[32mcontrol-center                 |[0m 	request.logger.name = io.confluent.rest-utils.requests
[36;1mconnect                        |[0m 	client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,230] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,11091,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:16,030] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,29092,ListenerName(SASL_SSL_HOST),SASL_SSL) (kafka.network.SocketServer)
[36;1mconnect                        |[0m 	compression.type = none
[32mcontrol-center                 |[0m 	resource.extension.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,232] INFO [SocketServer brokerId=1] Started 4 acceptor threads for data-plane (kafka.network.SocketServer)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:16,031] INFO Awaiting socket connections on 0.0.0.0:10092. (kafka.network.Acceptor)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[32mcontrol-center                 |[0m 	response.mediatype.default = application/json
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,300] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:16,040] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,10092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[32mcontrol-center                 |[0m 	response.mediatype.preferred = [application/json]
[36;1mconnect                        |[0m 	delivery.timeout.ms = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,300] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:16,040] INFO Awaiting socket connections on 0.0.0.0:11092. (kafka.network.Acceptor)
[32mcontrol-center                 |[0m 	rest.servlet.initializor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,301] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,034] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,11092,ListenerName(SSL),SSL) (kafka.network.SocketServer)
[36;1mconnect                        |[0m 	enable.idempotence = false
[32mcontrol-center                 |[0m 	shutdown.graceful.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,301] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,036] INFO [SocketServer brokerId=2] Started 4 acceptor threads for data-plane (kafka.network.SocketServer)
[36;1mconnect                        |[0m 	interceptor.classes = []
[32mcontrol-center                 |[0m 	ssl.cipher.suites = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,318] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,098] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mcontrol-center                 |[0m 	ssl.client.auth = false
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,414] INFO Creating /brokers/ids/1 (is it secure? true) (kafka.zk.KafkaZkClient)
[36;1mconnect                        |[0m 	linger.ms = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,099] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mcontrol-center                 |[0m 	ssl.client.authentication = NONE
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,441] INFO Stat of the created znode at /brokers/ids/1 is: 46,46,1590005057430,1590005057430,1,0,0,72059256317935619,339,0,46
[36;1mconnect                        |[0m 	max.block.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,112] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = []
[34mstreams-demo                   |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m  (kafka.zk.KafkaZkClient)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,113] INFO [ExpirationReaper-2-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,442] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka1,9091,ListenerName(SASL_SSL),SASL_SSL), EndPoint(localhost,29091,ListenerName(SASL_SSL_HOST),SASL_SSL), EndPoint(kafka1,10091,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka1,11091,ListenerName(SSL),SSL)), czxid (broker epoch): 46 (kafka.zk.KafkaZkClient)
[36;1mconnect                        |[0m 	max.request.size = 1048576
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,198] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,444] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,221] INFO Creating /brokers/ids/2 (is it secure? true) (kafka.zk.KafkaZkClient)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,551] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[36;1mconnect                        |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,242] INFO Stat of the created znode at /brokers/ids/2 is: 43,43,1590005057234,1590005057234,1,0,0,72059256317935618,339,0,43
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,624] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m  (kafka.zk.KafkaZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,635] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,242] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(kafka2,9092,ListenerName(SASL_SSL),SASL_SSL), EndPoint(localhost,29092,ListenerName(SASL_SSL_HOST),SASL_SSL), EndPoint(kafka2,10092,ListenerName(PLAINTEXT),PLAINTEXT), EndPoint(kafka2,11092,ListenerName(SSL),SSL)), czxid (broker epoch): 43 (kafka.zk.KafkaZkClient)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,636] DEBUG [Controller id=1] Broker 2 has been elected as the controller, so stopping the election process. (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,244] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,636] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,331] INFO [ControllerEventThread controllerId=2] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,646] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m 	ssl.provider = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,337] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,647] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,340] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,652] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,341] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:17,710] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,417] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	retries = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,056] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,418] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,058] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	websocket.path.prefix = /ws
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,420] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,095] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m 	websocket.servlet.initializor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,430] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,198] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[32mcontrol-center                 |[0m  (io.confluent.rest.RestConfig)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,436] INFO [Controller id=2] 2 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,198] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@52500920 (org.apache.zookeeper.ZooKeeper)
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,047] INFO [Producer clientId=c3-command] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mstreams-demo                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,199] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,436] INFO [Controller id=2] Registering handlers (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,216] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,199] INFO Client will use DIGEST-MD5 as SASL mechanism. (org.apache.zookeeper.client.ZooKeeperSaslClient)
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,440] INFO [Controller id=2] Deleting log dir event notifications (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,236] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,200] INFO Opening socket connection to server zookeeper/172.19.0.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client' (org.apache.zookeeper.ClientCnxn)
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,513] INFO [Controller id=2] Deleting isr change notifications (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,200] INFO Socket connection established to zookeeper/172.19.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,236] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,516] INFO [Controller id=2] Initializing controller context (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,203] INFO Session establishment complete on server zookeeper/172.19.0.2:2181, sessionid = 0x1000183079c0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,516] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,237] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey, _confluent-controlcenter-5-3-1-1-cluster-rekey, _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store, _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,203] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[34mstreams-demo                   |[0m 
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,629] INFO [Controller id=2] Initialized broker epochs cache: Map(1 -> 46, 2 -> 43) (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,238] INFO intermediateTopics=[_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,327] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.security.authenticator.AbstractLogin - Successfully logged in.
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,244] INFO CONTROL CENTER UI
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,634] DEBUG [Controller id=2] Register BrokerModifications handler for Set(1, 2) (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,328] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[32mcontrol-center                 |[0m 
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:17,640] DEBUG [Channel manager on controller 2]: Controller 2 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,519] INFO ConfluentMetricsReporterConfig values: 
[32mcontrol-center                 |[0m By using Control Center, subject to any license you may have with Confluent, you agree to the Confluent Data Protection Agreement.  In particular, please note that the version check feature of Control Center is enabled.
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,310] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.admin.AdminClientConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.bootstrap.servers = kafka1:9091
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,312] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.publish.ms = 15000
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m With this enabled, this instance is configured to collect and report certain data (version information, time stamped session IDs, instance ID, instance uptime, license key for subscription customers, IP address, and other product data)  to Confluent, Inc. ("Confluent") or its parent, subsidiaries, affiliates or service providers every hour.  By proceeding with `confluent.support.metrics.enable=true`, you agree to all such collection, transfer and use of Version information by Confluent. You can turn the version check feature off by setting `confluent.support.metrics.enable=false` in the Control Center configuration and restarting Control Center.  See the Confluent Enterprise documentation for further information.
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,313] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic = _confluent-metrics
[32mcontrol-center                 |[0m  (io.confluent.controlcenter.healthcheck.HealthCheck)
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,503] INFO [ZooKeeperClient Simple ACL authorizer] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005076722
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.create = false
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,254] INFO Starting Control Center version=5.3.1 (io.confluent.controlcenter.ControlCenter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,503] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@55787112 (org.apache.zookeeper.ZooKeeper)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Creating restore consumer client
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.max.message.bytes = 10485760
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,297] INFO getPersistentStoreTopicNames=[_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.partitions = 12
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,505] INFO Client will use DIGEST-MD5 as SASL mechanism. (org.apache.zookeeper.client.ZooKeeperSaslClient)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,297] INFO getLruStoreTopicNames=[_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.replicas = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,506] INFO Opening socket connection to server zookeeper/172.19.0.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client' (org.apache.zookeeper.ClientCnxn)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,297] INFO getWindowedStoreTopicNames=[_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog] (io.confluent.controlcenter.ControlCenterConfigModule)
[34mstreams-demo                   |[0m 	allow.auto.create.topics = true
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.retention.bytes = -1
[36;1mconnect                        |[0m 	ssl.key.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,506] INFO Socket connection established to zookeeper/172.19.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,298] INFO getLogAppendTimeIntermediateTopicNames=[_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey, _confluent-controlcenter-5-3-1-1-cluster-rekey, _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey, _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store, _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey] (io.confluent.controlcenter.ControlCenterConfigModule)
[34mstreams-demo                   |[0m 	auto.commit.interval.ms = 5000
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.retention.ms = 259200000
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,298] INFO intermediateTopics=[_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition] (io.confluent.controlcenter.ControlCenterConfigModule)
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,506] INFO [ZooKeeperClient Simple ACL authorizer] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[34mstreams-demo                   |[0m 	auto.offset.reset = none
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.topic.roll.ms = 14400000
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,299] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,508] DEBUG [Channel manager on controller 2]: Controller 2 trying to connect to broker 2 (kafka.controller.ControllerChannelManager)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.volume.metrics.refresh.ms = 15000
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,509] INFO Session establishment complete on server zookeeper/172.19.0.2:2181, sessionid = 0x1000183079c0005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[34mstreams-demo                   |[0m 	check.crcs = true
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m 	confluent.metrics.reporter.whitelist = .*MaxLag.*|kafka.log:type=Log,name=Size.*|.*name=(ActiveControllerCount|BytesInPerSec|BytesOutPerSec|FailedFetchRequestsPerSec|FailedProduceRequestsPerSec|InSyncReplicasCount|LeaderCount|LeaderElectionRateAndTimeMs|LocalTimeMs|LogEndOffset|LogStartOffset|NetworkProcessorAvgIdlePercent|NumLogSegments|OfflinePartitionsCount|PartitionCount|RemoteTimeMs|ReplicasCount|RequestHandlerAvgIdlePercent|RequestQueueSize|RequestQueueTimeMs|RequestsPerSec|ResponseQueueSize|ResponseQueueTimeMs|ResponseSendTimeMs|Size|TotalFetchRequestsPerSec|TotalProduceRequestsPerSec|TotalTimeMs|UncleanLeaderElectionsPerSec|UnderReplicated|UnderReplicatedPartitions|ZooKeeperDisconnectsPerSec|ZooKeeperExpiresPerSec).*
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,509] INFO [ZooKeeperClient Simple ACL authorizer] Connected. (kafka.zookeeper.ZooKeeperClient)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m  (io.confluent.metrics.reporter.ConfluentMetricsReporterConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,625] INFO ProducerConfig values: 
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,711] INFO [/kafka-acl-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-StreamThread-1-restore-consumer
[31;1mkafka1                         |[0m 	acks = all
[36;1mconnect                        |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:18,711] INFO [/kafka-acl-extended-changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[34mstreams-demo                   |[0m 	client.rack = 
[31;1mkafka1                         |[0m 	batch.size = 16384
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,006] INFO ConfluentMetricsReporterConfig values: 
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	bootstrap.servers = [kafka1:9091]
[32mcontrol-center                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.bootstrap.servers = kafka2:9092
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m 	buffer.memory = 33554432
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.publish.ms = 15000
[34mstreams-demo                   |[0m 	default.api.timeout.ms = 60000
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m 	enable.auto.commit = false
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic = _confluent-metrics
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m 	client.id = confluent-metrics-reporter
[34mstreams-demo                   |[0m 	exclude.internal.topics = true
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.create = false
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.max.message.bytes = 10485760
[34mstreams-demo                   |[0m 	fetch.max.bytes = 52428800
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m 	compression.type = lz4
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.partitions = 12
[36;1mconnect                        |[0m 	transactional.id = null
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.replicas = 2
[34mstreams-demo                   |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[34mstreams-demo                   |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.retention.bytes = -1
[31;1mkafka1                         |[0m 	delivery.timeout.ms = 120000
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	retries = 2147483647
[34mstreams-demo                   |[0m 	group.id = null
[31;1mkafka1                         |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.retention.ms = 259200000
[36;1mconnect                        |[0m May 20, 2020 8:05:25 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.topic.roll.ms = 14400000
[36;1mconnect                        |[0m WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource will be ignored. 
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.volume.metrics.refresh.ms = 15000
[36;1mconnect                        |[0m May 20, 2020 8:05:25 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34mstreams-demo                   |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[31;1mkafka1                         |[0m 	linger.ms = 500
[34;1mkafka2                         |[0m 	confluent.metrics.reporter.whitelist = .*MaxLag.*|kafka.log:type=Log,name=Size.*|.*name=(ActiveControllerCount|BytesInPerSec|BytesOutPerSec|FailedFetchRequestsPerSec|FailedProduceRequestsPerSec|InSyncReplicasCount|LeaderCount|LeaderElectionRateAndTimeMs|LocalTimeMs|LogEndOffset|LogStartOffset|NetworkProcessorAvgIdlePercent|NumLogSegments|OfflinePartitionsCount|PartitionCount|RemoteTimeMs|ReplicasCount|RequestHandlerAvgIdlePercent|RequestQueueSize|RequestQueueTimeMs|RequestsPerSec|ResponseQueueSize|ResponseQueueTimeMs|ResponseSendTimeMs|Size|TotalFetchRequestsPerSec|TotalProduceRequestsPerSec|TotalTimeMs|UncleanLeaderElectionsPerSec|UnderReplicated|UnderReplicatedPartitions|ZooKeeperDisconnectsPerSec|ZooKeeperExpiresPerSec).*
[36;1mconnect                        |[0m WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource will be ignored. 
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mstreams-demo                   |[0m 	internal.leave.group.on.close = false
[31;1mkafka1                         |[0m 	max.block.ms = 60000
[34;1mkafka2                         |[0m  (io.confluent.metrics.reporter.ConfluentMetricsReporterConfig)
[36;1mconnect                        |[0m May 20, 2020 8:05:25 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,213] INFO ProducerConfig values: 
[36;1mconnect                        |[0m WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.RootResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.RootResource will be ignored. 
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m 	acks = all
[36;1mconnect                        |[0m [2020-05-20 20:05:26,298] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:26,298] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m 	bootstrap.servers = [kafka2:9092]
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	max.poll.records = 1000
[34;1mkafka2                         |[0m 	buffer.memory = 33554432
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mstreams-demo                   |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	client.id = confluent-metrics-reporter
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m 	compression.type = lz4
[31;1mkafka1                         |[0m 	receive.buffer.bytes = 32768
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	delivery.timeout.ms = 120000
[31;1mkafka1                         |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	enable.idempotence = false
[31;1mkafka1                         |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m 	retries = 10
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 65536
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m 	retry.backoff.ms = 500
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	linger.ms = 500
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	max.block.ms = 60000
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m 	max.in.flight.requests.per.connection = 1
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m 	max.request.size = 10485760
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[34;1mkafka2                         |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m 	receive.buffer.bytes = 32768
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34mstreams-demo                   |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m 	retries = 10
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	retry.backoff.ms = 500
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,664] WARN The configuration 'consumer.session.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,664] WARN The configuration 'producer.max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,664] WARN The configuration 'producer.retries' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.endpoint.identification.algorithm = https
[34mstreams-demo                   |[0m 	session.timeout.ms = 10000
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,664] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.key.password = [hidden]
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] WARN The configuration 'producer.linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] WARN The configuration 'producer.delivery.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] WARN The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] WARN The configuration 'producer.compression.type' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] WARN The configuration 'num.stream.threads' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	ssl.secure.random.implementation = null
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,665] INFO Kafka startTimeMs: 1590005071665 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,924] INFO topicListings=[] (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,926] INFO missingTopics=[_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-cluster-rekey, _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey, _confluent-metrics, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey, _confluent-command, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog, _confluent-monitoring, _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey] (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m 	transaction.timeout.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:04:31,927] INFO extantTopics=[] (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[31;1mkafka1                         |[0m 	transactional.id = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,246] INFO describing topics=[_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog, _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-cluster-rekey, _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog, _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey, _confluent-metrics, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog, _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog, _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog, _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey, _confluent-command, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition, _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog, _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog, _confluent-monitoring, _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog, _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog, _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog, _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey] (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect                        |[0m [2020-05-20 20:05:26,299] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,363] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:04:18,702] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,363] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,100] WARN The configuration 'topic.create' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,363] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,100] WARN The configuration 'topic.replicas' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,363] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,110] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,363] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-cluster-rekey, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,110] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,110] INFO Kafka startTimeMs: 1590005059100 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,115] INFO Starting Confluent metrics reporter for cluster id lbUe4hq7QeWfnY0W4R-PhA with an interval of 15000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,128] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m 	ssl.protocol = TLS
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,225] INFO [SocketServer brokerId=1] Started data-plane processors for 4 acceptors (kafka.network.SocketServer)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m 	ssl.provider = null
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,295] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,295] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-metrics, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,295] INFO Kafka startTimeMs: 1590005059295 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,300] INFO Kafka startTimeMs: 1590005126300 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,296] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[36;1mconnect                        |[0m [2020-05-20 20:05:26,394] INFO ConsumerConfig values: 
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[34;1mkafka2                         |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,296] INFO Waiting until monitored service is ready for metrics collection (io.confluent.support.metrics.BaseMetricsReporter)
[36;1mconnect                        |[0m 	allow.auto.create.topics = true
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[34;1mkafka2                         |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,298] INFO Monitored service is now ready (io.confluent.support.metrics.BaseMetricsReporter)
[36;1mconnect                        |[0m 	auto.commit.interval.ms = 5000
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005078223
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Creating shared producer client
[31;1mkafka1                         |[0m [2020-05-20 20:04:19,298] INFO Attempting to collect and submit metrics (io.confluent.support.metrics.BaseMetricsReporter)
[36;1mconnect                        |[0m 	auto.offset.reset = earliest
[34;1mkafka2                         |[0m 	transaction.timeout.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:20,231] INFO [Producer clientId=confluent-metrics-reporter] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	transactional.id = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	acks = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:20,557] WARN The replication factor of topic __confluent.support.metrics will be set to 2, which is less than the desired replication factor of 3 (reason: this cluster contains only 2 brokers).  If you happen to add more brokers to this cluster, then it is important to increase the replication factor of the topic to eventually 3 to ensure reliable and durable metrics collection. (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[36;1mconnect                        |[0m 	check.crcs = true
[34;1mkafka2                         |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	batch.size = 16384
[31;1mkafka1                         |[0m [2020-05-20 20:04:20,557] INFO Attempting to create topic __confluent.support.metrics with 2 replicas, assuming 2 total brokers (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[31;1mkafka1                         |[0m [2020-05-20 20:04:20,635] INFO Creating topic __confluent.support.metrics with configuration {retention.ms=31536000000} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,303] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[34mstreams-demo                   |[0m 	buffer.memory = 33554432
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m 	client.rack = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,336] INFO ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,308] INFO [RequestSendThread controllerId=2] Starting (kafka.controller.RequestSendThread)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-command, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,310] INFO [RequestSendThread controllerId=2] Starting (kafka.controller.RequestSendThread)
[31;1mkafka1                         |[0m 	acks = 1
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-StreamThread-1-producer
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m 	default.api.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,312] INFO [Controller id=2] Partitions being reassigned: Map() (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	compression.type = none
[31;1mkafka1                         |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m 	enable.auto.commit = false
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,313] INFO [Controller id=2] Currently active brokers in the cluster: Set(1, 2) (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	bootstrap.servers = [PLAINTEXT://kafka1:10091, PLAINTEXT://kafka2:10092]
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,364] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m 	exclude.internal.topics = true
[34mstreams-demo                   |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,313] INFO [Controller id=2] Currently shutting brokers in the cluster: Set() (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	buffer.memory = 33554432
[36;1mconnect                        |[0m 	fetch.max.bytes = 52428800
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,314] INFO [Controller id=2] Current list of topics in the cluster: Set() (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m 	fetch.max.wait.ms = 500
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO create=success topic=TopicInfo{name=_confluent-monitoring, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,314] INFO [Controller id=2] Fetching topic deletions in progress (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	client.id = 
[34mstreams-demo                   |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[36;1mconnect                        |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,321] INFO [Controller id=2] List of topics to be deleted:  (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m 	compression.type = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,321] INFO [Controller id=2] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[36;1mconnect                        |[0m 	group.id = connect
[31;1mkafka1                         |[0m 	connections.max.idle.ms = 540000
[34mstreams-demo                   |[0m 	linger.ms = 100
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO create=success topic=TopicInfo{name=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey, partitions=1, replication=2} (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,322] INFO [Controller id=2] Initializing topic deletion manager (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m 	delivery.timeout.ms = 120000
[34mstreams-demo                   |[0m 	max.block.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,365] INFO ConsumerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,322] INFO [Topic Deletion Manager 2] Initializing manager with initial deletions: Set(), initial ineligible deletions: Set() (kafka.controller.TopicDeletionManager)
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m 	enable.idempotence = false
[34mstreams-demo                   |[0m 	max.in.flight.requests.per.connection = 5
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[36;1mconnect                        |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,323] INFO [Controller id=2] Sending update metadata request (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	max.request.size = 1048576
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect                        |[0m 	internal.leave.group.on.close = true
[31;1mkafka1                         |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	auto.offset.reset = latest
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,406] INFO [ReplicaStateMachine controllerId=2] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
[36;1mconnect                        |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m 	linger.ms = 0
[34mstreams-demo                   |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,407] INFO [ReplicaStateMachine controllerId=2] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
[36;1mconnect                        |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m 	max.block.ms = 10000
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,411] INFO [ReplicaStateMachine controllerId=2] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
[36;1mconnect                        |[0m 	max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m 	max.in.flight.requests.per.connection = 5
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,411] DEBUG [ReplicaStateMachine controllerId=2] Started replica state machine with initial state -> Map() (kafka.controller.ZkReplicaStateMachine)
[36;1mconnect                        |[0m 	max.poll.interval.ms = 300000
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	client.id = will-delete-this
[31;1mkafka1                         |[0m 	max.request.size = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,412] INFO [PartitionStateMachine controllerId=2] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
[36;1mconnect                        |[0m 	max.poll.records = 500
[34mstreams-demo                   |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mcontrol-center                 |[0m 	client.rack = 
[31;1mkafka1                         |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,413] INFO [PartitionStateMachine controllerId=2] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 32768
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,425] DEBUG [PartitionStateMachine controllerId=2] Started partition state machine with initial state -> Map() (kafka.controller.ZkPartitionStateMachine)
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[31;1mkafka1                         |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,495] INFO [Controller id=2] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m 	enable.auto.commit = false
[31;1mkafka1                         |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,497] INFO [Controller id=2] Removing partitions Set() from the list of reassigned partitions in zookeeper (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,498] INFO [Controller id=2] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,528] INFO [Controller id=2] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	retries = 2147483647
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,529] INFO [Controller id=2] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,529] INFO [Controller id=2] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	receive.buffer.bytes = 32768
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,530] INFO [Controller id=2] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,531] INFO [Controller id=2] Starting preferred replica leader election for partitions  (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m 	group.id = _confluent-controlcenter-5-3-1-1
[31;1mkafka1                         |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,613] INFO [Controller id=2] Starting the controller scheduler (kafka.controller.KafkaController)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,829] INFO [RequestSendThread controllerId=2] Controller 2 connected to kafka1:9091 (id: 1 rack: r1) for sending state change requests (kafka.controller.RequestSendThread)
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:19,954] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 0 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m 	retries = 2147483647
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,007] WARN The configuration 'topic.create' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = false
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,008] WARN The configuration 'topic.replicas' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m 	sasl.jaas.config = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,017] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34mstreams-demo                   |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,017] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 21600000
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,017] INFO Kafka startTimeMs: 1590005060008 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	max.poll.records = 100
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,029] INFO Starting Confluent metrics reporter for cluster id lbUe4hq7QeWfnY0W4R-PhA with an interval of 15000 ms (io.confluent.metrics.reporter.ConfluentMetricsReporter)
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,120] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,215] INFO [SocketServer brokerId=2] Started data-plane processors for 4 acceptors (kafka.network.SocketServer)
[31;1mkafka1                         |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,224] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,224] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,224] INFO Kafka startTimeMs: 1590005060224 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,225] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.factor = 0.8
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,234] INFO Waiting until monitored service is ready for metrics collection (io.confluent.support.metrics.BaseMetricsReporter)
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,241] INFO Monitored service is now ready (io.confluent.support.metrics.BaseMetricsReporter)
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m 	sasl.mechanism = GSSAPI
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,241] INFO Attempting to collect and submit metrics (io.confluent.support.metrics.BaseMetricsReporter)
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m 	request.timeout.ms = 960032
[31;1mkafka1                         |[0m 	security.protocol = PLAINTEXT
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,617] INFO [RequestSendThread controllerId=2] Controller 2 connected to kafka2:9092 (id: 2 rack: r1) for sending state change requests (kafka.controller.RequestSendThread)
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,736] INFO [Controller id=2] New topics: [Set(__confluent.support.metrics)], deleted topics: [Set()], new partition replica assignment [Map(__confluent.support.metrics-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,810] INFO [Controller id=2] New partition creation callback for __confluent.support.metrics-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,831] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 0 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m 	ssl.endpoint.identification.algorithm = https
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,899] TRACE [Controller id=2 epoch=1] Changed partition __confluent.support.metrics-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m 	ssl.key.password = null
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,929] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __confluent.support.metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	ssl.key.password = null
[34mstreams-demo                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:20,930] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __confluent.support.metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	ssl.keystore.location = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,110] INFO [Producer clientId=confluent-metrics-reporter] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[31;1mkafka1                         |[0m 	ssl.keystore.password = null
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,315] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(2, 1), 32 -> ArrayBuffer(1, 2), 41 -> ArrayBuffer(2, 1), 17 -> ArrayBuffer(2, 1), 8 -> ArrayBuffer(1, 2), 35 -> ArrayBuffer(2, 1), 44 -> ArrayBuffer(1, 2), 26 -> ArrayBuffer(1, 2), 11 -> ArrayBuffer(2, 1), 29 -> ArrayBuffer(2, 1), 38 -> ArrayBuffer(1, 2), 47 -> ArrayBuffer(2, 1), 20 -> ArrayBuffer(1, 2), 2 -> ArrayBuffer(1, 2), 5 -> ArrayBuffer(2, 1), 14 -> ArrayBuffer(1, 2), 46 -> ArrayBuffer(1, 2), 49 -> ArrayBuffer(2, 1), 40 -> ArrayBuffer(1, 2), 13 -> ArrayBuffer(2, 1), 4 -> ArrayBuffer(1, 2), 22 -> ArrayBuffer(1, 2), 31 -> ArrayBuffer(2, 1), 16 -> ArrayBuffer(1, 2), 7 -> ArrayBuffer(2, 1), 43 -> ArrayBuffer(2, 1), 25 -> ArrayBuffer(2, 1), 34 -> ArrayBuffer(1, 2), 10 -> ArrayBuffer(1, 2), 37 -> ArrayBuffer(2, 1), 1 -> ArrayBuffer(2, 1), 19 -> ArrayBuffer(2, 1), 28 -> ArrayBuffer(1, 2), 45 -> ArrayBuffer(2, 1), 27 -> ArrayBuffer(2, 1), 36 -> ArrayBuffer(1, 2), 18 -> ArrayBuffer(1, 2), 9 -> ArrayBuffer(2, 1), 21 -> ArrayBuffer(2, 1), 48 -> ArrayBuffer(1, 2), 3 -> ArrayBuffer(2, 1), 12 -> ArrayBuffer(1, 2), 30 -> ArrayBuffer(1, 2), 39 -> ArrayBuffer(2, 1), 15 -> ArrayBuffer(2, 1), 42 -> ArrayBuffer(1, 2), 24 -> ArrayBuffer(1, 2), 6 -> ArrayBuffer(1, 2), 33 -> ArrayBuffer(2, 1), 0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,323] TRACE [Controller id=2 epoch=1] Changed partition __confluent.support.metrics-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,352] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __confluent.support.metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,357] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __confluent.support.metrics-0 (state.change.logger)
[34mstreams-demo                   |[0m 	transaction.timeout.ms = 60000
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,365] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __confluent.support.metrics-0 (state.change.logger)
[34mstreams-demo                   |[0m 	transactional.id = null
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,360] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 1 from controller 2 epoch 1 for partition __confluent.support.metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34mstreams-demo                   |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m 	ssl.truststore.location = null
[31;1mkafka1                         |[0m 	ssl.truststore.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,365] INFO [KafkaApi-2] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 2 is successful (kafka.server.KafkaApis)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,422] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __confluent.support.metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,422] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __confluent.support.metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,428] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-leader transition for partition __confluent.support.metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[31;1mkafka1                         |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,444] INFO [Controller id=2] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-22 -> Vector(1, 2), __consumer_offsets-30 -> Vector(1, 2), __consumer_offsets-8 -> Vector(1, 2), __consumer_offsets-21 -> Vector(2, 1), __consumer_offsets-4 -> Vector(1, 2), __consumer_offsets-27 -> Vector(2, 1), __consumer_offsets-7 -> Vector(2, 1), __consumer_offsets-9 -> Vector(2, 1), __consumer_offsets-46 -> Vector(1, 2), __consumer_offsets-25 -> Vector(2, 1), __consumer_offsets-35 -> Vector(2, 1), __consumer_offsets-41 -> Vector(2, 1), __consumer_offsets-33 -> Vector(2, 1), __consumer_offsets-23 -> Vector(2, 1), __consumer_offsets-49 -> Vector(2, 1), __consumer_offsets-47 -> Vector(2, 1), __consumer_offsets-16 -> Vector(1, 2), __consumer_offsets-28 -> Vector(1, 2), __consumer_offsets-31 -> Vector(2, 1), __consumer_offsets-36 -> Vector(1, 2), __consumer_offsets-42 -> Vector(1, 2), __consumer_offsets-3 -> Vector(2, 1), __consumer_offsets-18 -> Vector(1, 2), __consumer_offsets-37 -> Vector(2, 1), __consumer_offsets-15 -> Vector(2, 1), __consumer_offsets-24 -> Vector(1, 2), __consumer_offsets-38 -> Vector(1, 2), __consumer_offsets-17 -> Vector(2, 1), __consumer_offsets-48 -> Vector(1, 2), __consumer_offsets-19 -> Vector(2, 1), __consumer_offsets-11 -> Vector(2, 1), __consumer_offsets-13 -> Vector(2, 1), __consumer_offsets-2 -> Vector(1, 2), __consumer_offsets-43 -> Vector(2, 1), __consumer_offsets-6 -> Vector(1, 2), __consumer_offsets-14 -> Vector(1, 2), __consumer_offsets-20 -> Vector(1, 2), __consumer_offsets-0 -> Vector(1, 2), __consumer_offsets-44 -> Vector(1, 2), __consumer_offsets-39 -> Vector(2, 1), __consumer_offsets-12 -> Vector(1, 2), __consumer_offsets-45 -> Vector(2, 1), __consumer_offsets-1 -> Vector(2, 1), __consumer_offsets-5 -> Vector(2, 1), __consumer_offsets-26 -> Vector(1, 2), __consumer_offsets-29 -> Vector(2, 1), __consumer_offsets-34 -> Vector(1, 2), __consumer_offsets-10 -> Vector(1, 2), __consumer_offsets-32 -> Vector(1, 2), __consumer_offsets-40 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	session.timeout.ms = 60000
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[31;1mkafka1                         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,445] INFO [Controller id=2] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m [2020-05-20 20:05:26,500] INFO [Producer clientId=producer-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,369] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 1 from controller 2 epoch 1 for partition __confluent.support.metrics-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,446] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__confluent.support.metrics-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m May 20, 2020 8:05:27 PM org.glassfish.jersey.internal.Errors logErrors
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,453] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,459] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,453] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-30 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,453] INFO Kafka startTimeMs: 1590005061441 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,503] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 2 epoch 1 starting the become-follower transition for partition __confluent.support.metrics-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,531] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-27 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,007] INFO Started o.e.j.s.ServletContextHandler@52f57666{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,605] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,007] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,613] INFO [Producer clientId=producer-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,007] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,738] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 3 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,465] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-46 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005080310
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,844] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 4 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-25 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Creating consumer client
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:21,945] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-35 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,003] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 5 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-41 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34mstreams-demo                   |[0m 	allow.auto.create.topics = true
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,011] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 362 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-33 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34mstreams-demo                   |[0m 	auto.commit.interval.ms = 5000
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,032] INFO Created log for partition __confluent.support.metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 31536000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	auto.offset.reset = earliest
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,033] INFO [Partition __confluent.support.metrics-0 broker=1] No checkpointed highwatermark is found for partition __confluent.support.metrics-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,716] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-49 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,034] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,717] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-47 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,041] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__confluent.support.metrics-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,717] INFO Kafka startTimeMs: 1590005075716 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,047] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition __confluent.support.metrics-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,419] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,717] INFO Setting offsets for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	client.id = wikipedia-activity-monitor-StreamThread-1-consumer
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-28 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,102] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __confluent.support.metrics-0 as part of become-follower request with correlation id 1 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,859] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34mstreams-demo                   |[0m 	client.rack = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-31 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,112] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 6 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,912] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Subscribed to partition(s): _confluent-monitoring-0 (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-36 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m 	default.api.timeout.ms = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,223] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 7 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34mstreams-demo                   |[0m 	enable.auto.commit = false
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,915] INFO found 1 topicPartitions for topic=_confluent-monitoring (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	exclude.internal.topics = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-42 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,333] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 8 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[32mcontrol-center                 |[0m [2020-05-20 20:04:35,989] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Seeking to LATEST offset of partition _confluent-monitoring-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m 	fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,034] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-monitoring-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,438] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 9 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34mstreams-demo                   |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,543] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 10 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34mstreams-demo                   |[0m 	fetch.min.bytes = 1
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,050] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-37 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,650] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 11 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,136] INFO Setting offsets for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)
[34mstreams-demo                   |[0m 	group.id = wikipedia-activity-monitor
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,466] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,755] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 12 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34mstreams-demo                   |[0m 	group.instance.id = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,193] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Subscribed to partition(s): _confluent-metrics-0 (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,864] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 13 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[34mstreams-demo                   |[0m 	heartbeat.interval.ms = 3000
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,193] INFO found 1 topicPartitions for topic=_confluent-metrics (io.confluent.controlcenter.KafkaHelper)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-38 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,940] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(__confluent.support.metrics-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34mstreams-demo                   |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,272] INFO [Consumer clientId=will-delete-this, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-metrics-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34mstreams-demo                   |[0m 	internal.leave.group.on.close = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,941] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 1 for partition __confluent.support.metrics-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-48 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m 	isolation.level = read_uncommitted
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,279] INFO action=starting topology=command (io.confluent.controlcenter.ControlCenter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,942] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-follower transition for partition __confluent.support.metrics-0 with leader 2 (state.change.logger)
[34mstreams-demo                   |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,280] INFO stream-client [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,943] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[34mstreams-demo                   |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,280] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,948] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __confluent.support.metrics-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34mstreams-demo                   |[0m 	max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,281] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:22,954] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m 	max.poll.records = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,281] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Subscribed to pattern: '_confluent-command' (org.apache.kafka.clients.consumer.KafkaConsumer)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,289] INFO unable to get command store (io.confluent.command.CommandStore)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-43 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,013] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 14 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,393] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,118] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 15 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,426] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,130] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __confluent.support.metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,533] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-13 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,534] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,534] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-46 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,534] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] partition revocation took 0 ms.
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-9 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-44 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[32mcontrol-center                 |[0m 	suspended active tasks: []
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-42 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-39 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	suspended standby tasks: [] (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,467] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-21 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,534] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-17 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,494] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-45 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-30 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:36,541] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,494] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-26 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:37,289] INFO unable to get command store (io.confluent.command.CommandStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,494] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:38,289] INFO unable to get command store (io.confluent.command.CommandStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,495] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-26 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-5 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,495] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-29 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,290] INFO unable to get command store (io.confluent.command.CommandStore)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-38 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,495] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-34 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,495] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,495] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-32 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,495] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-40 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,499] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-27 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-1 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,501] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-34 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,548] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer] Assigned tasks to clients as {77ec260a-6a09-43ac-955e-589cd959aa4e=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,562] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,501] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-16 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,564] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Setting newly assigned partitions: _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,501] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-44 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,501] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-37 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-45 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,564] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,501] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-12 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,580] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] partition assignment took 16 ms.
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,502] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-41 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	current active tasks: [0_0]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-24 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,502] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-48 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	current standby tasks: []
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,502] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	previous active tasks: []
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,137] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-49 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,502] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-42 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m  (org.apache.kafka.streams.processor.internals.StreamThread)
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,502] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-31 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,420] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,582] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Found no committed offset for partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-29 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,504] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-28 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,421] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,582] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] Setting topic '_confluent-command' to consume from earliest offset (org.apache.kafka.streams.processor.internals.StreamThread)
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-25 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,547] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-32 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,421] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,582] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Seeking to EARLIEST offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m 	session.timeout.ms = 10000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,548] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-34 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,421] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,586] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Found no committed offset for partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-37 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,548] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,421] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,758] INFO Opening store commander in regular mode (org.apache.kafka.streams.state.internals.RocksDBTimestampedStore)
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,549] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,421] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,809] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-restore-consumer, groupId=null] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-33 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,549] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,421] INFO Kafka startTimeMs: 1590005127421 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,931] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-15 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,549] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-35 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,509] INFO [Consumer clientId=consumer-1, groupId=connect] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,943] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-48 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,549] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,608] INFO [Consumer clientId=consumer-1, groupId=connect] Subscribed to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer)
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,943] INFO stream-thread [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-11 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,944] INFO stream-client [_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,611] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-44 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,549] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:04:39,950] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1-command] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-23 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:41,292] INFO action=started topology=command (io.confluent.controlcenter.ControlCenter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,549] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-19 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:41,703] INFO RestConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,556] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-43 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-32 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	access.control.allow.headers = 
[34mstreams-demo                   |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,556] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-47 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-28 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	access.control.allow.methods = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,556] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-46 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-7 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	access.control.allow.origin = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,556] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-40 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-40 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	authentication.method = NONE
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,556] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-3 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	authentication.realm = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,557] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-25 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-36 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	authentication.roles = [*]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,559] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-47 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	authentication.skip.paths = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,559] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	compression.enable = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,559] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-43 (state.change.logger)
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m 	debug = false
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,559] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-41 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-10 (state.change.logger)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.clients.Metadata - [Producer clientId=wikipedia-activity-monitor-StreamThread-1-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	idle.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,559] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-22 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	listeners = [http://0.0.0.0:9021, https://0.0.0.0:9022]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,595] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-30 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-18 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,596] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-33 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-31 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'schema.registry.url' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,597] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.jmx.prefix = rest-utils
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-27 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,597] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,138] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-39 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,604] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,139] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-6 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.tag.map = []
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,139] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-35 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-38 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'zookeeper.connect' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	port = 9021
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,139] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-36 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	request.logger.name = io.confluent.rest-utils.requests
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,364] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-26 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config.
[32mcontrol-center                 |[0m 	resource.extension.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-49 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,612] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	response.mediatype.default = application/json
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,407] INFO Successfully submitted metrics to Kafka topic __confluent.support.metrics (io.confluent.support.metrics.submitters.KafkaSubmitter)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-39 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	response.mediatype.preferred = [application/json]
[36;1mconnect                        |[0m [2020-05-20 20:05:27,613] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'advertised.listeners' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	rest.servlet.initializor.classes = []
[36;1mconnect                        |[0m [2020-05-20 20:05:27,613] INFO [Consumer clientId=consumer-1, groupId=connect] Seeking to EARLIEST offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
[34mstreams-demo                   |[0m [main] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-29 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	shutdown.graceful.ms = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:27,805] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-10 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-8 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[32mcontrol-center                 |[0m 	ssl.cipher.suites = []
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-14 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005081522
[32mcontrol-center                 |[0m 	ssl.client.auth = false
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-12 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,607] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [main] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] State transition from CREATED to REBALANCING
[32mcontrol-center                 |[0m 	ssl.client.authentication = NONE
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-2 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,607] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] Starting
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = []
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from CREATED to STARTING
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = null
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-6 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,607] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-45 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = 
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Subscribed to pattern: 'wikipedia.parsed'
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-4 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,609] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-24 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,611] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,453] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-18 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,611] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Revoking previously assigned partitions []
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-16 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,611] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-22 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,612] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,806] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-20 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	ssl.provider = 
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,612] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,807] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-9 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = 
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] partition revocation took 0 ms.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,612] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,807] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-23 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34mstreams-demo                   |[0m 	suspended active tasks: []
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,614] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:27,807] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-7 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m 	suspended standby tasks: []
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,615] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:27,807] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-13 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] (Re-)joining group
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
[32mcontrol-center                 |[0m 	websocket.path.prefix = /ws
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,615] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	websocket.servlet.initializor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,807] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-11 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,615] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] (Re-)joining group
[32mcontrol-center                 |[0m  (io.confluent.rest.RestConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,807] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-17 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor - stream-thread [wikipedia-activity-monitor-StreamThread-1-consumer] Assigned tasks to clients as {7d64729d-77cd-410f-ba31-06e885cc9363=[activeTasks: ([0_0, 0_1]) standbyTasks: ([]) assignedTasks: ([0_0, 0_1]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,615] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:41,704] WARN Configuration 'confluent.controlcenter.ksql.url' is deprecated. Configure new ksql clusters with 'confluent.controlcenter.ksql.<name>.url'. Please see documentation for more details. (io.confluent.controlcenter.ksql.KsqlClusterMetadata)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: [wikipedia.parsed]
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-1 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,615] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:41,720] INFO Starting License Store (io.confluent.license.LicenseStore)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Successfully joined group with generation 3
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-15 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,615] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:41,720] INFO Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Setting newly assigned partitions: wikipedia.parsed-1, wikipedia.parsed-0
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-21 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,616] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:41,720] INFO AdminClientConfig values: 
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-5 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,616] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.kafka.serializers.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-19 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,616] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,645] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,616] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO [Consumer clientId=consumer-1, groupId=connect] Resetting offset for partition connect-offsets-3 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-license-manager-5-3-1-1
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,700] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,616] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,708] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,617] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,712] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog)
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,617] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,714] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,808] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,618] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,714] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,810] INFO Worker started (org.apache.kafka.connect.runtime.Worker)
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,810] INFO Starting KafkaBasedLog with topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,715] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:27,810] INFO AdminClientConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,745] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,809] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,820] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.kafka.serializers.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,822] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,823] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,823] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[36;1mconnect                        |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,823] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	retries = 2147483647
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,620] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,826] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,620] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,826] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,620] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,830] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-48 (last update controller epoch 1) (state.change.logger)
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,620] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,841] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,620] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,845] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,621] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	specific.avro.reader = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,846] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,621] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,848] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	retries = 5
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,621] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,848] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,622] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,849] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 
[32mcontrol-center                 |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,849] INFO [Partition __consumer_offsets-10 broker=1] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,622] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.kafka.serializers.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,895] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-10 (last update controller epoch 1) (state.change.logger)
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,622] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,928] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,622] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,935] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,623] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,950] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,624] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,951] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,624] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,951] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,624] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,951] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,624] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,625] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,951] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,625] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,958] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-26 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,625] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,996] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,625] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:23,999] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.kafka.serializers.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,002] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,625] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NonExistentReplica to NewReplica (state.change.logger)
[34mstreams-demo                   |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,003] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,942] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	schema.registry.url = [https://schemaregistry:8085]
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,012] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,945] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-30 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,012] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,946] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	auto.register.schemas = true
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,013] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,946] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	max.schemas.per.subject = 1000
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,018] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-42 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,946] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,023] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,946] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-27 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	ssl.key.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,024] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,946] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,025] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	specific.avro.reader = false
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,947] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,035] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,947] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-46 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,046] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,049] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,947] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-25 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m 
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,207] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,049] INFO [Partition __consumer_offsets-4 broker=1] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,949] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-35 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,210] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,053] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-4 (last update controller epoch 1) (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] partition assignment took 79 ms.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,949] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-41 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,210] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,096] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34mstreams-demo                   |[0m 	current active tasks: [0_0, 0_1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,949] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-33 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,210] INFO Kafka startTimeMs: 1590005082210 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	current standby tasks: []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,098] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,950] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,282] INFO ProducerConfig values: 
[34mstreams-demo                   |[0m 	previous active tasks: []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,100] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-49 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[32mcontrol-center                 |[0m 	acks = all
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-47 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,100] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	batch.size = 16384
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Found no committed offset for partition wikipedia.parsed-1
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,100] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Found no committed offset for partition wikipedia.parsed-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-28 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,100] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	buffer.memory = 33554432
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Found no committed offset for partition wikipedia.parsed-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-31 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,100] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.state.internals.RocksDBTimestampedStore - Opening store KSTREAM-AGGREGATE-STATE-STORE-0000000002 in upgrade mode
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,105] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-20 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-36 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Found no committed offset for partition wikipedia.parsed-1
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-license-manager-5-3-1-1
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,110] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-42 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.state.internals.RocksDBTimestampedStore - Opening store KSTREAM-AGGREGATE-STATE-STORE-0000000002 in upgrade mode
[32mcontrol-center                 |[0m 	compression.type = lz4
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,110] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-restore-consumer, groupId=null] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,136] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	delivery.timeout.ms = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-37 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,140] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
[32mcontrol-center                 |[0m 	enable.idempotence = false
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,141] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.processor.internals.StreamThread - stream-thread [wikipedia-activity-monitor-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,951] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.streams.KafkaStreams - stream-client [wikipedia-activity-monitor] State transition from REBALANCING to RUNNING
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,141] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Found no committed offset for partition wikipedia.parsed-1
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,141] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-38 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	linger.ms = 500
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Found no committed offset for partition wikipedia.parsed-0
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,153] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-36 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	max.block.ms = 9223372036854775807
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Resetting offset for partition wikipedia.parsed-1 to offset 0.
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-48 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,200] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [kafka-coordinator-heartbeat-thread | wikipedia-activity-monitor] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=wikipedia-activity-monitor-StreamThread-1-consumer, groupId=wikipedia-activity-monitor] Resetting offset for partition wikipedia.parsed-0 to offset 0.
[32mcontrol-center                 |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,202] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor - creating interceptor
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,202] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig - MonitoringInterceptorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,206] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,206] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,206] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,207] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-43 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,213] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-14 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,260] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,261] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[34mstreams-demo                   |[0m 	acks = all
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,262] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-44 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,262] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-39 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,262] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,262] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	buffer.memory = 33554432
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-45 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,262] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	retries = 2147483647
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,265] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-30 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	client.id = confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-consumer
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,269] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	compression.type = lz4
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-26 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,269] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-29 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,270] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-34 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,270] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,952] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,270] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-32 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34mstreams-demo                   |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,270] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Changed partition __consumer_offsets-40 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34mstreams-demo                   |[0m 	linger.ms = 500
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,270] INFO [Partition __consumer_offsets-46 broker=1] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m 	max.block.ms = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,326] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-46 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34mstreams-demo                   |[0m 	max.in.flight.requests.per.connection = 1
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,331] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m 	max.request.size = 10485760
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,331] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,332] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,332] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,332] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,333] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,333] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,241] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,339] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-8 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,352] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,364] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,365] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	retries = 10
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,414] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,414] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	retry.backoff.ms = 500
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,414] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,421] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,437] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-24 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,443] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,443] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,458] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,458] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,458] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,458] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,459] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,509] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-2 (last update controller epoch 1) (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,242] INFO Kafka startTimeMs: 1590005128242 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,512] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
[36;1mconnect                        |[0m [2020-05-20 20:05:28,507] INFO Created topic (name=connect-statuses, numPartitions=5, replicationFactor=2, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at kafka1:9091,kafka2:9092 (org.apache.kafka.connect.util.TopicAdmin)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,521] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,509] INFO ProducerConfig values: 
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[36;1mconnect                        |[0m 	acks = all
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,640] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,524] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[36;1mconnect                        |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,640] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,528] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,640] INFO Kafka startTimeMs: 1590005082640 (org.apache.kafka.common.utils.AppInfoParser)
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,529] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,641] INFO ConsumerConfig values: 
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,529] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,529] INFO [Partition __consumer_offsets-40 broker=1] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect                        |[0m 	client.id = 
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,536] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-40 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[32mcontrol-center                 |[0m 	auto.offset.reset = earliest
[36;1mconnect                        |[0m 	compression.type = none
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,543] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,548] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	check.crcs = true
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,954] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,549] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[36;1mconnect                        |[0m 	enable.idempotence = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,550] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-license-manager-5-3-1-1-global-consumer
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[36;1mconnect                        |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,550] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	client.rack = 
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,550] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,550] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[34mstreams-demo                   |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[36;1mconnect                        |[0m 	max.block.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,554] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-18 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	enable.auto.commit = false
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,557] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[36;1mconnect                        |[0m 	max.request.size = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,558] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,559] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,559] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[32mcontrol-center                 |[0m 	group.id = null
[34mstreams-demo                   |[0m 	transaction.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,559] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[34mstreams-demo                   |[0m 	transactional.id = null
[32mcontrol-center                 |[0m 	group.instance.id = null
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,559] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,955] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[34mstreams-demo                   |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,559] INFO [Partition __consumer_offsets-34 broker=1] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,562] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-34 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = false
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,570] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,571] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[32mcontrol-center                 |[0m 	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,571] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005155012
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,571] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 21600000
[34mstreams-demo                   |[0m [wikipedia-activity-monitor-StreamThread-1] INFO io.confluent.monitoring.clients.interceptor.MonitoringInterceptor - interceptor=confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-consumer created for client_id=wikipedia-activity-monitor-StreamThread-1-consumer client_type=CONSUMER session= cluster=lbUe4hq7QeWfnY0W4R-PhA group=wikipedia-activity-monitor
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[36;1mconnect                        |[0m 	retries = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,572] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	max.poll.records = 100
[34mstreams-demo                   |[0m [kafka-producer-network-thread | confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-consumer] INFO org.apache.kafka.clients.Metadata - [Producer clientId=confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-consumer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,572] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor - creating interceptor
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,572] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	metric.reporters = []
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig - MonitoringInterceptorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,625] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-12 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34mstreams-demo                   |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[34;1mkafka2                         |[0m [2020-05-20 20:04:21,956] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,631] INFO Successfully submitted metrics to Confluent via secure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34mstreams-demo                   |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,008] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,634] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34mstreams-demo                   |[0m 
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,008] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,635] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34mstreams-demo                   |[0m 	acks = all
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34mstreams-demo                   |[0m 	batch.size = 16384
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,008] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,642] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,008] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[34mstreams-demo                   |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,644] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[34mstreams-demo                   |[0m 	buffer.memory = 33554432
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,644] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[34mstreams-demo                   |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,644] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	request.timeout.ms = 960032
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34mstreams-demo                   |[0m 	client.id = confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-producer
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,645] INFO [Partition __consumer_offsets-28 broker=1] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34mstreams-demo                   |[0m 	compression.type = lz4
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,654] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-28 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[34mstreams-demo                   |[0m 	connections.max.idle.ms = 540000
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,703] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34mstreams-demo                   |[0m 	delivery.timeout.ms = 120000
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,705] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m 	enable.idempotence = false
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,706] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34mstreams-demo                   |[0m 	interceptor.classes = []
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,711] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34mstreams-demo                   |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,711] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34mstreams-demo                   |[0m 	linger.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,712] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34mstreams-demo                   |[0m 	max.block.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,712] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34mstreams-demo                   |[0m 	max.in.flight.requests.per.connection = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,717] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-38 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,721] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.key.password = null
[34mstreams-demo                   |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,725] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34mstreams-demo                   |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,733] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34mstreams-demo                   |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,734] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,734] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34mstreams-demo                   |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,735] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34mstreams-demo                   |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,748] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,757] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-44 (last update controller epoch 1) (state.change.logger)
[34mstreams-demo                   |[0m 	receive.buffer.bytes = 32768
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,801] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34mstreams-demo                   |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m 	session.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,803] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[34mstreams-demo                   |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,825] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34mstreams-demo                   |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,826] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	retries = 10
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,826] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34mstreams-demo                   |[0m 	retry.backoff.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,826] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,826] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.jaas.config = [hidden]
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,843] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-6 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34mstreams-demo                   |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,847] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,009] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[34mstreams-demo                   |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,847] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34mstreams-demo                   |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,855] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,855] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,855] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,855] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[34mstreams-demo                   |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,855] INFO [Partition __consumer_offsets-16 broker=1] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,858] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-16 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-49 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,862] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,010] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-38 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,863] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-16 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,863] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-27 (state.change.logger)
[34mstreams-demo                   |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m [2020-05-20 20:04:42,717] INFO [Producer clientId=_confluent-controlcenter-license-manager-5-3-1-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,864] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-8 (state.change.logger)
[34mstreams-demo                   |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,043] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,864] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-19 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,044] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,864] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[34mstreams-demo                   |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-13 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,044] INFO Kafka startTimeMs: 1590005083043 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,864] INFO [Partition __consumer_offsets-22 broker=1] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34mstreams-demo                   |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,107] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-3-1-1-global-consumer, groupId=null] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,866] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-22 (last update controller epoch 1) (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-46 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,172] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-3-1-1-global-consumer, groupId=null] Subscribed to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,869] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-35 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,172] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-3-1-1-global-consumer, groupId=null] Seeking to EARLIEST offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,870] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34mstreams-demo                   |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-24 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,232] INFO [Consumer clientId=_confluent-controlcenter-license-manager-5-3-1-1-global-consumer, groupId=null] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34mstreams-demo                   |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,870] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-5 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,233] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,871] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-43 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,233] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,871] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-21 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,233] INFO Started License Store (io.confluent.license.LicenseStore)
[34mstreams-demo                   |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,871] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-32 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:43,741] INFO AdminClientConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,871] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-10 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,873] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-32 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-37 (state.change.logger)
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-license-manager-5-3-1-1
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-48 (state.change.logger)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[34mstreams-demo                   |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-48 (state.change.logger)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34mstreams-demo                   |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-26 (state.change.logger)
[34mstreams-demo                   |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,011] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-40 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-42 (state.change.logger)
[34mstreams-demo                   |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-18 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-29 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,874] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-20 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-7 (state.change.logger)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-36 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m 
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-23 (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-14 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 5.3.0-ce
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-45 (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-30 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: c1fadac00118dad6
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-34 (state.change.logger)
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-46 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1590005172911
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-26 (state.change.logger)
[32mcontrol-center                 |[0m 	retries = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-8 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | wikipedia-activity-monitor-StreamThread-1-producer] INFO io.confluent.monitoring.clients.interceptor.MonitoringInterceptor - interceptor=confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-producer created for client_id=wikipedia-activity-monitor-StreamThread-1-producer client_type=PRODUCER session= cluster=lbUe4hq7QeWfnY0W4R-PhA
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-15 (state.change.logger)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-24 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34mstreams-demo                   |[0m [kafka-producer-network-thread | confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-producer] INFO org.apache.kafka.clients.Metadata - [Producer clientId=confluent.monitoring.interceptor.wikipedia-activity-monitor-StreamThread-1-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-4 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,012] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-42 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-40 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-31 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-9 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-34 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-20 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m [2020-05-20 20:05:28,928] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-12 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-28 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-1 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-38 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-28 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-44 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-17 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-6 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-39 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-44 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-32 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-29 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-36 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-45 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-47 (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-7 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,014] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-3 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-23 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-25 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-14 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-30 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-39 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-17 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-41 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-22 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-33 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-33 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-49 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-11 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-11 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,015] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition __consumer_offsets-0 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-27 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,017] WARN The replication factor of topic __confluent.support.metrics is 2, which is less than the desired replication factor of 3.  If you happen to add more brokers to this cluster, then it is important to increase the replication factor of the topic to eventually 3 to ensure reliable and durable metrics collection. (io.confluent.support.metrics.common.kafka.KafkaUtilities)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-43 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,022] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:28,929] INFO Kafka startTimeMs: 1590005128929 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-5 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,033] INFO ProducerConfig values: 
[36;1mconnect                        |[0m [2020-05-20 20:05:28,930] INFO ConsumerConfig values: 
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-21 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m 	acks = 1
[36;1mconnect                        |[0m 	allow.auto.create.topics = true
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-37 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m 	batch.size = 16384
[36;1mconnect                        |[0m 	auto.commit.interval.ms = 5000
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-15 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	auto.offset.reset = earliest
[34;1mkafka2                         |[0m 	bootstrap.servers = [PLAINTEXT://kafka1:10091, PLAINTEXT://kafka2:10092]
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-31 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m 	buffer.memory = 33554432
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-9 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	check.crcs = true
[34;1mkafka2                         |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-47 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m 	client.id = 
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-19 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m 	compression.type = none
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,016] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-35 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	client.rack = 
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,016] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,016] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-25 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m 	delivery.timeout.ms = 120000
[36;1mconnect                        |[0m 	default.api.timeout.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,016] INFO Kafka startTimeMs: 1590005084016 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m 	enable.idempotence = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-41 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	enable.auto.commit = false
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,356] INFO Trial license for Confluent Enterprise expires in 29 days on 2020-06-19. (io.confluent.license.LicenseManager)
[34;1mkafka2                         |[0m 	interceptor.classes = []
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,357] INFO License: Trial license for Confluent Enterprise expires in 29 days on 2020-06-19. (io.confluent.controlcenter.license.LicenseModule)
[34;1mkafka2                         |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect                        |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,875] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-3 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,357] INFO License: Trial license for Confluent Enterprise expires in 29 days on 2020-06-19. (io.confluent.controlcenter.license.LicenseModule)
[34;1mkafka2                         |[0m 	linger.ms = 0
[36;1mconnect                        |[0m 	fetch.max.bytes = 52428800
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,876] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-13 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,639] INFO Logging initialized @22563ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[34;1mkafka2                         |[0m 	max.block.ms = 10000
[36;1mconnect                        |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,876] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,641] INFO RestConfig values: 
[34;1mkafka2                         |[0m 	max.in.flight.requests.per.connection = 5
[36;1mconnect                        |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,915] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m 	max.request.size = 1048576
[32mcontrol-center                 |[0m 	access.control.allow.headers = 
[36;1mconnect                        |[0m 	group.id = connect
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,915] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	access.control.allow.methods = 
[36;1mconnect                        |[0m 	group.instance.id = null
[32mcontrol-center                 |[0m 	access.control.allow.origin = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,916] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[34;1mkafka2                         |[0m 	metric.reporters = []
[36;1mconnect                        |[0m 	interceptor.classes = []
[32mcontrol-center                 |[0m 	authentication.method = NONE
[32mcontrol-center                 |[0m 	authentication.realm = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,916] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	internal.leave.group.on.close = true
[34;1mkafka2                         |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,916] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	authentication.roles = [*]
[36;1mconnect                        |[0m 	isolation.level = read_uncommitted
[34;1mkafka2                         |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,917] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	authentication.skip.paths = []
[36;1mconnect                        |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,938] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m 	compression.enable = true
[36;1mconnect                        |[0m 	max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,939] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,940] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[32mcontrol-center                 |[0m 	debug = false
[36;1mconnect                        |[0m 	max.poll.interval.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,940] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m 	receive.buffer.bytes = 32768
[36;1mconnect                        |[0m 	max.poll.records = 500
[32mcontrol-center                 |[0m 	idle.timeout.ms = 30000
[34;1mkafka2                         |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,944] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	listeners = [http://0.0.0.0:9021, https://0.0.0.0:9022]
[34;1mkafka2                         |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,944] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	metrics.jmx.prefix = rest-utils
[34;1mkafka2                         |[0m 	request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,953] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m 	retries = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,954] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,955] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	metrics.tag.map = []
[34;1mkafka2                         |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,955] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	port = 9021
[34;1mkafka2                         |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,955] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	request.logger.name = io.confluent.rest-utils.requests
[34;1mkafka2                         |[0m 	sasl.jaas.config = null
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[32mcontrol-center                 |[0m 	resource.extension.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,956] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,959] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	response.mediatype.default = application/json
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[32mcontrol-center                 |[0m 	response.mediatype.preferred = [application/json]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,959] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m 	rest.servlet.initializor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,960] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	shutdown.graceful.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,960] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,960] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = []
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m 	ssl.client.auth = false
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,961] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	ssl.client.authentication = NONE
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,965] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = []
[34;1mkafka2                         |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,965] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = null
[34;1mkafka2                         |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,966] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,966] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = 
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,966] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m 	sasl.mechanism = GSSAPI
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,966] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m 	security.protocol = PLAINTEXT
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,969] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,970] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,970] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m 	ssl.provider = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,971] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,971] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,971] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,974] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m 	ssl.key.password = null
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,974] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[34;1mkafka2                         |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,975] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m 	ssl.keystore.location = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,975] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	websocket.path.prefix = /ws
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m 	ssl.keystore.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,975] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	websocket.servlet.initializor.classes = []
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,975] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m  (io.confluent.rest.RestConfig)
[36;1mconnect                        |[0m 	ssl.key.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:24,996] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m [2020-05-20 20:04:44,809] INFO action=starting topology=monitoring (io.confluent.controlcenter.ControlCenter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,025] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:45,040] INFO AdminClientConfig values: 
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,027] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,031] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m 	ssl.truststore.location = null
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-admin
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,036] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m 	ssl.truststore.password = null
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,036] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[34;1mkafka2                         |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,048] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m 	transaction.timeout.ms = 60000
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,048] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m 	transactional.id = null
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,065] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,065] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,065] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-27 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,066] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,069] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,006] INFO [Producer clientId=producer-2] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,069] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,404] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-44 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,070] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-37 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,070] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	retries = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,071] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,046] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,071] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,047] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-48 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,073] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,047] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,074] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,047] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-42 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,074] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,047] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-31 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,075] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,047] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-28 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,075] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,047] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-32 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,075] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,048] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-34 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,123] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,048] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,124] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,125] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,048] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,125] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,048] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,125] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,048] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-35 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,125] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,048] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,049] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,134] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,049] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,134] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,049] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-43 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,135] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,049] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-47 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,148] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,049] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-46 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,149] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,049] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-40 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,149] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,165] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-25 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,167] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,168] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-41 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,168] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,050] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,051] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-30 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,168] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,051] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-33 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,169] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,051] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,172] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,051] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,220] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,051] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,220] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,051] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,221] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,052] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-38 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:45,706] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,052] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-36 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,221] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,052] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-26 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:45,706] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,221] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:45,706] INFO Kafka startTimeMs: 1590005085706 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,052] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-49 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,233] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:45,716] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,052] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:45,717] INFO ConsumerConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,233] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,053] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-39 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,234] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,053] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,234] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] INFO Kafka startTimeMs: 1590005062040 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	auto.offset.reset = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,234] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,235] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-29 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,257] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,257] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-restore-consumer
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,329] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	client.rack = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,331] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,331] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	enable.auto.commit = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,331] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition __consumer_offsets-45 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[36;1mconnect                        |[0m [2020-05-20 20:05:29,405] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,351] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-42 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,353] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-40 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,353] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-23 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,353] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-20 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	group.id = null
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-9 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,354] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-15 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,354] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,425] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-14 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,406] INFO Kafka startTimeMs: 1590005129406 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,432] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-8 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,433] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,425] INFO [Consumer clientId=consumer-2, groupId=connect] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-22 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,434] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,446] INFO [Consumer clientId=consumer-2, groupId=connect] Subscribed to partition(s): connect-statuses-0, connect-statuses-4, connect-statuses-1, connect-statuses-2, connect-statuses-3 (org.apache.kafka.clients.consumer.KafkaConsumer)
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,054] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-30 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,434] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,446] INFO [Consumer clientId=consumer-2, groupId=connect] Seeking to EARLIEST offset of partition connect-statuses-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-10 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,434] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,446] INFO [Consumer clientId=consumer-2, groupId=connect] Seeking to EARLIEST offset of partition connect-statuses-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 21600000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,442] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-7 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	max.poll.records = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-29 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,446] INFO [Consumer clientId=consumer-2, groupId=connect] Seeking to EARLIEST offset of partition connect-statuses-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,495] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-26 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,446] INFO [Consumer clientId=consumer-2, groupId=connect] Seeking to EARLIEST offset of partition connect-statuses-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,496] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,496] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-44 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	metric.reporters = []
[36;1mconnect                        |[0m [2020-05-20 20:05:29,446] INFO [Consumer clientId=consumer-2, groupId=connect] Seeking to EARLIEST offset of partition connect-statuses-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,497] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,599] INFO [Consumer clientId=consumer-2, groupId=connect] Resetting offset for partition connect-statuses-3 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-18 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,497] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,600] INFO [Consumer clientId=consumer-2, groupId=connect] Resetting offset for partition connect-statuses-1 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-39 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,506] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,600] INFO [Consumer clientId=consumer-2, groupId=connect] Resetting offset for partition connect-statuses-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-46 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,601] INFO [Consumer clientId=consumer-2, groupId=connect] Resetting offset for partition connect-statuses-4 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,507] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-27 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,601] INFO [Consumer clientId=consumer-2, groupId=connect] Resetting offset for partition connect-statuses-2 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,513] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-31 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,513] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,601] INFO Finished reading KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-49 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,513] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,601] INFO Started KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-4 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,514] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,602] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[32mcontrol-center                 |[0m 	request.timeout.ms = 960032
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,520] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-38 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,602] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-2 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:29,603] INFO AdminClientConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,529] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-34 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-11 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,536] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-13 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,536] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-17 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,537] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-1 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,537] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-25 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,597] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,055] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-43 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,601] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-19 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-48 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,602] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-35 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,602] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-12 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,603] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,603] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-28 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,614] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-6 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,616] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,056] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-37 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	retries = 5
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,617] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-5 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,619] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,620] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-24 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	session.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-47 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-16 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,624] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-32 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,628] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,057] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-33 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,058] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-3 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,638] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,058] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-21 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,638] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,058] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-45 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,639] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,058] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-41 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,639] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,058] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition __consumer_offsets-36 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,641] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-17, __consumer_offsets-39, __consumer_offsets-43, __consumer_offsets-21, __consumer_offsets-25, __consumer_offsets-3, __consumer_offsets-47, __consumer_offsets-29, __consumer_offsets-37, __consumer_offsets-7, __consumer_offsets-11, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-23, __consumer_offsets-45, __consumer_offsets-19, __consumer_offsets-49, __consumer_offsets-27, __consumer_offsets-1, __consumer_offsets-31, __consumer_offsets-9, __consumer_offsets-5, __consumer_offsets-35, __consumer_offsets-13) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,095] INFO [Log partition=__confluent.support.metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 487 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,641] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-25 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,641] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-31 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,101] INFO Created log for partition __confluent.support.metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 31536000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,641] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-37 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,103] INFO [Partition __confluent.support.metrics-0 broker=2] No checkpointed highwatermark is found for partition __confluent.support.metrics-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,105] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,641] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-43 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,106] INFO Replica loaded for partition __confluent.support.metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-5 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,138] INFO [Partition __confluent.support.metrics-0 broker=2] __confluent.support.metrics-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-49 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,206] WARN [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {__confluent.support.metrics=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient)
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-11 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,222] INFO [Producer clientId=producer-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-17 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,404] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,223] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 1 for partition __confluent.support.metrics-0 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-23 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,404] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-29 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,228] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 1 from controller 2 epoch 1 for the become-leader transition for partition __confluent.support.metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,404] INFO Kafka startTimeMs: 1590005086404 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-35 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,243] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=__confluent.support.metrics,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 1 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,309] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __confluent.support.metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,405] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] Creating shared producer client (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-41 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,310] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 2 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,642] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-3 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-13 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,405] INFO ProducerConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,643] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-9 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-46 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	acks = all
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,643] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-47 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-9 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m 	batch.size = 16384
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,643] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-15 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-42 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-21 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-21 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-27 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-17 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m 	buffer.memory = 33554432
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-33 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-30 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-26 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-producer
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-39 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-5 (state.change.logger)
[32mcontrol-center                 |[0m 	compression.type = lz4
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-45 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-38 (state.change.logger)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-7 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-1 (state.change.logger)
[32mcontrol-center                 |[0m 	delivery.timeout.ms = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-13 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-34 (state.change.logger)
[32mcontrol-center                 |[0m 	enable.idempotence = false
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,644] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-19 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-16 (state.change.logger)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-25 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-45 (state.change.logger)
[32mcontrol-center                 |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-31 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-12 (state.change.logger)
[32mcontrol-center                 |[0m 	linger.ms = 500
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-37 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	max.block.ms = 9223372036854775807
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-41 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-43 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	max.in.flight.requests.per.connection = 5
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-5 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-24 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-49 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	max.request.size = 10485760
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-20 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-49 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-11 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-17 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metric.reporters = []
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-29 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-23 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-25 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-29 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-8 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-35 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-37 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-41 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,334] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-33 (state.change.logger)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-3 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-15 (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-9 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-48 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-47 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-11 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-15 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	retries = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-44 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-21 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-23 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-27 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-19 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-33 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-32 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-1 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-28 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-39 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-7 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-45 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-40 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-7 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-3 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-13 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-36 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,645] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-19 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-47 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(__consumer_offsets-21 -> (offset=0, leaderEpoch=0), __consumer_offsets-27 -> (offset=0, leaderEpoch=0), __consumer_offsets-7 -> (offset=0, leaderEpoch=0), __consumer_offsets-9 -> (offset=0, leaderEpoch=0), __consumer_offsets-25 -> (offset=0, leaderEpoch=0), __consumer_offsets-35 -> (offset=0, leaderEpoch=0), __consumer_offsets-41 -> (offset=0, leaderEpoch=0), __consumer_offsets-33 -> (offset=0, leaderEpoch=0), __consumer_offsets-23 -> (offset=0, leaderEpoch=0), __consumer_offsets-49 -> (offset=0, leaderEpoch=0), __consumer_offsets-47 -> (offset=0, leaderEpoch=0), __consumer_offsets-31 -> (offset=0, leaderEpoch=0), __consumer_offsets-3 -> (offset=0, leaderEpoch=0), __consumer_offsets-37 -> (offset=0, leaderEpoch=0), __consumer_offsets-15 -> (offset=0, leaderEpoch=0), __consumer_offsets-17 -> (offset=0, leaderEpoch=0), __consumer_offsets-19 -> (offset=0, leaderEpoch=0), __consumer_offsets-11 -> (offset=0, leaderEpoch=0), __consumer_offsets-13 -> (offset=0, leaderEpoch=0), __consumer_offsets-43 -> (offset=0, leaderEpoch=0), __consumer_offsets-39 -> (offset=0, leaderEpoch=0), __consumer_offsets-45 -> (offset=0, leaderEpoch=0), __consumer_offsets-1 -> (offset=0, leaderEpoch=0), __consumer_offsets-5 -> (offset=0, leaderEpoch=0), __consumer_offsets-29 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-14 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-25 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-43 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-31 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-10 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-37 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-22 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-43 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-18 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-5 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-31 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-49 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-27 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-11 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-39 (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-17 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-6 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-23 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-35 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-29 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,335] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 3 from controller 2 epoch 1 for partition __consumer_offsets-2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,649] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-35 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,562] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-41 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,562] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-3 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,562] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-9 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-47 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-15 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-21 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-27 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-33 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-39 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-45 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-7 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,563] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-13 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,120] INFO Kafka startTimeMs: 1590005130120 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-19 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,295] INFO Created topic (name=connect-configs, numPartitions=1, replicationFactor=2, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at kafka1:9091,kafka2:9092 (org.apache.kafka.connect.util.TopicAdmin)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-29 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:30,297] INFO ProducerConfig values: 
[32mcontrol-center                 |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-45 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	acks = all
[32mcontrol-center                 |[0m 	transactional.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-7 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
[36;1mconnect                        |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-23 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,718] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-39 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,718] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-17 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,718] INFO Kafka startTimeMs: 1590005086718 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-33 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	compression.type = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,719] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-49 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,720] INFO ConsumerConfig values: 
[36;1mconnect                        |[0m 	delivery.timeout.ms = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-11 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,564] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[36;1mconnect                        |[0m 	enable.idempotence = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-27 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,612] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-31, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	interceptor.classes = []
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-43 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,648] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
[32mcontrol-center                 |[0m 	auto.offset.reset = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-5 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,649] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	check.crcs = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-21 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-37 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m 	max.block.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-15 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,650] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	client.id = _confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,651] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-31 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	client.rack = 
[36;1mconnect                        |[0m 	max.request.size = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,653] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-9 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,654] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[36;1mconnect                        |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-47 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,655] INFO [Partition __consumer_offsets-29 broker=2] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	enable.auto.commit = false
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-19 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,656] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer)
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,658] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-29 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-35 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,660] INFO Successfully submitted metrics to Kafka topic __confluent.support.metrics (io.confluent.support.metrics.submitters.KafkaSubmitter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-25 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,661] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,650] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-41 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,662] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,651] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-3 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	group.id = _confluent-controlcenter-5-3-1-1
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,663] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,651] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-13 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,663] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,653] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,663] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,654] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	retries = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,663] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,654] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,663] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,666] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-45 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,669] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,670] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 21600000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,670] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	max.poll.records = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,671] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,671] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,671] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,671] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,655] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,721] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-7 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,728] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,731] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,732] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,741] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,742] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,742] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m 	request.timeout.ms = 960032
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,742] INFO [Partition __consumer_offsets-23 broker=2] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,746] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-23 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,755] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,757] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,758] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	ssl.key.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,759] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,759] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,656] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,759] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,657] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,759] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,795] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-39 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,803] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,803] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,804] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,805] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,805] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,805] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,806] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,818] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,828] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,829] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	transactional.id = null
[32mcontrol-center                 |[0m 	session.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,831] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,834] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,834] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,834] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,835] INFO [Partition __consumer_offsets-17 broker=2] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,840] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-17 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,858] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,859] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,901] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,901] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,901] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,902] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,902] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,906] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-33 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,909] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,910] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,910] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,911] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,658] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,911] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,721] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,911] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,911] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:46,799] INFO [Producer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,922] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-49 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,133] WARN The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,934] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,133] WARN The configuration 'admin.retries' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,934] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,133] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,133] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,935] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,936] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,133] INFO Kafka startTimeMs: 1590005087133 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,135] INFO stream-client [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,936] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,135] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,135] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,936] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,135] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,936] INFO [Partition __consumer_offsets-11 broker=2] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,135] INFO tocheck=[Store{name=KSTREAM-OUTEROTHER-0000000105-store, rollup=false}, Store{name=aggregate-topic-partition-store, rollup=false}, Store{name=MonitoringTriggerStore, rollup=false}, Store{name=KSTREAM-OUTERTHIS-0000000104-store, rollup=false}, Store{name=MonitoringMessageAggregatorWindows, rollup=true}, Store{name=monitoring-aggregate-rekey-store, rollup=false}, Store{name=TriggerActionsStore, rollup=false}, Store{name=TriggerEventsStore, rollup=false}, Store{name=MonitoringVerifierStore, rollup=false}, Store{name=Group, rollup=true}, Store{name=MetricsAggregateStore, rollup=false}, Store{name=MonitoringStream, rollup=true}, Store{name=aggregatedTopicPartitionTableWindows, rollup=true}, Store{name=group-aggregate-store, rollup=true}, Store{name=AlertHistoryStore, rollup=false}] (io.confluent.controlcenter.streams.KafkaStreamsManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:22,950] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-11 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,136] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,007] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,136] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Subscribed to pattern: '_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition|_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition|_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition|_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition|_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition|_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey|_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition|_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition|_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey|_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey|_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey|_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store|_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey|_confluent-metrics|_confluent-monitoring' (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,017] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,115] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,017] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,204] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,018] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,216] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,018] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,219] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,018] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,219] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,018] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,220] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,026] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-27 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,220] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] partition revocation took 0 ms.
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,031] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m 	suspended active tasks: []
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,031] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m 	suspended standby tasks: [] (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,041] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=__confluent.support.metrics,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 1 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,220] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,108] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:47,307] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,128] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:48,136] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,128] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:48,136] INFO tocheck=[Store{name=KSTREAM-OUTEROTHER-0000000105-store, rollup=false}, Store{name=aggregate-topic-partition-store, rollup=false}, Store{name=MonitoringTriggerStore, rollup=false}, Store{name=KSTREAM-OUTERTHIS-0000000104-store, rollup=false}, Store{name=MonitoringMessageAggregatorWindows, rollup=true}, Store{name=monitoring-aggregate-rekey-store, rollup=false}, Store{name=TriggerActionsStore, rollup=false}, Store{name=TriggerEventsStore, rollup=false}, Store{name=MonitoringVerifierStore, rollup=false}, Store{name=Group, rollup=true}, Store{name=MetricsAggregateStore, rollup=false}, Store{name=MonitoringStream, rollup=true}, Store{name=aggregatedTopicPartitionTableWindows, rollup=true}, Store{name=group-aggregate-store, rollup=true}, Store{name=AlertHistoryStore, rollup=false}] (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,129] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:48,136] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,130] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:49,137] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,133] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-43 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,133] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 2 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:49,137] INFO tocheck=[Store{name=KSTREAM-OUTEROTHER-0000000105-store, rollup=false}, Store{name=aggregate-topic-partition-store, rollup=false}, Store{name=MonitoringTriggerStore, rollup=false}, Store{name=KSTREAM-OUTERTHIS-0000000104-store, rollup=false}, Store{name=MonitoringMessageAggregatorWindows, rollup=true}, Store{name=monitoring-aggregate-rekey-store, rollup=false}, Store{name=TriggerActionsStore, rollup=false}, Store{name=TriggerEventsStore, rollup=false}, Store{name=MonitoringVerifierStore, rollup=false}, Store{name=Group, rollup=true}, Store{name=MetricsAggregateStore, rollup=false}, Store{name=MonitoringStream, rollup=true}, Store{name=aggregatedTopicPartitionTableWindows, rollup=true}, Store{name=group-aggregate-store, rollup=true}, Store{name=AlertHistoryStore, rollup=false}] (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,139] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:49,137] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,200] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,137] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,201] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,137] INFO tocheck=[Store{name=KSTREAM-OUTEROTHER-0000000105-store, rollup=false}, Store{name=aggregate-topic-partition-store, rollup=false}, Store{name=MonitoringTriggerStore, rollup=false}, Store{name=KSTREAM-OUTERTHIS-0000000104-store, rollup=false}, Store{name=MonitoringMessageAggregatorWindows, rollup=true}, Store{name=monitoring-aggregate-rekey-store, rollup=false}, Store{name=TriggerActionsStore, rollup=false}, Store{name=TriggerEventsStore, rollup=false}, Store{name=MonitoringVerifierStore, rollup=false}, Store{name=Group, rollup=true}, Store{name=MetricsAggregateStore, rollup=false}, Store{name=MonitoringStream, rollup=true}, Store{name=aggregatedTopicPartitionTableWindows, rollup=true}, Store{name=group-aggregate-store, rollup=true}, Store{name=AlertHistoryStore, rollup=false}] (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,201] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,137] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,201] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,716] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer] Assigned tasks to clients as {64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf=[activeTasks: ([0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0, 11_0, 12_0]) standbyTasks: ([]) assignedTasks: ([0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0, 11_0, 12_0]) prevActiveTasks: ([]) prevStandbyTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,201] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,717] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: [_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition, _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition, _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,201] INFO [Partition __consumer_offsets-5 broker=2] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,204] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-5 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,734] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,211] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,745] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,746] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,211] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,735] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Setting newly assigned partitions: _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0, _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0, _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0, _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, _confluent-monitoring-0, _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0, _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0, _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, _confluent-metrics-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,212] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,735] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,746] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] partition assignment took 11 ms.
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,213] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	current active tasks: [0_0, 1_0, 2_0, 3_0, 4_0, 5_0, 6_0, 7_0, 8_0, 9_0, 10_0, 11_0, 12_0]
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,753] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 99 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] INFO Kafka startTimeMs: 1590005131116 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,116] INFO ConsumerConfig values: 
[32mcontrol-center                 |[0m 	current standby tasks: []
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,213] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	allow.auto.create.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m 	previous active tasks: []
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,213] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	auto.commit.interval.ms = 5000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m  (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,213] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	auto.offset.reset = earliest
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,754] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,218] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-21 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,246] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	check.crcs = true
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,259] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,755] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,260] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,756] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	client.rack = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,312] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,756] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,312] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,756] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,312] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	default.api.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,814] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 58 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,313] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	enable.auto.commit = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,814] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,321] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-37 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,326] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	fetch.max.bytes = 52428800
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,326] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,337] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,748] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-metrics-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,337] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	group.id = connect
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,749] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Setting offset for partition _confluent-monitoring-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=kafka1:9091 (id: 1 rack: r1), epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,337] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	group.instance.id = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,820] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,337] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,821] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,337] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,821] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,342] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-15 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,821] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	internal.leave.group.on.close = true
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,414] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,822] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	isolation.level = read_uncommitted
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,822] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,415] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	max.partition.fetch.bytes = 1048576
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,822] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,416] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	max.poll.interval.ms = 300000
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,416] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-25. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	max.poll.records = 500
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,432] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-31. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,433] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-37. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,433] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-43. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,439] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-31 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-5. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,443] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-49. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,444] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-11. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] No custom setting defined for topic '_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition' using original config 'earliest' for offset reset (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,444] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-17. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,750] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] Setting topic '_confluent-metrics' to consume from earliest offset (org.apache.kafka.streams.processor.internals.StreamThread)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,447] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-23. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,447] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-29. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,447] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-35. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,447] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-41. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,454] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-9 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-3. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,497] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-9. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,498] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-47. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,498] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-15. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,499] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,824] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-21. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,499] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-27. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,499] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-33. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,499] INFO [Partition __consumer_offsets-47 broker=2] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,751] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Seeking to EARLIEST offset of partition _confluent-metrics-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,516] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-47 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-1. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,757] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,531] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-39. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,531] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-45. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,808] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,542] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,543] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,814] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,819] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-7. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,544] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,544] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,824] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-13. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,544] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,827] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,825] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-19. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-17 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,829] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [Log partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,548] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-19 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-39 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,831] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,553] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [Log partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,834] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,553] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-21 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,895] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,554] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [Log partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,896] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,554] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-43 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,951] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,554] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [Log partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.key.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,555] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-25 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,555] INFO [Partition __consumer_offsets-35 broker=2] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:50,953] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Found no committed offset for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,558] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-35 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,043] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-restore-consumer, groupId=null] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-47 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,563] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,118] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,913] INFO [Log partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,563] INFO [Log partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,138] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,138] INFO tocheck=[Store{name=KSTREAM-OUTEROTHER-0000000105-store, rollup=false}, Store{name=aggregate-topic-partition-store, rollup=false}, Store{name=MonitoringTriggerStore, rollup=false}, Store{name=KSTREAM-OUTERTHIS-0000000104-store, rollup=false}, Store{name=MonitoringMessageAggregatorWindows, rollup=true}, Store{name=monitoring-aggregate-rekey-store, rollup=false}, Store{name=TriggerActionsStore, rollup=false}, Store{name=TriggerEventsStore, rollup=false}, Store{name=MonitoringVerifierStore, rollup=false}, Store{name=Group, rollup=true}, Store{name=MetricsAggregateStore, rollup=false}, Store{name=MonitoringStream, rollup=true}, Store{name=aggregatedTopicPartitionTableWindows, rollup=true}, Store{name=group-aggregate-store, rollup=true}, Store{name=AlertHistoryStore, rollup=false}] (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,564] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,138] INFO streams in state=REBALANCING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,612] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,215] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,612] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,216] INFO stream-thread [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,613] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-37 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,216] INFO stream-client [_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,613] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,225] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,623] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-25 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-29 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,630] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,225] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,631] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-33 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,305] INFO [Producer clientId=producer-3] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,632] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'log4j.loggers' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,632] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-41 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,632] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,632] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-11 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,632] INFO [Partition __consumer_offsets-41 broker=2] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-metrics-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,642] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-41 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,226] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-15 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,647] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,319] INFO name=metrics-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.count type=metrics cluster=lbUe4hq7QeWfnY0W4R-PhA value=0.0 (io.confluent.controlcenter.util.StreamProgressReporter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,648] INFO [Log partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-23 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,321] INFO name=metrics-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.rate type=metrics cluster=lbUe4hq7QeWfnY0W4R-PhA value=NaN (io.confluent.controlcenter.util.StreamProgressReporter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,651] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,321] INFO name=metrics-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.timestamp type=metrics cluster=lbUe4hq7QeWfnY0W4R-PhA value=1.7976931348623157E308 (io.confluent.controlcenter.util.StreamProgressReporter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,651] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-45 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,322] INFO name=metrics-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.min type=metrics cluster=lbUe4hq7QeWfnY0W4R-PhA value=1.7976931348623157E308 (io.confluent.controlcenter.util.StreamProgressReporter)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,652] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,928] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,652] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,928] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-19 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,652] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,928] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,657] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-3 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,929] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-27 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:51,929] INFO [Consumer clientId=_confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer, groupId=_confluent-controlcenter-5-3-1-1] Resetting offset for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,753] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,914] INFO [Log partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:52,139] INFO streams in state=RUNNING (io.confluent.controlcenter.streams.KafkaStreamsManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,763] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 104 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-49 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'rest.advertised.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:52,139] INFO tocheck=[Store{name=KSTREAM-OUTEROTHER-0000000105-store, rollup=false}, Store{name=aggregate-topic-partition-store, rollup=false}, Store{name=MonitoringTriggerStore, rollup=false}, Store{name=KSTREAM-OUTERTHIS-0000000104-store, rollup=false}, Store{name=MonitoringMessageAggregatorWindows, rollup=true}, Store{name=monitoring-aggregate-rekey-store, rollup=false}, Store{name=TriggerActionsStore, rollup=false}, Store{name=TriggerEventsStore, rollup=false}, Store{name=MonitoringVerifierStore, rollup=false}, Store{name=Group, rollup=true}, Store{name=MetricsAggregateStore, rollup=false}, Store{name=MonitoringStream, rollup=true}, Store{name=aggregatedTopicPartitionTableWindows, rollup=true}, Store{name=group-aggregate-store, rollup=true}, Store{name=AlertHistoryStore, rollup=false}] (io.confluent.controlcenter.streams.KafkaStreamsManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:04:53,194] INFO action=started topology=monitoring (io.confluent.controlcenter.ControlCenter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,766] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:53,195] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,766] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,766] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,766] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-31 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m 	client.id = 
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,767] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-13 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-29 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-45 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-35 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-7 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-13 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-23 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:25,915] INFO [Log partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-39 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:26,019] INFO [GroupCoordinator 1]: Preparing to rebalance group wikipedia-activity-monitor in state PreparingRebalance with old generation 0 (__consumer_offsets-14) (reason: Adding new member wikipedia-activity-monitor-StreamThread-1-consumer-97ae8bf2-f4b7-4081-aa38-37b038254db7 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-17 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:29,028] INFO [GroupCoordinator 1]: Stabilized group wikipedia-activity-monitor generation 1 (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-33 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:29,042] INFO [GroupCoordinator 1]: Assignment received from leader for group wikipedia-activity-monitor for generation 1 (kafka.coordinator.group.GroupCoordinator)
[32mcontrol-center                 |[0m 	retries = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-49 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,002] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 5 from controller 2 epoch 1 for partition _schemas-0 (state.change.logger)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,003] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 5 from controller 2 epoch 1 starting the become-leader transition for partition _schemas-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-11 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,003] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_schemas-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-27 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.client.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-43 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-5 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,014] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-21 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-37 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,014] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'consumer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-15 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,015] INFO Created log for partition _schemas-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-31 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,018] INFO [Partition _schemas-0 broker=1] No checkpointed highwatermark is found for partition _schemas-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-9 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,018] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,018] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,996] WARN The configuration 'producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-47 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,018] INFO [Partition _schemas-0 broker=1] _schemas-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'listeners' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,815] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-19 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,021] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 5 for partition _schemas-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,816] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-35 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,021] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 5 from controller 2 epoch 1 for the become-leader transition for partition _schemas-0 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,816] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-25 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:30,027] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _schemas-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 6 (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'producer.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,816] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-41 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'producer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,973] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 7 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,816] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-3 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,974] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 7 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,816] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-leader transition for partition __consumer_offsets-13 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,974] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,977] INFO [Log partition=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,977] INFO [Log partition=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'consumer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-48 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,978] INFO Created log for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-10 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-26 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,979] INFO [Partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'consumer.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-42 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,979] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,979] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-4 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] WARN The configuration 'log4j.root.loglevel' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-20 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,979] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 7 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-36 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:31,997] INFO Kafka startTimeMs: 1590005131997 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,979] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 as part of become-follower request with correlation id 7 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,015] INFO [Consumer clientId=consumer-3, groupId=connect] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-14 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,980] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,095] INFO [Consumer clientId=consumer-3, groupId=connect] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-30 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,980] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 7 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,980] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 7 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,095] INFO [Consumer clientId=consumer-3, groupId=connect] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:31,982] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-46 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-8 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m [2020-05-20 20:05:32,118] INFO [Consumer clientId=consumer-3, groupId=connect] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,033] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-24 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m [2020-05-20 20:05:32,118] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,033] INFO [Log partition=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-2 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m [2020-05-20 20:05:32,118] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-40 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,039] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 9 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-18 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,118] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,040] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 9 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-34 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,118] INFO [Worker clientId=connect-1, groupId=connect] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,040] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-12 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,207] INFO [Worker clientId=connect-1, groupId=connect] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,046] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-28 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,207] INFO [Worker clientId=connect-1, groupId=connect] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,047] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-38 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,210] INFO [Worker clientId=connect-1, groupId=connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-44 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,047] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,210] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,048] INFO [Partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-6 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:32,297] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-16 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'consumer.session.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:35,328] INFO [Worker clientId=connect-1, groupId=connect] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-22 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'producer.max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:35,329] INFO [Worker clientId=connect-1, groupId=connect] Joined group at generation 1 and got assignment: Assignment{error=0, leader='connect-1-534a2a13-2f66-4763-9455-ccc532644fa6', leaderUrl='https://connect:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 9 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,817] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 2 epoch 1 starting the become-follower transition for partition __consumer_offsets-32 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'producer.retries' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:35,329] INFO [Worker clientId=connect-1, groupId=connect] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 as part of become-follower request with correlation id 9 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,820] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:35,329] INFO [Worker clientId=connect-1, groupId=connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,836] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:36,502] INFO AbstractConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 9 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,837] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'producer.linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m  (org.apache.kafka.common.config.AbstractConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,049] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 9 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,837] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,112] WARN The configuration 'producer.delivery.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:36,721] INFO [Worker clientId=connect-1, groupId=connect] Connector wikipedia-irc config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,838] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,113] WARN The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,113] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 10 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,295] INFO [Worker clientId=connect-1, groupId=connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,842] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,113] WARN The configuration 'producer.compression.type' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,159] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 11 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,295] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,843] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,310] INFO [Worker clientId=connect-1, groupId=connect] Successfully joined group with generation 2 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,113] WARN The configuration 'num.stream.threads' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,857] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,161] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 11 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,311] INFO [Worker clientId=connect-1, groupId=connect] Joined group at generation 2 and got assignment: Assignment{error=0, leader='connect-1-534a2a13-2f66-4763-9455-ccc532644fa6', leaderUrl='https://connect:8083/', offset=1, connectorIds=[wikipedia-irc], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,113] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,857] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,161] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,311] INFO [Worker clientId=connect-1, groupId=connect] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,858] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,113] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,165] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,312] INFO [Worker clientId=connect-1, groupId=connect] Starting connector wikipedia-irc (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,859] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,165] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,113] INFO Kafka startTimeMs: 1590005094113 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,316] INFO ConnectorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,859] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,166] INFO Created log for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,310] INFO cluster lbUe4hq7QeWfnY0W4R-PhA registered with configuration controlcenter.cluster (io.confluent.controlcenter.kafka.ClusterManager)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,167] INFO [Partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,859] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,408] INFO Starting Health Check (io.confluent.controlcenter.ControlCenter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,167] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connector.class = com.github.cjmatta.kafka.connect.irc.IrcSourceConnector
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,408] INFO Starting Alert Manager (io.confluent.controlcenter.ControlCenter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,167] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,862] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,408] INFO Starting Consumer Offsets Fetch (io.confluent.controlcenter.ControlCenter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,863] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,167] INFO [Partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,418] WARN unable to check ulimit: Cannot run program "ulimit": error=2, No such file or directory (io.confluent.controlcenter.healthcheck.HealthCheck)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,863] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,206] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 11 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,420] INFO current clusterId=lbUe4hq7QeWfnY0W4R-PhA (io.confluent.controlcenter.healthcheck.HealthCheck)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,863] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,207] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 11 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,501] INFO broker id set has changed new={2=[kafka2:9092 (id: 2 rack: r1)], 1=[kafka1:9091 (id: 1 rack: r1)]} removed={} (io.confluent.controlcenter.healthcheck.HealthCheck)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,863] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,501] INFO new controller=kafka2:9092 (id: 2 rack: r1) (io.confluent.controlcenter.healthcheck.HealthCheck)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,212] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 12 (state.change.logger)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,864] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:54,903] INFO Adding listener: http://0.0.0.0:9021 (io.confluent.rest.Application)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,249] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 13 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:55,112] INFO Adding listener: https://0.0.0.0:9022 (io.confluent.rest.Application)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,934] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	key.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,250] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 13 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:55,498] INFO name=monitoring-input-topic-progress-.count type=monitoring cluster= value=0.0 (io.confluent.controlcenter.util.StreamProgressReporter)
[36;1mconnect                        |[0m 	name = wikipedia-irc
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,250] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,937] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:04:55,498] INFO name=monitoring-input-topic-progress-.rate type=monitoring cluster= value=NaN (io.confluent.controlcenter.util.StreamProgressReporter)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,253] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,938] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:55,498] INFO name=monitoring-input-topic-progress-.timestamp type=monitoring cluster= value=1.7976931348623157E308 (io.confluent.controlcenter.util.StreamProgressReporter)
[36;1mconnect                        |[0m 	transforms = [WikiEditTransformation]
[32mcontrol-center                 |[0m [2020-05-20 20:04:55,499] INFO name=monitoring-input-topic-progress-.min type=monitoring cluster= value=1.7976931348623157E308 (io.confluent.controlcenter.util.StreamProgressReporter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,254] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,939] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[32mcontrol-center                 |[0m [2020-05-20 20:04:56,097] INFO jetty-9.4.z-SNAPSHOT; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_212-b04 (org.eclipse.jetty.server.Server)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,254] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:04:56,219] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,939] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,255] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:56,219] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,395] INFO EnrichedConnectorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,940] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,255] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:56,296] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,947] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,255] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:57,216] INFO AdminClientConfig values: 
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,953] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,255] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	connector.class = com.github.cjmatta.kafka.connect.irc.IrcSourceConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,954] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m 	errors.log.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,954] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,258] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 13 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	client.id = 
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,954] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,258] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 13 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 300000
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,955] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,261] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 14 (state.change.logger)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,960] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,364] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 15 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m 	metric.reporters = []
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,960] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,365] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 15 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,961] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,365] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,961] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,368] INFO [Log partition=_confluent-controlcenter-5-3-1-1-cluster-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,961] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	name = wikipedia-irc
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,368] INFO [Log partition=_confluent-controlcenter-5-3-1-1-cluster-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:23,961] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,369] INFO Created log for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,016] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] INFO [Partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	transforms = [WikiEditTransformation]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,016] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.dead.letter.topic = wikipedia.failed
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,017] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.field.message = message
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-cluster-rekey-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,017] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	request.timeout.ms = 120000
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.save.unparseable.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 15 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,017] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	retries = 2147483647
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.type = class com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformation
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 as part of become-follower request with correlation id 15 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,017] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-cluster-rekey-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 15 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,033] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,370] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 15 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,033] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,395] INFO Creating connector wikipedia-irc of type com.github.cjmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,422] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 16 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,518] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 17 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,034] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,519] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 17 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m [2020-05-20 20:05:37,399] INFO Instantiated connector wikipedia-irc with version 4.0.0 of type class com.github.cjmatta.kafka.connect.irc.IrcSourceConnector (org.apache.kafka.connect.runtime.Worker)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,034] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,400] INFO IrcSourceConnectorConfig values: 
[36;1mconnect                        |[0m 	irc.bot.name = KafkaConnectBot_W50fIq
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,519] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,034] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,545] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,034] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	irc.channels = [#en.wikipedia, #fr.wikipedia, #es.wikipedia, #ru.wikipedia, #en.wiktionary, #de.wikipedia, #zh.wikipedia, #sd.wikipedia, #it.wikipedia, #mediawiki.wikipedia, #commons.wikimedia, #eu.wikipedia, #vo.wikipedia, #eo.wikipedia, #uk.wikipedia]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,047] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,545] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	irc.password = [hidden]
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,546] INFO Created log for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,047] INFO Successfully submitted metrics to Confluent via secure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[36;1mconnect                        |[0m 	irc.server = irc.wikimedia.org
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,547] INFO [Partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,048] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	irc.server.port = 6667
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,547] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,049] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	kafka.topic = wikipedia.parsed
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,547] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,053] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[36;1mconnect                        |[0m  (com.github.cjmatta.kafka.connect.irc.IrcSourceConnectorConfig)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,548] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 17 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,053] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,505] INFO Finished creating connector wikipedia-irc (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,548] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 as part of become-follower request with correlation id 17 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,054] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,506] INFO SourceConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,548] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,058] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,548] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 17 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	config.action.reload = restart
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,058] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	connector.class = com.github.cjmatta.kafka.connect.irc.IrcSourceConnector
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,548] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 17 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,059] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,059] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,553] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,554] INFO [Log partition=_confluent-controlcenter-5-3-1-1-cluster-rekey-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,059] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,554] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,060] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,554] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,555] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,063] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	header.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,555] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,064] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	key.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,554] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 18 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,101] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	name = wikipedia-irc
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,637] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 19 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,106] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 19 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,106] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m 	transforms = [WikiEditTransformation]
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,638] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,106] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,641] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,120] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,641] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:37,507] INFO EnrichedConnectorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,126] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,642] INFO Created log for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,127] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,644] INFO [Partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,127] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	connector.class = com.github.cjmatta.kafka.connect.irc.IrcSourceConnector
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,644] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,128] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,644] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,128] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,644] INFO [Partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,647] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 19 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,140] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,647] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 19 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,142] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,652] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 20 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'consumer.session.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,757] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 21 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'producer.max.block.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,758] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 21 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'producer.retries' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m 	header.converter = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'consumer.request.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,758] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,147] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	key.converter = null
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'producer.retry.backoff.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,761] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,148] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	name = wikipedia-irc
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'producer.linger.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,761] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	tasks.max = 1
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'producer.delivery.timeout.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,148] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,762] INFO Created log for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	transforms = [WikiEditTransformation]
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'cache.max.bytes.buffering' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,148] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,762] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'producer.compression.type' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,152] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.dead.letter.topic = wikipedia.failed
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,762] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] WARN The configuration 'num.stream.threads' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,153] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,763] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.field.message = message
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,154] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.save.unparseable.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,763] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 21 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,155] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.type = class com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformation
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,763] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 as part of become-follower request with correlation id 21 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,155] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:04:58,508] INFO Kafka startTimeMs: 1590005098508 (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,763] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,155] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[32mcontrol-center                 |[0m May 20, 2020 8:04:58 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,763] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 21 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,159] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,310] INFO [Worker clientId=connect-1, groupId=connect] Tasks [wikipedia-irc-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.CachedConsumerOffsetsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.CachedConsumerOffsetsResource will be ignored. 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,763] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 21 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,160] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,812] INFO [Worker clientId=connect-1, groupId=connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,161] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,765] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 22 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,813] INFO [Worker clientId=connect-1, groupId=connect] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,161] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.KafkaResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.KafkaResource will be ignored. 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,857] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 23 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,813] INFO [Worker clientId=connect-1, groupId=connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,161] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,813] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,161] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,858] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 23 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.ClusterResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.ClusterResource will be ignored. 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,164] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,858] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,819] INFO [Worker clientId=connect-1, groupId=connect] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,164] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,819] INFO [Worker clientId=connect-1, groupId=connect] Joined group at generation 3 and got assignment: Assignment{error=0, leader='connect-1-534a2a13-2f66-4763-9455-ccc532644fa6', leaderUrl='https://connect:8083/', offset=3, connectorIds=[wikipedia-irc], taskIds=[wikipedia-irc-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.AuthResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.AuthResource will be ignored. 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,861] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,165] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,820] INFO [Worker clientId=connect-1, groupId=connect] Starting connectors and tasks using config offset 3 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,861] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,165] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,820] INFO [Worker clientId=connect-1, groupId=connect] Starting task wikipedia-irc-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,862] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.FeatureFlagResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.FeatureFlagResource will be ignored. 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,165] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,821] INFO Creating task wikipedia-irc-0 (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,862] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,821] INFO ConnectorConfig values: 
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,862] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,166] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.AlertsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.AlertsResource will be ignored. 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,863] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connector.class = com.github.cjmatta.kafka.connect.irc.IrcSourceConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,207] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,863] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.log.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,221] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.MetricsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.MetricsResource will be ignored. 
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,865] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 23 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,223] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,865] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 23 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.PermissionsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.PermissionsResource will be ignored. 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,223] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:32,911] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 24 (state.change.logger)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,223] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,002] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 25 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.StatusResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.StatusResource will be ignored. 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,223] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,003] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 25 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,244] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	header.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,003] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.MessageDeliveryResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.MessageDeliveryResource will be ignored. 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,006] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,245] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[36;1mconnect                        |[0m 	key.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,006] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,246] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.HealthCheckResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.HealthCheckResource will be ignored. 
[36;1mconnect                        |[0m 	name = wikipedia-irc
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,007] INFO Created log for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,246] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[36;1mconnect                        |[0m 	tasks.max = 1
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.LicenseResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.LicenseResource will be ignored. 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,246] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] INFO [Partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m May 20, 2020 8:04:59 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
[36;1mconnect                        |[0m 	transforms = [WikiEditTransformation]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,246] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m WARNING: A provider io.confluent.controlcenter.rest.CommandResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.controlcenter.rest.CommandResource will be ignored. 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,255] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:04:59,410] INFO ConsumerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,255] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,822] INFO EnrichedConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 25 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,256] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,257] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 as part of become-follower request with correlation id 25 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	auto.offset.reset = latest
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,257] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	connector.class = com.github.cjmatta.kafka.connect.irc.IrcSourceConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,257] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	check.crcs = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 25 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,304] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,008] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 25 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,305] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m 	client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,013] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 26 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,305] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[32mcontrol-center                 |[0m 	client.rack = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,117] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,316] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,117] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,316] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.tolerance = none
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,117] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,317] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	header.converter = null
[32mcontrol-center                 |[0m 	enable.auto.commit = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,117] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,320] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,139] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 27 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,335] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,140] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 27 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	name = wikipedia-irc
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,336] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,140] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	tasks.max = 1
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,336] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,143] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,144] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	transforms = [WikiEditTransformation]
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,336] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,144] INFO Created log for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.dead.letter.topic = wikipedia.failed
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,336] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	group.id = 
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.field.message = message
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,145] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,397] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	group.instance.id = null
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.save.unparseable.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,145] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect                        |[0m 	transforms.WikiEditTransformation.type = class com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformation
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[32mcontrol-center                 |[0m 	interceptor.classes = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,145] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,145] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 broker=1] _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,148] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 27 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,399] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,148] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 27 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,824] INFO TaskConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,405] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,151] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 28 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,406] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	task.class = class com.github.cjmatta.kafka.connect.irc.IrcSourceTask
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,246] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 29 from controller 2 epoch 1 for partition _confluent-metrics-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,406] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,247] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 29 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-metrics-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,406] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,824] INFO Instantiated task wikipedia-irc-0 with version 4.0.0 of type com.github.cjmatta.kafka.connect.irc.IrcSourceTask (org.apache.kafka.connect.runtime.Worker)
[32mcontrol-center                 |[0m 	max.poll.records = 10
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,247] INFO Replica loaded for partition _confluent-metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,411] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:38,896] INFO AvroConverterConfig values: 
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,250] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,413] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,250] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,414] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	schema.registry.url = [https://schemaregistry:8085]
[36;1mconnect                        |[0m 	basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,251] INFO Created log for partition _confluent-metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 259200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 10485760, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,415] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	auto.register.schemas = true
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,420] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,251] INFO [Partition _confluent-metrics-0 broker=1] No checkpointed highwatermark is found for partition _confluent-metrics-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	max.schemas.per.subject = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,421] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,251] INFO Replica loaded for partition _confluent-metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,432] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,433] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,252] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-metrics-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,252] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 29 for partition _confluent-metrics-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,434] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,252] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-metrics-0 as part of become-follower request with correlation id 29 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,434] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[36;1mconnect                        |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,252] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-metrics-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,440] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,252] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 29 for partition _confluent-metrics-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,440] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m  (io.confluent.connect.avro.AvroConverterConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,252] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 29 from controller 2 epoch 1 for the become-follower transition for partition _confluent-metrics-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,450] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m [2020-05-20 20:05:38,911] INFO KafkaAvroSerializerConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,256] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 30 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,450] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,348] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 31 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,451] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,349] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 31 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.url = [https://schemaregistry:8085]
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,451] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,349] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,451] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	auto.register.schemas = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,452] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-28, __consumer_offsets-6, __consumer_offsets-32, __consumer_offsets-10, __consumer_offsets-14, __consumer_offsets-44, __consumer_offsets-36, __consumer_offsets-40, __consumer_offsets-18, __consumer_offsets-48, __consumer_offsets-22, __consumer_offsets-0, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-4, __consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-16, __consumer_offsets-12, __consumer_offsets-20, __consumer_offsets-42, __consumer_offsets-2, __consumer_offsets-46, __consumer_offsets-24) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	max.schemas.per.subject = 1000
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,353] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-22 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-28 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,353] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-34 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,353] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-2 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,353] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-40 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,353] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 31 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m [2020-05-20 20:05:38,914] INFO KafkaAvroDeserializerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-46 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,353] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 as part of become-follower request with correlation id 31 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	bearer.auth.token = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,354] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-8 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.url = [https://schemaregistry:8085]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,354] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 31 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-14 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,354] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 31 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-20 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	auto.register.schemas = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,357] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 32 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-26 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	max.schemas.per.subject = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,446] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 33 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-32 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	session.timeout.ms = 10000
[36;1mconnect                        |[0m 	basic.auth.credentials.source = URL
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-38 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,447] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 33 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	schema.registry.basic.auth.user.info = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,447] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,459] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-44 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,450] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	specific.avro.reader = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-6 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,451] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-12 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,451] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-18 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,452] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,452] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,533] INFO AvroDataConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-24 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	connect.meta.data = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-30 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,452] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m 	enhanced.avro.schema.support = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-36 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,452] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m 	schemas.cache.config = 1000
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m  (io.confluent.connect.avro.AvroDataConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,454] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 33 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-42 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,533] INFO StringConverterConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,454] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 33 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-4 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,456] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 34 (state.change.logger)
[36;1mconnect                        |[0m 	converter.encoding = UTF8
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-48 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	converter.type = key
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,546] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 35 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-10 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m  (org.apache.kafka.connect.storage.StringConverterConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,548] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 35 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,533] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task wikipedia-irc-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,460] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-16 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,548] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,534] INFO Set up the value converter class io.confluent.connect.avro.AvroConverter for task wikipedia-irc-0 using the connector config (org.apache.kafka.connect.runtime.Worker)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,551] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,461] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-22 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:59,411] INFO ConsumerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-28 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,534] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task wikipedia-irc-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,551] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	allow.auto.create.topics = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-34 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,538] INFO WikiEditTransformationConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,552] INFO Created log for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	auto.commit.interval.ms = 5000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-2 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	dead.letter.topic = wikipedia.failed
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,552] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	auto.offset.reset = latest
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-40 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	field.message = message
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,552] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-46 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	save.unparseable.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,552] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	check.crcs = true
[36;1mconnect                        |[0m  (com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformationConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-8 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	client.dns.lookup = default
[36;1mconnect                        |[0m [2020-05-20 20:05:39,538] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{com.github.cjmatta.kafka.connect.transform.wikiedit.WikiEditTransformation} (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-14 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,552] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-20 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:39,541] INFO ProducerConfig values: 
[32mcontrol-center                 |[0m 	client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,555] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 35 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-26 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	acks = all
[32mcontrol-center                 |[0m 	client.rack = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,555] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 35 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-32 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,557] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 36 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-38 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	batch.size = 16384
[32mcontrol-center                 |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,628] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-0 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[32mcontrol-center                 |[0m 	default.api.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,628] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-44 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[32mcontrol-center                 |[0m 	enable.auto.commit = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,628] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-metrics-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-6 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[32mcontrol-center                 |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,628] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	client.id = connect-worker-producer
[32mcontrol-center                 |[0m 	fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-12 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,641] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 37 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	compression.type = none
[32mcontrol-center                 |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-18 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,642] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 37 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-24 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 2147483647
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,642] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	group.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-30 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	enable.idempotence = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,646] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	group.instance.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-36 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,646] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	heartbeat.interval.ms = 3000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-42 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,647] INFO Created log for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-4 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m 	linger.ms = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] INFO [Partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-48 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	internal.leave.group.on.close = true
[36;1mconnect                        |[0m 	max.block.ms = 9223372036854775807
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-10 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,462] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition __consumer_offsets-16 as part of become-follower request with correlation id 3 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[32mcontrol-center                 |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 37 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect                        |[0m 	max.request.size = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,661] INFO [Controller id=2] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 as part of become-follower request with correlation id 37 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	max.poll.interval.ms = 300000
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,662] TRACE [Controller id=2] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	metric.reporters = []
[32mcontrol-center                 |[0m 	max.poll.records = 10
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 37 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,666] DEBUG [Controller id=2] Preferred replicas by broker Map(2 -> Map(__consumer_offsets-21 -> Vector(2, 1), __consumer_offsets-27 -> Vector(2, 1), __consumer_offsets-7 -> Vector(2, 1), __consumer_offsets-9 -> Vector(2, 1), __consumer_offsets-25 -> Vector(2, 1), __consumer_offsets-35 -> Vector(2, 1), __consumer_offsets-41 -> Vector(2, 1), __consumer_offsets-33 -> Vector(2, 1), __consumer_offsets-23 -> Vector(2, 1), __consumer_offsets-49 -> Vector(2, 1), __consumer_offsets-47 -> Vector(2, 1), __consumer_offsets-31 -> Vector(2, 1), __consumer_offsets-3 -> Vector(2, 1), __consumer_offsets-37 -> Vector(2, 1), __consumer_offsets-15 -> Vector(2, 1), __consumer_offsets-17 -> Vector(2, 1), __confluent.support.metrics-0 -> Vector(2, 1), __consumer_offsets-19 -> Vector(2, 1), __consumer_offsets-11 -> Vector(2, 1), __consumer_offsets-13 -> Vector(2, 1), __consumer_offsets-43 -> Vector(2, 1), __consumer_offsets-39 -> Vector(2, 1), __consumer_offsets-45 -> Vector(2, 1), __consumer_offsets-1 -> Vector(2, 1), __consumer_offsets-5 -> Vector(2, 1), __consumer_offsets-29 -> Vector(2, 1)), 1 -> Map(__consumer_offsets-22 -> Vector(1, 2), __consumer_offsets-30 -> Vector(1, 2), __consumer_offsets-8 -> Vector(1, 2), __consumer_offsets-4 -> Vector(1, 2), __consumer_offsets-46 -> Vector(1, 2), __consumer_offsets-16 -> Vector(1, 2), __consumer_offsets-28 -> Vector(1, 2), __consumer_offsets-36 -> Vector(1, 2), __consumer_offsets-42 -> Vector(1, 2), __consumer_offsets-18 -> Vector(1, 2), __consumer_offsets-24 -> Vector(1, 2), __consumer_offsets-38 -> Vector(1, 2), __consumer_offsets-48 -> Vector(1, 2), __consumer_offsets-2 -> Vector(1, 2), __consumer_offsets-6 -> Vector(1, 2), __consumer_offsets-14 -> Vector(1, 2), __consumer_offsets-20 -> Vector(1, 2), __consumer_offsets-0 -> Vector(1, 2), __consumer_offsets-44 -> Vector(1, 2), __consumer_offsets-12 -> Vector(1, 2), __consumer_offsets-26 -> Vector(1, 2), __consumer_offsets-34 -> Vector(1, 2), __consumer_offsets-10 -> Vector(1, 2), __consumer_offsets-32 -> Vector(1, 2), __consumer_offsets-40 -> Vector(1, 2))) (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,648] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 37 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,668] DEBUG [Controller id=2] Topics not in preferred replica for broker 2 Map() (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,651] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 38 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,669] TRACE [Controller id=2] Leader imbalance ratio for broker 2 is 0.0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,735] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 39 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m 	metric.reporters = []
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,669] DEBUG [Controller id=2] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,736] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 39 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m [2020-05-20 20:04:24,669] TRACE [Controller id=2] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,736] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,068] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,745] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,096] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(__consumer_offsets-22 -> (offset=0, leaderEpoch=0), __consumer_offsets-30 -> (offset=0, leaderEpoch=0), __consumer_offsets-8 -> (offset=0, leaderEpoch=0), __consumer_offsets-4 -> (offset=0, leaderEpoch=0), __consumer_offsets-46 -> (offset=0, leaderEpoch=0), __consumer_offsets-16 -> (offset=0, leaderEpoch=0), __consumer_offsets-28 -> (offset=0, leaderEpoch=0), __consumer_offsets-36 -> (offset=0, leaderEpoch=0), __consumer_offsets-42 -> (offset=0, leaderEpoch=0), __consumer_offsets-18 -> (offset=0, leaderEpoch=0), __consumer_offsets-24 -> (offset=0, leaderEpoch=0), __consumer_offsets-38 -> (offset=0, leaderEpoch=0), __consumer_offsets-48 -> (offset=0, leaderEpoch=0), __consumer_offsets-2 -> (offset=0, leaderEpoch=0), __consumer_offsets-6 -> (offset=0, leaderEpoch=0), __consumer_offsets-14 -> (offset=0, leaderEpoch=0), __consumer_offsets-20 -> (offset=0, leaderEpoch=0), __consumer_offsets-0 -> (offset=0, leaderEpoch=0), __consumer_offsets-44 -> (offset=0, leaderEpoch=0), __consumer_offsets-12 -> (offset=0, leaderEpoch=0), __consumer_offsets-26 -> (offset=0, leaderEpoch=0), __consumer_offsets-34 -> (offset=0, leaderEpoch=0), __consumer_offsets-10 -> (offset=0, leaderEpoch=0), __consumer_offsets-32 -> (offset=0, leaderEpoch=0), __consumer_offsets-40 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,745] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	request.timeout.ms = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,097] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-22 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,746] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	retries = 2147483647
[32mcontrol-center                 |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,097] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-28 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,746] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,097] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-34 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,746] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,097] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-2 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,747] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,097] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-40 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,747] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 39 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,097] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-46 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,747] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 as part of become-follower request with correlation id 39 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-8 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,747] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-14 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,747] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 39 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-20 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,747] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 39 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-26 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,751] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 40 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-32 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,840] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 41 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-38 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,841] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 41 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-44 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,841] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,098] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-6 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,844] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-12 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,844] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	sasl.login.class = null
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-18 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,845] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-24 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-30 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-36 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-42 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 41 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-4 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 as part of become-follower request with correlation id 41 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-48 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,099] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-10 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 41 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,100] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 3 for partition __consumer_offsets-16 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,846] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 41 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[32mcontrol-center                 |[0m 	session.timeout.ms = 10000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,102] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,853] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 42 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,102] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-48 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,930] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 43 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,102] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-10 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.endpoint.identification.algorithm = HTTPS
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,931] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 43 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[32mcontrol-center                 |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,102] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-26 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,931] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,102] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-42 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,934] INFO [Log partition=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.control-center.keystore.jks
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-4 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,934] INFO [Log partition=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-20 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,935] INFO Created log for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,935] INFO [Partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-36 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.provider = null
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,935] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-14 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.secure.random.implementation = null
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,935] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-30 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,935] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 43 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.control-center.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-46 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	transactional.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,935] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 as part of become-follower request with correlation id 43 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,936] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[32mcontrol-center                 |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,936] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 43 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,103] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-8 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,936] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 43 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-24 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-2 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:33,938] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 44 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:04:59,411] WARN [Consumer clientId=consumer-1, groupId=] Support for using the empty group id by consumers is deprecated and will be removed in the next major release. (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-40 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,029] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 45 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-18 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:00,497] INFO HV000001: Hibernate Validator 5.1.3.Final (org.hibernate.validator.internal.util.Version)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-34 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,031] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 45 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:00,711] INFO Kafka version: 5.3.1-ce (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,031] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:05:00,794] INFO Kafka commitId: 30df4bec2f6882ab (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,035] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-12 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:00,794] INFO Kafka startTimeMs: 1590005100711 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,035] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-28 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:01,316] INFO [Consumer clientId=consumer-1, groupId=] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,036] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-38 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:01,501] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,038] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-28 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:01,999] ERROR Could not submit metrics to Confluent: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target (io.confluent.support.metrics.utils.WebClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,039] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,104] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-44 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,000] ERROR Failed to submit metrics via secure endpoint, falling back to insecure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,121] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-6 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,122] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-16 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,308] INFO x509=X509@1983b48a(control-center,h=[control-center, localhost],w=[]) for Server@629a9f26[provider=null,keyStore=file:///etc/kafka/secrets/kafka.control-center.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.control-center.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,215] INFO Kafka startTimeMs: 1590005140215 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,039] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,299] INFO [Worker clientId=connect-1, groupId=connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,122] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-22 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,039] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,309] INFO x509=X509@b791a81(caroot,h=[ca1.test.confluent.io],w=[]) for Server@629a9f26[provider=null,keyStore=file:///etc/kafka/secrets/kafka.control-center.keystore.jks,trustStore=file:///etc/kafka/secrets/kafka.control-center.truststore.jks] (org.eclipse.jetty.util.ssl.SslContextFactory)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,300] INFO IrcSourceTaskConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,122] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 3 from controller 2 epoch 1 for the become-follower transition for partition __consumer_offsets-32 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,041] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 45 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,701] INFO Started o.e.j.s.ServletContextHandler@36fcf6c0{/,[jar:file:/usr/share/java/acl/acl-5.3.1.jar!/io/confluent/controlcenter/rest/static],AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[36;1mconnect                        |[0m 	irc.bot.name = KafkaConnectBot_YoeCY7
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,125] INFO [Log partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,041] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 45 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,706] INFO {"confluentPlatformVersion":null,"informationForUser":null} (io.confluent.controlcenter.healthcheck.HealthCheckModule)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,138] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	irc.channels = [#en.wikipedia, #fr.wikipedia, #es.wikipedia, #ru.wikipedia, #en.wiktionary, #de.wikipedia, #zh.wikipedia, #sd.wikipedia, #it.wikipedia, #mediawiki.wikipedia, #commons.wikimedia, #eu.wikipedia, #vo.wikipedia, #eo.wikipedia, #uk.wikipedia]
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,043] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 46 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,706] INFO Successfully submitted metrics to Confluent via insecure endpoint (io.confluent.support.metrics.submitters.ConfluentSubmitter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,138] INFO [Log partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	irc.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,813] INFO Started o.e.j.s.ServletContextHandler@5a00eb1e{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,149] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 47 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,138] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	irc.server = irc.wikimedia.org
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,898] INFO Started NetworkTrafficServerConnector@6c1832aa{HTTP/1.1,[http/1.1]}{0.0.0.0:9021} (org.eclipse.jetty.server.AbstractConnector)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,151] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 47 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,138] INFO [Log partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	irc.server.port = 6667
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,905] INFO Started NetworkTrafficServerConnector@4bafe935{SSL,[ssl, http/1.1]}{0.0.0.0:9022} (org.eclipse.jetty.server.AbstractConnector)
[32mcontrol-center                 |[0m [2020-05-20 20:05:02,905] INFO Started @40829ms (org.eclipse.jetty.server.Server)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,152] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-32 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	kafka.topic = wikipedia.parsed
[32mcontrol-center                 |[0m [2020-05-20 20:05:04,509] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,152] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m  (com.github.cjmatta.kafka.connect.irc.IrcSourceTaskConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [Log partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:06,801] INFO 172.19.0.1 - - [20/May/2020:20:05:06 +0000] "GET /2.0/clusters/kafka/ HTTP/1.1" 200 149  519 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,152] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,306] INFO Connecting to server: irc.wikimedia.org (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-36 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:06,912] INFO Updating metadata for cluster lbUe4hq7QeWfnY0W4R-PhA: KafkaCluster{id=null, displayName=Kafka Raleigh, zookeeper.connect=null, bootstrap.servers=null} (io.confluent.controlcenter.rest.ClusterResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,153] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,308] INFO AbstractConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [Log partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,153] INFO [Log partition=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:07,420] INFO 172.19.0.1 - - [20/May/2020:20:05:06 +0000] "PATCH /2.0/clusters/kafka/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 204 0  624 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (org.apache.kafka.common.config.AbstractConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-14 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,153] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:09,447] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,395] INFO [Producer clientId=connect-worker-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [Log partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,153] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:14,468] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,400] INFO [Worker clientId=connect-1, groupId=connect] Connector elasticsearch-ksql config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,139] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-44 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,153] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,140] INFO [Log partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,440] INFO Joining channel: #en.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:17,360] INFO Opening store MetricsAggregateStore.1589716800000 in regular mode (org.apache.kafka.streams.state.internals.RocksDBTimestampedStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,140] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-18 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,153] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #fr.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:19,530] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,140] INFO [Log partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,155] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #es.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:24,428] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,140] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-48 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,156] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #ru.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,140] INFO [Log partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:29,435] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,157] INFO Created log for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #en.wiktionary (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,140] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-40 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:34,427] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,157] INFO [Partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #de.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,141] INFO [Log partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:39,437] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,157] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #zh.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,141] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-22 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:44,430] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,158] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #sd.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,141] INFO [Log partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:49,507] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,158] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 47 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #it.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,141] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-30 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,158] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 as part of become-follower request with correlation id 47 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #mediawiki.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,141] INFO [Log partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,410] WARN unable to check ulimit: Cannot run program "ulimit": error=2, No such file or directory (io.confluent.controlcenter.healthcheck.HealthCheck)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #commons.wikimedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,158] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #eu.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,141] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,158] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 47 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #vo.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,142] INFO [Log partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,159] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 47 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #eo.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,142] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,225] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 48 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO Joining channel: #uk.wikipedia (com.github.cjmatta.kafka.connect.irc.IrcSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,145] INFO [Log partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,299] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 49 from controller 2 epoch 1 for partition _confluent-command-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,441] INFO WorkerSourceTask{id=wikipedia-irc-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,145] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-26 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,300] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 49 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-command-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,901] INFO [Worker clientId=connect-1, groupId=connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,145] INFO [Log partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,300] INFO Replica loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,902] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,145] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-34 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,308] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:54,433] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,909] INFO [Worker clientId=connect-1, groupId=connect] Successfully joined group with generation 4 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,309] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,145] INFO [Log partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:05:59,431] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,309] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 259200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,145] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:06:04,428] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,910] INFO [Worker clientId=connect-1, groupId=connect] Joined group at generation 4 and got assignment: Assignment{error=0, leader='connect-1-534a2a13-2f66-4763-9455-ccc532644fa6', leaderUrl='https://connect:8083/', offset=4, connectorIds=[elasticsearch-ksql, wikipedia-irc], taskIds=[wikipedia-irc-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,146] INFO [Log partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] INFO [Partition _confluent-command-0 broker=1] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:06:09,430] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,910] INFO [Worker clientId=connect-1, groupId=connect] Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,146] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-16 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] INFO Replica loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:06:10,628] INFO name=monitoring-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.count type=monitoring cluster=lbUe4hq7QeWfnY0W4R-PhA value=0.0 (io.confluent.controlcenter.util.StreamProgressReporter)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,910] INFO [Worker clientId=connect-1, groupId=connect] Starting connector elasticsearch-ksql (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,148] INFO [Log partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,910] INFO ConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 49 for partition _confluent-command-0 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-command-0 as part of become-follower request with correlation id 49 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	config.action.reload = restart
[32mcontrol-center                 |[0m [2020-05-20 20:06:10,628] INFO name=monitoring-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.rate type=monitoring cluster=lbUe4hq7QeWfnY0W4R-PhA value=NaN (io.confluent.controlcenter.util.StreamProgressReporter)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,148] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-38 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-command-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:10,628] INFO name=monitoring-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.timestamp type=monitoring cluster=lbUe4hq7QeWfnY0W4R-PhA value=1.7976931348623157E308 (io.confluent.controlcenter.util.StreamProgressReporter)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,148] INFO [Log partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:06:10,628] INFO name=monitoring-input-topic-progress-lbUe4hq7QeWfnY0W4R-PhA.min type=monitoring cluster=lbUe4hq7QeWfnY0W4R-PhA value=1.590005157248E12 (io.confluent.controlcenter.util.StreamProgressReporter)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 49 for partition _confluent-command-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,149] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-12 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:06:14,432] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,310] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 49 from controller 2 epoch 1 for the become-follower transition for partition _confluent-command-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m [2020-05-20 20:06:19,082] INFO Opening store MonitoringStream-ONE_MINUTE.1589932800000 in regular mode (org.apache.kafka.streams.state.internals.RocksDBTimestampedStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,149] INFO [Log partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,426] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-command-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 50 (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:06:19,139] INFO Opening store MonitoringStream-THREE_HOURS.1572480000000 in regular mode (org.apache.kafka.streams.state.internals.RocksDBTimestampedStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,149] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-42 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,431] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 51 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[32mcontrol-center                 |[0m [2020-05-20 20:06:19,247] INFO Opening store Group-ONE_MINUTE.1589932800000 in regular mode (org.apache.kafka.streams.state.internals.RocksDBTimestampedStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,149] INFO [Log partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,436] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 51 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	errors.tolerance = none
[32mcontrol-center                 |[0m [2020-05-20 20:06:19,280] INFO Opening store Group-THREE_HOURS.1572480000000 in regular mode (org.apache.kafka.streams.state.internals.RocksDBTimestampedStore)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,149] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-20 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,437] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:19,709] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,150] INFO [Log partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,441] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:06:24,434] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,151] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-46 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,442] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:06:29,078] INFO 172.19.0.1 - - [20/May/2020:20:06:29 +0000] "GET /2.0/clusters/kafka/ HTTP/1.1" 200 141  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,151] INFO [Log partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,443] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:29,443] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	tasks.max = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,152] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-24 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,444] INFO [Partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:06:29,724] INFO 172.19.0.1 - - [20/May/2020:20:06:29 +0000] "POST /2.0/alerts/triggers HTTP/1.1" 200 240  632 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	transforms = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,159] INFO [Log partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,444] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:06:29,738] INFO 172.19.0.1 - - [20/May/2020:20:06:29 +0000] "GET /2.0/clusters/kafka/ HTTP/1.1" 200 141  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,160] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,444] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:06:30,263] INFO 172.19.0.1 - - [20/May/2020:20:06:29 +0000] "POST /2.0/alerts/triggers HTTP/1.1" 200 279  511 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,161] INFO [Log partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,444] INFO [Partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 broker=1] _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,911] INFO EnrichedConnectorConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:06:30,278] INFO 172.19.0.1 - - [20/May/2020:20:06:30 +0000] "GET /2.0/alerts/triggers/ HTTP/1.1" 200 522  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,166] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:30,291] INFO 172.19.0.1 - - [20/May/2020:20:06:30 +0000] "GET /2.0/alerts/triggers/ HTTP/1.1" 200 522  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,446] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 51 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:30,826] INFO 172.19.0.1 - - [20/May/2020:20:06:30 +0000] "POST /2.0/alerts/actions HTTP/1.1" 200 308  521 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,446] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 51 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:34,539] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:39,613] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,505] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 52 (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,508] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 53 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:44,515] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,509] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 53 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:49,531] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,509] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:06:50,514] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	header.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,526] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] WARN unable to check ulimit: Cannot run program "ulimit": error=2, No such file or directory (io.confluent.controlcenter.healthcheck.HealthCheck)
[36;1mconnect                        |[0m 	key.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,550] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,551] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	tasks.max = 1
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,552] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	transforms = []
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,552] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,552] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,552] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 53 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,911] INFO Creating connector elasticsearch-ksql of type io.confluent.connect.elasticsearch.ElasticsearchSinkConnector (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,552] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 as part of become-follower request with correlation id 53 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,410] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,911] INFO Instantiated connector elasticsearch-ksql with version 5.3.1 of type class io.confluent.connect.elasticsearch.ElasticsearchSinkConnector (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,553] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,912] INFO ElasticsearchSinkConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,553] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 53 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	auto.create.indices.at.start = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,553] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 53 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	batch.size = 2000
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,555] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 54 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,610] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 55 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	behavior.on.malformed.documents = fail
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,171] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,645] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 55 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	behavior.on.null.values = ignore
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,645] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,172] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	compact.map.entries = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,654] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,172] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,655] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,655] INFO Created log for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,172] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	connection.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,656] INFO [Partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	connection.timeout.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,656] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connection.url = [http://elasticsearch:9200]
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,172] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,656] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	connection.username = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,172] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,656] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 55 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	drop.invalid.message = false
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,172] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,656] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 as part of become-follower request with correlation id 55 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.cipher.suites = null
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,173] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,656] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,173] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,657] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 55 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,173] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.key.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,657] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 55 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,411] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,173] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,660] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 56 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:06:54,523] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,173] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.location = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,705] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 57 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,173] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:06:59,600] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,706] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:04,602] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,708] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:07:09,632] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	elastic.https.ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,711] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:07:14,554] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,716] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:19,552] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	elastic.https.ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,717] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:21,102] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,717] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	elastic.https.ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:21,102] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,718] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:07:21,104] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,718] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:21,104] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	elastic.https.ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,719] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:21,110] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.location = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,719] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 as part of become-follower request with correlation id 57 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:21,223] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,720] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:24,604] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,721] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 57 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:29,552] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	elastic.security.protocol = PLAINTEXT
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,721] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:34,606] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	flush.timeout.ms = 10000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,729] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:07:39,553] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	key.ignore = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:07:44,554] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	linger.ms = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:07:49,553] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	max.buffered.records = 20000
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	max.in.flight.requests = 5
[32mcontrol-center                 |[0m [2020-05-20 20:07:51,513] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:51,528] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	max.retries = 5
[32mcontrol-center                 |[0m [2020-05-20 20:07:51,528] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	read.timeout.ms = 3000
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,408] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,174] INFO [GroupMetadataManager brokerId=2] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,175] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-command-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,175] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	schema.ignore = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,731] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,175] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,730] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[36;1mconnect                        |[0m 	topic.index.map = [WIKIPEDIABOT:wikipediabot]
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,748] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 59 from controller 2 epoch 1 for partition _confluent-monitoring-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,175] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	topic.key.ignore = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,749] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 59 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-monitoring-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,175] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,749] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-monitoring-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	topic.schema.ignore = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,176] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,800] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	type.name = wikichange
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,176] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,801] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	write.method = insert
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,176] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,195] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0}]} for request LEADER_AND_ISR with correlation id 3 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m  (io.confluent.connect.elasticsearch.ElasticsearchSinkConnectorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,912] INFO Finished creating connector elasticsearch-ksql (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,801] INFO Created log for partition _confluent-monitoring-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 259200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,197] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,912] INFO SinkConnectorConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,197] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,802] INFO [Partition _confluent-monitoring-0 broker=1] No checkpointed highwatermark is found for partition _confluent-monitoring-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	config.action.reload = restart
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,198] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,802] INFO Replica loaded for partition _confluent-monitoring-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,204] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,802] INFO Replica loaded for partition _confluent-monitoring-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.deadletterqueue.context.headers.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,204] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.name = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,802] INFO [Partition _confluent-monitoring-0 broker=1] _confluent-monitoring-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,205] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.replication.factor = 3
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,823] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 59 for partition _confluent-monitoring-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,205] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,824] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 59 from controller 2 epoch 1 for the become-leader transition for partition _confluent-monitoring-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,205] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,845] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-monitoring-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 60 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,205] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,852] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 61 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,205] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,853] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 61 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,853] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,856] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,856] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,857] INFO Created log for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,857] INFO [Partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	tasks.max = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,857] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	topics = [WIKIPEDIABOT]
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,207] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,857] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	topics.regex = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,209] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,410] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,857] INFO [Partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	transforms = []
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,410] WARN unable to check ulimit: Cannot run program "ulimit": error=2, No such file or directory (io.confluent.controlcenter.healthcheck.HealthCheck)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-46 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:07:54,609] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,860] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 61 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:40,913] INFO EnrichedConnectorConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:07:59,566] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,860] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 61 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-42 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,898] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 62 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:04,552] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-30 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,934] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 63 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:09,569] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-26 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,935] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 63 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[32mcontrol-center                 |[0m [2020-05-20 20:08:14,614] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,935] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	errors.deadletterqueue.context.headers.enable = false
[32mcontrol-center                 |[0m [2020-05-20 20:08:19,614] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-38 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.name = 
[32mcontrol-center                 |[0m [2020-05-20 20:08:21,797] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,938] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.replication.factor = 3
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-34 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:21,810] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,939] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:21,810] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-45 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,939] INFO Created log for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:21,810] INFO metric=CONSUMPTION_DIFF value=2 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,940] INFO [Partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:08:21,810] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-41 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,940] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[32mcontrol-center                 |[0m [2020-05-20 20:08:24,548] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,940] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.tolerance = none
[32mcontrol-center                 |[0m [2020-05-20 20:08:29,553] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:34,550] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,940] INFO [Partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-49 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:39,549] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,943] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 63 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-29 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:44,551] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,943] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 63 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-25 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:44,553] INFO 68.93.140.216 - - [20/May/2020:20:08:44 +0000] "GET / HTTP/1.1" 200 267  6 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:34,953] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 64 (state.change.logger)
[36;1mconnect                        |[0m 	tasks.max = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:44,877] INFO 68.93.140.216 - - [20/May/2020:20:08:44 +0000] "GET /dist/main.js HTTP/1.1" 200 274592  127 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,051] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 65 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	topics = [WIKIPEDIABOT]
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,052] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 65 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-37 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	topics.regex = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,052] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	transforms = []
[32mcontrol-center                 |[0m [2020-05-20 20:08:45,406] INFO 68.93.140.216 - - [20/May/2020:20:08:44 +0000] "GET /dist/vendor.js HTTP/1.1" 200 1054442  665 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,122] INFO [Log partition=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-33 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,122] INFO [Log partition=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,268] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/feature/flags HTTP/1.1" 200 156  10 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,123] INFO Created log for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-48 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,569] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:41,917] INFO [Worker clientId=connect-1, groupId=connect] Tasks [elasticsearch-ksql-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,123] INFO [Partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,578] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  13 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,419] INFO [Worker clientId=connect-1, groupId=connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,123] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-44 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,698] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  5 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,430] INFO AbstractConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,123] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,698] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  6 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (org.apache.kafka.common.config.AbstractConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,123] INFO [Partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 broker=1] _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,713] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,437] INFO [Worker clientId=connect-1, groupId=connect] Connector replicate-topic config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,127] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 65 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-32 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,714] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  12 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,938] INFO [Worker clientId=connect-1, groupId=connect] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,795] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  91 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-28 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,795] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  84 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,127] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 65 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,938] INFO [Worker clientId=connect-1, groupId=connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,797] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /dist/favicon.ico HTTP/1.1" 200 22382  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-40 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,939] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,799] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,139] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 66 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,800] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /3.0/license HTTP/1.1" 200 275  5 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,946] INFO [Worker clientId=connect-1, groupId=connect] Successfully joined group with generation 5 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-36 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,157] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 67 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,800] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  5 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,946] INFO [Worker clientId=connect-1, groupId=connect] Joined group at generation 5 and got assignment: Assignment{error=0, leader='connect-1-534a2a13-2f66-4763-9455-ccc532644fa6', leaderUrl='https://connect:8083/', offset=7, connectorIds=[replicate-topic, elasticsearch-ksql, wikipedia-irc], taskIds=[elasticsearch-ksql-0, wikipedia-irc-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-47 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,158] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 67 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,899] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  28 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,946] INFO [Worker clientId=connect-1, groupId=connect] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:47,910] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,158] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,008] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  13 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,947] INFO [Worker clientId=connect-1, groupId=connect] Starting connector replicate-topic (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,947] INFO [Worker clientId=connect-1, groupId=connect] Starting task elasticsearch-ksql-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,316] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /api/ksql/KSQL/info HTTP/1.1" 200 113  221 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,162] INFO [Log partition=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-43 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,400] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,947] INFO Creating task elasticsearch-ksql-0 (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,163] INFO [Log partition=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,408] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  546 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,947] INFO ConnectorConfig values: 
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,163] INFO Created log for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,213] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,497] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,164] INFO [Partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,505] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /api/connect/connect-default/ HTTP/1.1" 200 111  507 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,505] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/status HTTP/1.1" 200 109  639 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,164] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.log.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-31 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,595] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /api/ksql/KSQL/info HTTP/1.1" 200 113  101 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,164] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-27 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,164] INFO [Partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 broker=1] _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,595] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/detail HTTP/1.1" 200 241  734 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-39 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,598] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,226] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 67 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,598] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,226] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 67 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition __consumer_offsets-35 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,599] INFO 68.93.140.216 - - [20/May/2020:20:08:47 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/status HTTP/1.1" 200 242  731 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:35,255] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 68 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,214] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition __consumer_offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 4 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,599] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:36,543] INFO [GroupCoordinator 1]: Preparing to rebalance group _confluent-controlcenter-5-3-1-1-command in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member _confluent-controlcenter-5-3-1-1-command-77ec260a-6a09-43ac-955e-589cd959aa4e-StreamThread-1-consumer-438668f5-3560-4b7d-86c7-46e06d0e86b7 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,215] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 4 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,696] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,136] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 69 from controller 2 epoch 1 for partition users-1 (state.change.logger)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-22. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,136] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 69 from controller 2 epoch 1 for partition users-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,696] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /api/ksql/KSQL/info HTTP/1.1" 200 113  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	tasks.max = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-28. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,698] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,138] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 69 from controller 2 epoch 1 starting the become-leader transition for partition users-1 (state.change.logger)
[36;1mconnect                        |[0m 	transforms = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-34. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,698] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,138] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(users-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,743] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,142] INFO [Log partition=users-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,142] INFO [Log partition=users-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-2. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,747] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,947] INFO ConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,143] INFO Created log for partition users-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-40. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,747] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,143] INFO [Partition users-1 broker=1] No checkpointed highwatermark is found for partition users-1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,143] INFO Replica loaded for partition users-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-46. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,748] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /api/ksql/KSQL/info HTTP/1.1" 200 113  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,143] INFO Replica loaded for partition users-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-8. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,786] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,143] INFO [Partition users-1 broker=1] users-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-14. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,146] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 69 for partition users-1 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-20. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,146] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 69 from controller 2 epoch 1 for the become-leader transition for partition users-1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,787] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.log.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-26. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,146] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 69 from controller 2 epoch 1 starting the become-follower transition for partition users-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,787] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-32. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,146] INFO Replica loaded for partition users-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:08:48,827] INFO 68.93.140.216 - - [20/May/2020:20:08:48 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-38. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,148] INFO [Log partition=users-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,511] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-0. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,149] INFO [Log partition=users-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,596] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/requests?interval=60000&end=1590005280000&start=1589990880000 HTTP/1.1" 200 214  78 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-44. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,150] INFO Created log for partition users-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,597] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/status HTTP/1.1" 200 242  76 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-6. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,150] INFO [Partition users-0 broker=1] No checkpointed highwatermark is found for partition users-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,603] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/status HTTP/1.1" 200 109  85 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-12. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,150] INFO Replica loaded for partition users-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,603] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/detail HTTP/1.1" 200 241  87 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	name = replicate-topic
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-18. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,151] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(users-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,606] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/request/pool?interval=60000&end=1590005280000&start=1589990880000 HTTP/1.1" 200 166  10 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,151] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 69 for partition users-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-24. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,607] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/network/pool?interval=60000&end=1590005280000&start=1589990880000 HTTP/1.1" 200 139  10 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,223] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-30. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,613] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	transforms = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,151] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition users-0 as part of become-follower request with correlation id 69 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,224] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-36. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,803] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,151] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(users-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,224] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-42. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,803] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,151] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 69 for partition users-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,224] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-4. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,803] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,151] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 69 from controller 2 epoch 1 for the become-follower transition for partition users-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,224] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-48. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,805] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,153] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition users-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 70 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,224] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-10. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,947] INFO EnrichedConnectorConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,806] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,153] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition users-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 70 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,224] INFO [GroupMetadataManager brokerId=2] Finished unloading __consumer_offsets-16. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[36;1mconnect                        |[0m 	config.action.reload = restart
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,807] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  8 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,586] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition users-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,515] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-22 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,897] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:38,586] INFO [Log partition=users-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,897] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:39,113] INFO [GroupCoordinator 1]: Member wikipedia-activity-monitor-StreamThread-1-consumer-97ae8bf2-f4b7-4081-aa38-37b038254db7 in group wikipedia-activity-monitor has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,521] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-30 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:49,897] INFO 68.93.140.216 - - [20/May/2020:20:08:49 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:39,114] INFO [GroupCoordinator 1]: Preparing to rebalance group wikipedia-activity-monitor in state PreparingRebalance with old generation 1 (__consumer_offsets-14) (reason: removing member wikipedia-activity-monitor-StreamThread-1-consumer-97ae8bf2-f4b7-4081-aa38-37b038254db7 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:08:51,914] INFO 68.93.140.216 - - [20/May/2020:20:08:51 +0000] "GET /api/connect/connect-default/connectors?expand=status&expand=info HTTP/1.1" 200 1192  15 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:39,121] INFO [GroupCoordinator 1]: Group wikipedia-activity-monitor with generation 2 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,521] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-8 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:52,023] INFO metric=CONSUMPTION_DIFF value=2 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	errors.tolerance = none
[32mcontrol-center                 |[0m [2020-05-20 20:08:52,023] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:39,543] INFO [GroupCoordinator 1]: Stabilized group _confluent-controlcenter-5-3-1-1-command generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	header.converter = null
[32mcontrol-center                 |[0m [2020-05-20 20:08:52,023] INFO now=1590005331897 deadline=1590005291328 lastTriggerTimstamp=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:39,552] INFO [GroupCoordinator 1]: Assignment received from leader for group _confluent-controlcenter-5-3-1-1-command for generation 1 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,521] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-4 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	key.converter = null
[32mcontrol-center                 |[0m [2020-05-20 20:08:52,035] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:42,309] INFO [GroupCoordinator 1]: Preparing to rebalance group wikipedia-activity-monitor in state PreparingRebalance with old generation 2 (__consumer_offsets-14) (reason: Adding new member wikipedia-activity-monitor-StreamThread-1-consumer-be917ddf-51fb-44fc-853b-324a8fa36b5a with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[32mcontrol-center                 |[0m [2020-05-20 20:08:52,050] INFO metric=CONSUMPTION_DIFF value=1 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,321] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 71 from controller 2 epoch 1 for partition wikipedia.parsed-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,521] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-46 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	tasks.max = 1
[32mcontrol-center                 |[0m [2020-05-20 20:08:52,050] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,321] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 71 from controller 2 epoch 1 for partition wikipedia.parsed-0 (state.change.logger)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	transforms = []
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,408] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,323] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 71 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.parsed-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,522] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-16 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,323] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.parsed-1) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,330] INFO [Log partition=wikipedia.parsed-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,522] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-28 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,948] INFO EnrichedConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,330] INFO [Log partition=wikipedia.parsed-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,331] INFO Created log for partition wikipedia.parsed-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,524] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-36 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,331] INFO [Partition wikipedia.parsed-1 broker=1] No checkpointed highwatermark is found for partition wikipedia.parsed-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,331] INFO Replica loaded for partition wikipedia.parsed-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,524] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-42 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,332] INFO Replica loaded for partition wikipedia.parsed-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,524] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-18 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,332] INFO [Partition wikipedia.parsed-1 broker=1] wikipedia.parsed-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,334] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 71 for partition wikipedia.parsed-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	errors.tolerance = none
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-24 at offset 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,334] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 71 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.parsed-1 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,334] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 71 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.parsed-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-38 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	name = replicate-topic
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,334] INFO Replica loaded for partition wikipedia.parsed-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,338] INFO [Log partition=wikipedia.parsed-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	transforms = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-48 at offset 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,338] INFO [Log partition=wikipedia.parsed-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,339] INFO Created log for partition wikipedia.parsed-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-2 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,948] INFO Creating connector replicate-topic of type io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,340] INFO [Partition wikipedia.parsed-0 broker=1] No checkpointed highwatermark is found for partition wikipedia.parsed-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,949] INFO Instantiated connector replicate-topic with version 5.3.1 of type class io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,340] INFO Replica loaded for partition wikipedia.parsed-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-6 at offset 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,340] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.parsed-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,949] INFO TaskConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	task.class = class io.confluent.connect.elasticsearch.ElasticsearchSinkTask
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,340] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 71 for partition wikipedia.parsed-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-14 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,340] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition wikipedia.parsed-0 as part of become-follower request with correlation id 71 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,341] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(wikipedia.parsed-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,949] INFO Instantiated task elasticsearch-ksql-0 with version 5.3.1 of type io.confluent.connect.elasticsearch.ElasticsearchSinkTask (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-20 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,410] WARN unable to check ulimit: Cannot run program "ulimit": error=2, No such file or directory (io.confluent.controlcenter.healthcheck.HealthCheck)
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,341] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 71 for partition wikipedia.parsed-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,949] INFO ReplicatorSourceConnectorConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:08:54,623] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,341] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 71 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.parsed-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	confluent.license = 
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,794] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-0 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	confluent.topic = _confluent-command
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,343] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.parsed-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 72 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,795] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	dest.kafka.bootstrap.servers = [kafka1:9091]
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,795] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	dest.kafka.client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,344] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.parsed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 72 (state.change.logger)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,796] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	dest.kafka.connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,673] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition wikipedia.parsed-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,525] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-44 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,800] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/consumer/offsets/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 381  9 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	dest.kafka.metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:44,673] INFO [Log partition=wikipedia.parsed-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,835] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	dest.kafka.metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,251] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 73 from controller 2 epoch 1 for partition _confluent-ksql-default__command_topic-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,526] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-12 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	dest.kafka.metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,252] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 73 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-ksql-default__command_topic-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,835] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,252] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-ksql-default__command_topic-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	dest.kafka.receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,255] INFO [Log partition=_confluent-ksql-default__command_topic-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,534] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-26 at offset 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,835] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	dest.kafka.reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,256] INFO [Log partition=_confluent-ksql-default__command_topic-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	dest.kafka.request.timeout.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,835] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,256] INFO Created log for partition _confluent-ksql-default__command_topic-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 9223372036854775807, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,535] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-34 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	dest.kafka.retry.backoff.ms = 100
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,836] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,257] INFO [Partition _confluent-ksql-default__command_topic-0 broker=1] No checkpointed highwatermark is found for partition _confluent-ksql-default__command_topic-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	dest.kafka.send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,257] INFO Replica loaded for partition _confluent-ksql-default__command_topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:08:55,897] INFO 68.93.140.216 - - [20/May/2020:20:08:55 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,535] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-10 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	dest.zookeeper.connect = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,257] INFO [Partition _confluent-ksql-default__command_topic-0 broker=1] _confluent-ksql-default__command_topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:08:56,500] INFO 68.93.140.216 - - [20/May/2020:20:08:54 +0000] "POST /api/ksql/KSQL/ksql HTTP/1.1" 200 3443  1815 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	dest.zookeeper.connection.timeout.ms = 6000
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,259] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 73 for partition _confluent-ksql-default__command_topic-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:08:59,550] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,535] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-32 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	dest.zookeeper.session.timeout.ms = 6000
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,259] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 73 from controller 2 epoch 1 for the become-leader transition for partition _confluent-ksql-default__command_topic-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:00,821] INFO 68.93.140.216 - - [20/May/2020:20:09:00 +0000] "GET /2.0/consumer/offsets/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 385  5 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	offset.start = connect
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,261] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-ksql-default__command_topic-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 74 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:02,015] INFO 68.93.140.216 - - [20/May/2020:20:09:01 +0000] "GET /2.0/kafka/lbUe4hq7QeWfnY0W4R-PhA/topics HTTP/1.1" 200 1491  108 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,311] INFO [GroupCoordinator 1]: Stabilized group wikipedia-activity-monitor generation 3 (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,535] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition __consumer_offsets-40 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	offset.timestamps.commit = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,440] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 75 from controller 2 epoch 1 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:02,408] INFO 68.93.140.216 - - [20/May/2020:20:09:01 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/detail HTTP/1.1" 200 1551  506 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,441] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 75 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	offset.topic.commit = true
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[32mcontrol-center                 |[0m [2020-05-20 20:09:02,496] INFO 68.93.140.216 - - [20/May/2020:20:09:02 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  30 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,441] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	offset.translator.batch.period.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,660] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0}]} for request LEADER_AND_ISR with correlation id 3 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:04,175] INFO 68.93.140.216 - - [20/May/2020:20:09:04 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/users/requests?interval=60000&end=1590005280000&start=1589990880000 HTTP/1.1" 200 143  6 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,444] INFO [Log partition=wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	offset.translator.batch.size = 1
[32mcontrol-center                 |[0m [2020-05-20 20:09:04,176] INFO 68.93.140.216 - - [20/May/2020:20:09:04 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/detail/users?interval=60000&end=1590005280000&start=1589990880000 HTTP/1.1" 200 161  7 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	offset.translator.tasks.max = -1
[32mcontrol-center                 |[0m [2020-05-20 20:09:04,177] INFO 68.93.140.216 - - [20/May/2020:20:09:04 +0000] "GET /2.0/kafka/lbUe4hq7QeWfnY0W4R-PhA/topics/users/config HTTP/1.1" 200 656  12 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,444] INFO [Log partition=wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:25,747] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 4 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.tasks.separate = false
[32mcontrol-center                 |[0m [2020-05-20 20:09:04,208] INFO 68.93.140.216 - - [20/May/2020:20:09:04 +0000] "GET /2.0/kafka/lbUe4hq7QeWfnY0W4R-PhA/topics HTTP/1.1" 200 1491  46 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,917] INFO Creating topic _schemas with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,445] INFO Created log for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,933] INFO [Controller id=2] New topics: [Set(_schemas)], deleted topics: [Set()], new partition replica assignment [Map(_schemas-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	provenance.header.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,933] INFO [Controller id=2] New partition creation callback for _schemas-0 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:09:04,564] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m 	provenance.header.filter.overrides = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,933] TRACE [Controller id=2 epoch=1] Changed partition _schemas-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,445] INFO [Partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 broker=1] No checkpointed highwatermark is found for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,933] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _schemas-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,445] INFO Replica loaded for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:09,551] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,933] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _schemas-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.credentials.source = URL
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,445] INFO [Partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 broker=1] wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:10,829] INFO 68.93.140.216 - - [20/May/2020:20:09:10 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.user.info = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,995] TRACE [Controller id=2 epoch=1] Changed partition _schemas-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,447] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 75 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.max.schemas.per.subject = 1000
[32mcontrol-center                 |[0m [2020-05-20 20:09:10,829] INFO 68.93.140.216 - - [20/May/2020:20:09:10 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,995] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _schemas-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,447] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 75 from controller 2 epoch 1 for the become-leader transition for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.topic = null
[32mcontrol-center                 |[0m [2020-05-20 20:09:10,842] INFO 68.93.140.216 - - [20/May/2020:20:09:10 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,996] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _schemas-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,449] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 76 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.url = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,997] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 5 from controller 2 epoch 1 for partition _schemas-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:10,843] INFO 68.93.140.216 - - [20/May/2020:20:09:10 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	schema.subject.translator.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,449] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 76 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,997] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 5 from controller 2 epoch 1 starting the become-follower transition for partition _schemas-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.check.crcs = true
[32mcontrol-center                 |[0m [2020-05-20 20:09:10,853] INFO 68.93.140.216 - - [20/May/2020:20:09:10 +0000] "GET /3.0/license HTTP/1.1" 200 275  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:29,998] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:45,511] INFO [GroupCoordinator 1]: Assignment received from leader for group wikipedia-activity-monitor for generation 3 (kafka.coordinator.group.GroupCoordinator)
[32mcontrol-center                 |[0m [2020-05-20 20:09:10,853] INFO 68.93.140.216 - - [20/May/2020:20:09:10 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,001] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _schemas-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:47,313] INFO [GroupCoordinator 1]: Preparing to rebalance group _confluent-controlcenter-5-3-1-1 in state PreparingRebalance with old generation 0 (__consumer_offsets-28) (reason: Adding new member _confluent-controlcenter-5-3-1-1-64d98ef1-6b68-4a3c-9314-7f1a5a5f86bf-StreamThread-1-consumer-262f6fee-2ba2-4570-a25d-109164160d49 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.bytes = 52428800
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,553] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,005] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _schemas-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,315] INFO [GroupCoordinator 1]: Stabilized group _confluent-controlcenter-5-3-1-1 generation 1 (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.wait.ms = 500
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,706] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,005] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _schemas-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.fetch.min.bytes = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,349] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 77 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,707] INFO Returning rate from the metrics input topic 9.000547859434922 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,007] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,350] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 77 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,707] INFO Returning rate from the monitoring input topic NaN (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,007] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,350] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,707] INFO Returning last timestamp consumed from the metrics input topic: 1.590005329116E12 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,008] INFO Created log for partition _schemas-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	src.consumer.max.poll.interval.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,009] INFO [Partition _schemas-0 broker=2] No checkpointed highwatermark is found for partition _schemas-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,707] INFO Returning last timestamp consumed from the monitoring input topic: 1.59000531E12 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	src.consumer.max.poll.records = 500
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,353] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,009] INFO Replica loaded for partition _schemas-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,711] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/status/app_info/ HTTP/1.1" 200 122  8 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,712] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,353] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,010] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_schemas-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.bootstrap.servers = [kafka1:9091]
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,712] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,354] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.kafka.client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,010] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 5 for partition _schemas-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,713] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,354] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,010] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _schemas-0 as part of become-follower request with correlation id 5 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,354] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,713] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,010] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_schemas-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,354] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 77 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,010] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 5 for partition _schemas-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,745] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,354] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 as part of become-follower request with correlation id 77 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,010] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 5 from controller 2 epoch 1 for the become-follower transition for partition _schemas-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,748] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,012] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_schemas,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 5 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,355] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,794] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  47 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,021] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _schemas-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 6 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,355] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 77 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:14,795] INFO 68.93.140.216 - - [20/May/2020:20:09:14 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  48 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,024] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_schemas,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 5 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,355] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 77 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:17,462] INFO 68.93.140.216 - - [20/May/2020:20:09:17 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.request.timeout.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,551] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,029] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 6 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,356] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 78 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,042] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 6 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,736] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,402] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 79 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,132] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _schemas-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	src.kafka.sasl.jaas.config = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,737] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,403] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 79 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:30,133] INFO [Log partition=_schemas-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,738] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,403] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,960] INFO Creating topic _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,408] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,738] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,966] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,408] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,966] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,741] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /api/ksql/KSQL/info HTTP/1.1" 200 113  5 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,409] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,966] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,741] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,409] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.callback.handler.class = null
[36;1mconnect                        |[0m 	src.kafka.sasl.login.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,782] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,409] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,966] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,782] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,410] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,782] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,966] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,410] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 79 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,410] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 as part of become-follower request with correlation id 79 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,782] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,971] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,410] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,785] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/status HTTP/1.1" 200 245  5 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,971] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,410] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 79 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,972] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,799] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/status HTTP/1.1" 200 109  20 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,410] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 79 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,972] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,820] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,413] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 80 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,972] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,820] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,495] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 81 from controller 2 epoch 1 for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,495] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 81 from controller 2 epoch 1 for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,972] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,820] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,497] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 81 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,972] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 7 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.endpoint.identification.algorithm = https
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,825] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/detail HTTP/1.1" 200 238  8 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,497] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.parsed.count-by-channel-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.ssl.key.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:19,862] INFO 68.93.140.216 - - [20/May/2020:20:09:19 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,518] INFO [Log partition=wikipedia.parsed.count-by-channel-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,973] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 7 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,973] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,976] INFO [Log partition=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,976] INFO [Log partition=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,977] INFO Created log for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,978] INFO [Partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.kafka.ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,826] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,519] INFO [Log partition=wikipedia.parsed.count-by-channel-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,978] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,840] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/requests?interval=60000&end=1590005340000&start=1589990940000 HTTP/1.1" 200 236  4 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,519] INFO Created log for partition wikipedia.parsed.count-by-channel-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,978] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,840] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/status HTTP/1.1" 200 245  5 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,520] INFO [Partition wikipedia.parsed.count-by-channel-1 broker=1] No checkpointed highwatermark is found for partition wikipedia.parsed.count-by-channel-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,978] INFO [Partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 broker=2] _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,843] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/topic/status HTTP/1.1" 200 109  8 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,981] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 7 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,981] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 7 for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,981] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 7 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,520] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,843] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/request/pool?interval=60000&end=1590005340000&start=1589990940000 HTTP/1.1" 200 177  8 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,982] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 7 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,520] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,846] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/detail HTTP/1.1" 200 238  11 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,983] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 8 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,872] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/broker/network/pool?interval=60000&end=1590005340000&start=1589990940000 HTTP/1.1" 200 142  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:31,983] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 8 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,520] INFO [Partition wikipedia.parsed.count-by-channel-1 broker=1] wikipedia.parsed.count-by-channel-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,873] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,002] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 8 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,522] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 81 for partition wikipedia.parsed.count-by-channel-1 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,895] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  24 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,014] INFO Creating topic _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,523] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 81 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,919] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,025] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,523] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 81 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.parsed.count-by-channel-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,919] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,025] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,523] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,934] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,526] INFO [Log partition=wikipedia.parsed.count-by-channel-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,934] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,026] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,526] INFO [Log partition=wikipedia.parsed.count-by-channel-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,935] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	src.zookeeper.connect = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,026] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,527] INFO Created log for partition wikipedia.parsed.count-by-channel-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:21,961] INFO 68.93.140.216 - - [20/May/2020:20:09:21 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,026] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.connection.timeout.ms = 6000
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,527] INFO [Partition wikipedia.parsed.count-by-channel-0 broker=1] No checkpointed highwatermark is found for partition wikipedia.parsed.count-by-channel-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,009] INFO 68.93.140.216 - - [20/May/2020:20:09:22 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,032] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.session.timeout.ms = 6000
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,527] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,032] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,343] INFO metric=CONSUMPTION_DIFF value=1 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,527] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.parsed.count-by-channel-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	topic.auto.create = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,033] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,343] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,528] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 81 for partition wikipedia.parsed.count-by-channel-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	topic.blacklist = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,038] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,528] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition wikipedia.parsed.count-by-channel-0 as part of become-follower request with correlation id 81 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	topic.config.sync = true
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,343] INFO now=1590005362174 deadline=1590005322339 lastTriggerTimstamp=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,038] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,528] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(wikipedia.parsed.count-by-channel-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	topic.config.sync.interval.ms = 120000
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,402] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,038] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,528] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 81 for partition wikipedia.parsed.count-by-channel-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	topic.create.backoff.ms = 120000
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,415] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,041] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 9 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,528] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 81 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.parsed.count-by-channel-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	topic.poll.interval.ms = 120000
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,415] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,043] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 9 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,531] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.parsed.count-by-channel-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 82 (state.change.logger)
[36;1mconnect                        |[0m 	topic.preserve.partitions = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,043] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,416] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,531] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.parsed.count-by-channel-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 82 (state.change.logger)
[36;1mconnect                        |[0m 	topic.regex = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,046] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:22,416] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,533] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 83 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.rename.format = ${topic}.replica
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,047] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,548] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,533] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 83 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,047] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	topic.timestamp.type = CreateTime
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,980] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,049] INFO [Partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,534] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 83 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,981] INFO 68.93.140.216 - - [20/May/2020:20:09:24 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	topic.whitelist = [wikipedia.parsed]
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,049] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,534] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,981] INFO 68.93.140.216 - - [20/May/2020:20:09:24 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (io.confluent.connect.replicator.ReplicatorSourceConnectorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,050] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,982] INFO 68.93.140.216 - - [20/May/2020:20:09:24 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  4 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,537] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,950] INFO AvroConverterConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,982] INFO 68.93.140.216 - - [20/May/2020:20:09:24 +0000] "GET /2.0/clusters/schema-registry HTTP/1.1" 200 137  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,050] INFO [Partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,538] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	bearer.auth.token = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,052] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 9 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,983] INFO 68.93.140.216 - - [20/May/2020:20:09:24 +0000] "GET /2.0/clusters/kafka/display/stream-monitoring HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,539] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,115] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 10 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,540] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	schema.registry.url = [https://schemaregistry:8085]
[32mcontrol-center                 |[0m [2020-05-20 20:09:24,983] INFO 68.93.140.216 - - [20/May/2020:20:09:24 +0000] "GET /2.0/clusters/kafka/display/cluster_management HTTP/1.1" 200 108  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,120] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 9 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,017] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,540] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,017] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /3.0/auth/principal HTTP/1.1" 200 50  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,120] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 9 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,540] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,017] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,121] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 9 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	auto.register.schemas = true
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,018] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,540] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 broker=1] _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,123] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 10 (state.change.logger)
[36;1mconnect                        |[0m 	max.schemas.per.subject = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,543] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 83 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,022] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,125] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 10 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,043] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589992800000&stopTimeMs=1590007200000&rollup=ONE_MINUTE&type=MEMBER_LIST HTTP/1.1" 200 322  17 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,543] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 83 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,137] INFO Creating topic _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,121] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589992800000&stopTimeMs=1590007200000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 396  12 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,543] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 83 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,150] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,121] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589992800000&stopTimeMs=1590007200000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 379  11 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,543] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:25,121] INFO 68.93.140.216 - - [20/May/2020:20:09:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589992800000&stopTimeMs=1590007200000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 419  11 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,150] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[36;1mconnect                        |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[36;1mconnect                        |[0m  (io.confluent.connect.avro.AvroConverterConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,950] INFO Starting replicator connector replicate-topic (io.confluent.connect.replicator.ReplicatorSourceConnector)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,601] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,150] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:26,951] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,602] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,950] INFO KafkaAvroSerializerConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:09:26,953] INFO 68.93.140.216 - - [20/May/2020:20:09:26 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,603] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,151] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	bearer.auth.token = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:27,003] INFO 68.93.140.216 - - [20/May/2020:20:09:26 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 411  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	schema.registry.url = [https://schemaregistry:8085]
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:27,003] INFO 68.93.140.216 - - [20/May/2020:20:09:26 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 412  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,151] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	basic.auth.user.info = [hidden]
[36;1mconnect                        |[0m 	auto.register.schemas = true
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,157] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 83 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	max.schemas.per.subject = 1000
[32mcontrol-center                 |[0m [2020-05-20 20:09:27,003] INFO 68.93.140.216 - - [20/May/2020:20:09:26 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 376  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,157] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 as part of become-follower request with correlation id 83 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:27,006] INFO 68.93.140.216 - - [20/May/2020:20:09:27 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 364  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	basic.auth.credentials.source = URL
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,158] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:28,960] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	schema.registry.basic.auth.user.info = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,159] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:28,961] INFO 68.93.140.216 - - [20/May/2020:20:09:28 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 83 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,159] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:29,011] INFO 68.93.140.216 - - [20/May/2020:20:09:29 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 366  4 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,604] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 83 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,159] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:29,011] INFO 68.93.140.216 - - [20/May/2020:20:09:29 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 394  4 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,606] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 84 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:29,028] INFO 68.93.140.216 - - [20/May/2020:20:09:29 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 383  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,159] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 11 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,607] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 84 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:29,028] INFO 68.93.140.216 - - [20/May/2020:20:09:29 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 410  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,161] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 11 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:09:29,548] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,951] INFO KafkaAvroDeserializerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,161] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	bearer.auth.token = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:30,946] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,195] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition wikipedia.parsed.count-by-channel-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	schema.registry.url = [https://schemaregistry:8085]
[32mcontrol-center                 |[0m [2020-05-20 20:09:30,947] INFO 68.93.140.216 - - [20/May/2020:20:09:30 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,196] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [Log partition=wikipedia.parsed.count-by-channel-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:30,993] INFO 68.93.140.216 - - [20/May/2020:20:09:30 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,196] INFO Created log for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	auto.register.schemas = true
[32mcontrol-center                 |[0m [2020-05-20 20:09:30,993] INFO 68.93.140.216 - - [20/May/2020:20:09:30 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 245  2 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m [2020-05-20 20:09:30,998] INFO 68.93.140.216 - - [20/May/2020:20:09:30 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,198] INFO [Partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:09:31,101] INFO 68.93.140.216 - - [20/May/2020:20:09:31 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  4 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,198] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:32,467] INFO 68.93.140.216 - - [20/May/2020:20:09:32 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	max.schemas.per.subject = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,198] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,613] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	basic.auth.credentials.source = URL
[32mcontrol-center                 |[0m [2020-05-20 20:09:33,048] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,621] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 85 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,198] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 11 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.basic.auth.user.info = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:33,049] INFO 68.93.140.216 - - [20/May/2020:20:09:33 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,621] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 85 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,198] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 as part of become-follower request with correlation id 11 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:33,096] INFO 68.93.140.216 - - [20/May/2020:20:09:33 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 216  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	bearer.auth.credentials.source = STATIC_TOKEN
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,622] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 85 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,199] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:33,096] INFO 68.93.140.216 - - [20/May/2020:20:09:33 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 248  4 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	specific.avro.reader = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,622] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:33,097] INFO 68.93.140.216 - - [20/May/2020:20:09:33 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 271  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,200] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 11 for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,626] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:33,100] INFO 68.93.140.216 - - [20/May/2020:20:09:33 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,200] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 11 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,627] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:34,548] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[36;1mconnect                        |[0m  (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,201] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 11 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:34,963] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,627] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,951] INFO AvroDataConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,629] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:34,964] INFO 68.93.140.216 - - [20/May/2020:20:09:34 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	connect.meta.data = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,203] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 12 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,629] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:35,009] INFO 68.93.140.216 - - [20/May/2020:20:09:35 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 245  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	enhanced.avro.schema.support = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,208] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 12 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:35,009] INFO 68.93.140.216 - - [20/May/2020:20:09:35 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,629] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	schemas.cache.config = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,210] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 11 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:35,009] INFO 68.93.140.216 - - [20/May/2020:20:09:35 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,629] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 broker=1] _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m  (io.confluent.connect.avro.AvroDataConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,213] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 12 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:35,014] INFO 68.93.140.216 - - [20/May/2020:20:09:35 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 249  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,631] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 85 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,952] INFO StringConverterConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,220] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,631] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 85 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	converter.encoding = UTF8
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,228] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,631] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 85 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,236] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:09:36,953] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,631] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,236] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	converter.type = key
[32mcontrol-center                 |[0m [2020-05-20 20:09:36,954] INFO 68.93.140.216 - - [20/May/2020:20:09:36 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,634] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.storage.StringConverterConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:09:36,998] INFO 68.93.140.216 - - [20/May/2020:20:09:36 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 215  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,237] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,634] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:36,998] INFO 68.93.140.216 - - [20/May/2020:20:09:36 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 248  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,952] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task elasticsearch-ksql-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,237] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:37,001] INFO 68.93.140.216 - - [20/May/2020:20:09:36 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 268  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,635] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,952] INFO Set up the value converter class io.confluent.connect.avro.AvroConverter for task elasticsearch-ksql-0 using the connector config (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,246] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:37,002] INFO 68.93.140.216 - - [20/May/2020:20:09:37 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,635] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 broker=1] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,246] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,206] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,952] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task elasticsearch-ksql-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,635] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,207] INFO 68.93.140.216 - - [20/May/2020:20:09:39 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,953] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,636] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,247] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,953] INFO SinkConnectorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,247] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,253] INFO 68.93.140.216 - - [20/May/2020:20:09:39 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 247  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,636] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 85 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,248] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,253] INFO 68.93.140.216 - - [20/May/2020:20:09:39 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 215  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,636] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 as part of become-follower request with correlation id 85 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,248] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,256] INFO 68.93.140.216 - - [20/May/2020:20:09:39 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.deadletterqueue.context.headers.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,636] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,249] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 13 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,256] INFO 68.93.140.216 - - [20/May/2020:20:09:39 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 270  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,636] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 85 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.name = 
[32mcontrol-center                 |[0m [2020-05-20 20:09:39,550] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,636] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 85 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,250] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 13 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:40,184] INFO 68.93.140.216 - - [20/May/2020:20:09:40 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.replication.factor = 3
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,697] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 86 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,250] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:40,184] INFO 68.93.140.216 - - [20/May/2020:20:09:40 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,697] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 86 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,255] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,255] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:40,184] INFO 68.93.140.216 - - [20/May/2020:20:09:40 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:50,725] INFO [GroupCoordinator 1]: Assignment received from leader for group _confluent-controlcenter-5-3-1-1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,255] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:40,184] INFO 68.93.140.216 - - [20/May/2020:20:09:40 +0000] "GET /3.0/license HTTP/1.1" 200 275  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,259] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 13 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:40,187] INFO 68.93.140.216 - - [20/May/2020:20:09:40 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,317] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:04:51,121] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:09:40,187] INFO 68.93.140.216 - - [20/May/2020:20:09:40 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:51,121] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,328] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:41,387] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,407] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 87 from controller 2 epoch 1 for partition wikipedia.failed-0 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,317] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 14 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:41,388] INFO 68.93.140.216 - - [20/May/2020:20:09:41 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,407] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 87 from controller 2 epoch 1 for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,329] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:41,432] INFO 68.93.140.216 - - [20/May/2020:20:09:41 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 251  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,408] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 87 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.failed-0 (state.change.logger)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,332] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 13 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:41,433] INFO 68.93.140.216 - - [20/May/2020:20:09:41 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 268  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,408] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.failed-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:41,435] INFO 68.93.140.216 - - [20/May/2020:20:09:41 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 276  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,332] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 as part of become-follower request with correlation id 13 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	topics = [WIKIPEDIABOT]
[32mcontrol-center                 |[0m [2020-05-20 20:09:41,448] INFO 68.93.140.216 - - [20/May/2020:20:09:41 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 215  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,411] INFO [Log partition=wikipedia.failed-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	topics.regex = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,333] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:43,544] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,411] INFO [Log partition=wikipedia.failed-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	transforms = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,333] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 13 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,412] INFO Created log for partition wikipedia.failed-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:43,545] INFO 68.93.140.216 - - [20/May/2020:20:09:43 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,333] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 13 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,412] INFO [Partition wikipedia.failed-0 broker=1] No checkpointed highwatermark is found for partition wikipedia.failed-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:43,686] INFO 68.93.140.216 - - [20/May/2020:20:09:43 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 235  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,336] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 13 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,412] INFO Replica loaded for partition wikipedia.failed-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:43,686] INFO 68.93.140.216 - - [20/May/2020:20:09:43 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 270  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,953] INFO EnrichedConnectorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,338] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 14 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,412] INFO Replica loaded for partition wikipedia.failed-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:43,686] INFO 68.93.140.216 - - [20/May/2020:20:09:43 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	config.action.reload = restart
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,342] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 14 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,412] INFO [Partition wikipedia.failed-0 broker=1] wikipedia.failed-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:43,686] INFO 68.93.140.216 - - [20/May/2020:20:09:43 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 215  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,414] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 87 for partition wikipedia.failed-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,349] INFO Creating topic _confluent-controlcenter-5-3-1-1-cluster-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,414] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 87 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.failed-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:44,557] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,357] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-cluster-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-cluster-rekey-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	errors.deadletterqueue.context.headers.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,357] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.name = 
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,415] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 87 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.failed-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,357] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	errors.deadletterqueue.topic.replication.factor = 3
[32mcontrol-center                 |[0m [2020-05-20 20:09:45,685] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,357] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,415] INFO Replica loaded for partition wikipedia.failed-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.log.enable = false
[32mcontrol-center                 |[0m [2020-05-20 20:09:45,686] INFO 68.93.140.216 - - [20/May/2020:20:09:45 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,357] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,417] INFO [Log partition=wikipedia.failed-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[32mcontrol-center                 |[0m [2020-05-20 20:09:45,735] INFO 68.93.140.216 - - [20/May/2020:20:09:45 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 270  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,362] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:45,740] INFO 68.93.140.216 - - [20/May/2020:20:09:45 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 235  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,362] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,417] INFO [Log partition=wikipedia.failed-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,363] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,418] INFO Created log for partition wikipedia.failed-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:45,972] INFO 68.93.140.216 - - [20/May/2020:20:09:45 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 275  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,363] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,418] INFO [Partition wikipedia.failed-1 broker=1] No checkpointed highwatermark is found for partition wikipedia.failed-1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:46,072] INFO 68.93.140.216 - - [20/May/2020:20:09:46 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 251  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,363] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,418] INFO Replica loaded for partition wikipedia.failed-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:47,295] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,363] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,419] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.failed-1) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:47,296] INFO 68.93.140.216 - - [20/May/2020:20:09:47 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,363] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 15 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	name = elasticsearch-ksql
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,419] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 87 for partition wikipedia.failed-1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:47,338] INFO 68.93.140.216 - - [20/May/2020:20:09:47 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 215  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,408] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 15 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,419] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition wikipedia.failed-1 as part of become-follower request with correlation id 87 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:47,341] INFO 68.93.140.216 - - [20/May/2020:20:09:47 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,408] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-cluster-rekey-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	topics = [WIKIPEDIABOT]
[32mcontrol-center                 |[0m [2020-05-20 20:09:47,341] INFO 68.93.140.216 - - [20/May/2020:20:09:47 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 270  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,419] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(wikipedia.failed-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,415] INFO [Log partition=_confluent-controlcenter-5-3-1-1-cluster-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	topics.regex = 
[32mcontrol-center                 |[0m [2020-05-20 20:09:47,347] INFO 68.93.140.216 - - [20/May/2020:20:09:47 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 248  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,419] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 87 for partition wikipedia.failed-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,415] INFO [Log partition=_confluent-controlcenter-5-3-1-1-cluster-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	transforms = []
[32mcontrol-center                 |[0m [2020-05-20 20:09:48,306] INFO 68.93.140.216 - - [20/May/2020:20:09:48 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,419] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 87 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.failed-1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,198] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,199] INFO 68.93.140.216 - - [20/May/2020:20:09:49 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,420] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-cluster-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 15 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.avro.AvroConverter
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,421] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.failed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 88 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,242] INFO 68.93.140.216 - - [20/May/2020:20:09:49 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 270  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,424] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 16 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,421] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.failed-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 88 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,243] INFO 68.93.140.216 - - [20/May/2020:20:09:49 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 235  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,428] INFO Created log for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:42,954] INFO ConsumerConfig values: 
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,245] INFO 68.93.140.216 - - [20/May/2020:20:09:49 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 275  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,553] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition wikipedia.failed-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,429] INFO [Partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	allow.auto.create.topics = true
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,248] INFO 68.93.140.216 - - [20/May/2020:20:09:49 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 250  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:04:56,553] INFO [Log partition=wikipedia.failed-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,429] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	auto.commit.interval.ms = 5000
[32mcontrol-center                 |[0m [2020-05-20 20:09:49,609] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,430] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 89 from controller 2 epoch 1 for partition WIKIPEDIABOT-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,430] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:51,463] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[32mcontrol-center                 |[0m [2020-05-20 20:09:51,464] INFO 68.93.140.216 - - [20/May/2020:20:09:51 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	auto.offset.reset = earliest
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,431] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 89 from controller 2 epoch 1 for partition WIKIPEDIABOT-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,430] INFO [Partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 broker=2] _confluent-controlcenter-5-3-1-1-cluster-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:51,508] INFO 68.93.140.216 - - [20/May/2020:20:09:51 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 216  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,436] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 15 for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,432] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 89 from controller 2 epoch 1 starting the become-leader transition for partition WIKIPEDIABOT-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,432] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(WIKIPEDIABOT-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,436] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 15 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:51,511] INFO 68.93.140.216 - - [20/May/2020:20:09:51 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,439] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-cluster-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 15 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,434] INFO [Log partition=WIKIPEDIABOT-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:51,511] INFO 68.93.140.216 - - [20/May/2020:20:09:51 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 270  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	client.id = connector-consumer-elasticsearch-ksql-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,442] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-cluster-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 16 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,435] INFO [Log partition=WIKIPEDIABOT-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:51,512] INFO 68.93.140.216 - - [20/May/2020:20:09:51 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 268  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	client.rack = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,443] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 16 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,435] INFO Created log for partition WIKIPEDIABOT-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:52,747] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,455] INFO Creating topic _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,436] INFO [Partition WIKIPEDIABOT-0 broker=1] No checkpointed highwatermark is found for partition WIKIPEDIABOT-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:09:52,760] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	default.api.timeout.ms = 60000
[36;1mconnect                        |[0m 	enable.auto.commit = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,436] INFO Replica loaded for partition WIKIPEDIABOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:52,760] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	exclude.internal.topics = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,464] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,464] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:09:53,508] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	fetch.max.bytes = 52428800
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,436] INFO Replica loaded for partition WIKIPEDIABOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,464] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:53,509] INFO 68.93.140.216 - - [20/May/2020:20:09:53 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,436] INFO [Partition WIKIPEDIABOT-0 broker=1] WIKIPEDIABOT-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,465] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:53,823] INFO 68.93.140.216 - - [20/May/2020:20:09:53 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 246  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	fetch.min.bytes = 1
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,438] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 89 for partition WIKIPEDIABOT-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,465] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	group.id = connect-elasticsearch-ksql
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,439] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 89 from controller 2 epoch 1 for the become-leader transition for partition WIKIPEDIABOT-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:53,833] INFO 68.93.140.216 - - [20/May/2020:20:09:53 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 275  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	group.instance.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,509] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,439] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 89 from controller 2 epoch 1 starting the become-follower transition for partition WIKIPEDIABOT-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[32mcontrol-center                 |[0m [2020-05-20 20:09:53,833] INFO 68.93.140.216 - - [20/May/2020:20:09:53 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 250  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,509] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,439] INFO Replica loaded for partition WIKIPEDIABOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[32mcontrol-center                 |[0m [2020-05-20 20:09:53,885] INFO 68.93.140.216 - - [20/May/2020:20:09:53 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 212  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,510] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 17 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,441] INFO [Log partition=WIKIPEDIABOT-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	internal.leave.group.on.close = true
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,441] INFO [Log partition=WIKIPEDIABOT-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,511] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 17 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	isolation.level = read_uncommitted
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,442] INFO Created log for partition WIKIPEDIABOT-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,511] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,512] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,442] INFO [Partition WIKIPEDIABOT-1 broker=1] No checkpointed highwatermark is found for partition WIKIPEDIABOT-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,517] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,442] INFO Replica loaded for partition WIKIPEDIABOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,517] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,442] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(WIKIPEDIABOT-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	max.poll.records = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,517] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,442] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 89 for partition WIKIPEDIABOT-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,519] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,443] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition WIKIPEDIABOT-1 as part of become-follower request with correlation id 89 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,520] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,443] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(WIKIPEDIABOT-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,521] INFO Created log for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,522] INFO [Partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,443] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 89 for partition WIKIPEDIABOT-1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,522] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,443] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 89 from controller 2 epoch 1 for the become-follower transition for partition WIKIPEDIABOT-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,522] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,456] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition WIKIPEDIABOT-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 90 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,522] INFO [Partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,456] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition WIKIPEDIABOT-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 90 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,527] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 17 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,595] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition WIKIPEDIABOT-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,527] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 17 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:02,595] INFO [Log partition=WIKIPEDIABOT-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,535] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 17 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,427] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 91 from controller 2 epoch 1 for partition WIKIPEDIANOBOT-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,538] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 18 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,427] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 91 from controller 2 epoch 1 for partition WIKIPEDIANOBOT-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,549] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 18 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,553] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 17 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,429] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 91 from controller 2 epoch 1 starting the become-leader transition for partition WIKIPEDIANOBOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,429] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(WIKIPEDIANOBOT-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,556] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 18 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,557] INFO Creating topic _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,431] INFO [Log partition=WIKIPEDIANOBOT-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,623] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,431] INFO [Log partition=WIKIPEDIANOBOT-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,623] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,432] INFO Created log for partition WIKIPEDIANOBOT-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,624] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,409] INFO triggerList=[] (io.confluent.controlcenter.alert.AlertManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,432] INFO [Partition WIKIPEDIANOBOT-0 broker=1] No checkpointed highwatermark is found for partition WIKIPEDIANOBOT-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,624] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,410] WARN unable to check ulimit: Cannot run program "ulimit": error=2, No such file or directory (io.confluent.controlcenter.healthcheck.HealthCheck)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,432] INFO Replica loaded for partition WIKIPEDIANOBOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:09:54,605] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,624] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,432] INFO Replica loaded for partition WIKIPEDIANOBOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,270] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,432] INFO [Partition WIKIPEDIANOBOT-0 broker=1] WIKIPEDIANOBOT-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,633] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,271] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,435] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 91 for partition WIKIPEDIANOBOT-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,634] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,635] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,283] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,435] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 91 from controller 2 epoch 1 for the become-leader transition for partition WIKIPEDIANOBOT-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,636] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,286] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,435] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 91 from controller 2 epoch 1 starting the become-follower transition for partition WIKIPEDIANOBOT-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,636] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 19 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,435] INFO Replica loaded for partition WIKIPEDIANOBOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,286] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /3.0/license HTTP/1.1" 200 275  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,639] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,437] INFO [Log partition=WIKIPEDIANOBOT-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,286] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,639] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,497] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 47  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,640] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 19 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,437] INFO [Log partition=WIKIPEDIANOBOT-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,502] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER_LIST HTTP/1.1" 200 321  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,641] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,438] INFO Created log for partition WIKIPEDIANOBOT-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,644] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,438] INFO [Partition WIKIPEDIANOBOT-1 broker=1] No checkpointed highwatermark is found for partition WIKIPEDIANOBOT-1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,438] INFO Replica loaded for partition WIKIPEDIANOBOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,505] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 229  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,438] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(WIKIPEDIANOBOT-1) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,505] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,645] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,439] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 91 for partition WIKIPEDIANOBOT-1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,506] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 268  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,645] INFO Created log for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,439] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition WIKIPEDIANOBOT-1 as part of become-follower request with correlation id 91 from controller 2 epoch 1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:55,685] INFO 68.93.140.216 - - [20/May/2020:20:09:55 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,439] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(WIKIPEDIANOBOT-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [2020-05-20 20:09:57,180] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,646] INFO [Partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,439] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 91 for partition WIKIPEDIANOBOT-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,646] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,439] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 91 from controller 2 epoch 1 for the become-follower transition for partition WIKIPEDIANOBOT-1 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:57,181] INFO 68.93.140.216 - - [20/May/2020:20:09:57 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,647] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:57,220] INFO 68.93.140.216 - - [20/May/2020:20:09:57 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 412  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,647] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 19 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,440] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition WIKIPEDIANOBOT-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 92 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:57,230] INFO 68.93.140.216 - - [20/May/2020:20:09:57 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 212  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,441] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition WIKIPEDIANOBOT-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 92 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,647] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 as part of become-follower request with correlation id 19 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:57,231] INFO 68.93.140.216 - - [20/May/2020:20:09:57 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005340000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 252  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,928] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition WIKIPEDIANOBOT-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	ssl.provider = null
[32mcontrol-center                 |[0m [2020-05-20 20:09:58,978] INFO 68.93.140.216 - - [20/May/2020:20:09:58 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 377  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:08,928] INFO [Log partition=WIKIPEDIANOBOT-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,647] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,210] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,505] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 93 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,647] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 19 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,211] INFO 68.93.140.216 - - [20/May/2020:20:09:59 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,505] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 93 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,647] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 19 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,253] INFO 68.93.140.216 - - [20/May/2020:20:09:59 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 366  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,507] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 93 from controller 2 epoch 1 starting the become-leader transition for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,648] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 19 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,255] INFO 68.93.140.216 - - [20/May/2020:20:09:59 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 406  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,507] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,256] INFO 68.93.140.216 - - [20/May/2020:20:09:59 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 411  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,652] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 19 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,257] INFO 68.93.140.216 - - [20/May/2020:20:09:59 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991000000&stopTimeMs=1590005400000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 396  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,513] INFO [Log partition=EN_WIKIPEDIA_GT_1-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[32mcontrol-center                 |[0m [2020-05-20 20:09:59,563] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,653] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 20 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:01,299] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,513] INFO [Log partition=EN_WIKIPEDIA_GT_1-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,653] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 20 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:01,300] INFO 68.93.140.216 - - [20/May/2020:20:10:01 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:43,011] INFO Starting License Store (io.confluent.license.LicenseStore)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,514] INFO Created log for partition EN_WIKIPEDIA_GT_1-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,655] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 20 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:01,386] INFO 68.93.140.216 - - [20/May/2020:20:10:01 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991060000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 390  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:43,094] INFO Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,514] INFO [Partition EN_WIKIPEDIA_GT_1-0 broker=1] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:10:01,386] INFO 68.93.140.216 - - [20/May/2020:20:10:01 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991060000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 368  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,729] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:43,095] INFO AdminClientConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,514] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:10:01,387] INFO 68.93.140.216 - - [20/May/2020:20:10:01 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 239  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,729] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,514] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[32mcontrol-center                 |[0m [2020-05-20 20:10:01,389] INFO 68.93.140.216 - - [20/May/2020:20:10:01 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 212  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,729] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,514] INFO [Partition EN_WIKIPEDIA_GT_1-0 broker=1] EN_WIKIPEDIA_GT_1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	client.id = 
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,430] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,729] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,517] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 93 for partition EN_WIKIPEDIA_GT_1-0 (last update controller epoch 1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,430] INFO 68.93.140.216 - - [20/May/2020:20:10:03 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,729] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,730] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,430] INFO 68.93.140.216 - - [20/May/2020:20:10:03 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,517] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 93 from controller 2 epoch 1 for the become-leader transition for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,736] INFO Creating topic _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,475] INFO 68.93.140.216 - - [20/May/2020:20:10:03 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 202  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,517] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 93 from controller 2 epoch 1 starting the become-follower transition for partition EN_WIKIPEDIA_GT_1-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,747] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,475] INFO 68.93.140.216 - - [20/May/2020:20:10:03 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 236  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,517] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,748] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,475] INFO 68.93.140.216 - - [20/May/2020:20:10:03 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 202  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[32mcontrol-center                 |[0m [2020-05-20 20:10:03,475] INFO 68.93.140.216 - - [20/May/2020:20:10:03 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 235  2 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m [2020-05-20 20:10:04,550] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,748] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,520] INFO [Log partition=EN_WIKIPEDIA_GT_1-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,748] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:05,524] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,520] INFO [Log partition=EN_WIKIPEDIA_GT_1-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,749] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,521] INFO Created log for partition EN_WIKIPEDIA_GT_1-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[32mcontrol-center                 |[0m [2020-05-20 20:10:05,525] INFO 68.93.140.216 - - [20/May/2020:20:10:05 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,754] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,521] INFO [Partition EN_WIKIPEDIA_GT_1-1 broker=1] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1-1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:10:05,573] INFO 68.93.140.216 - - [20/May/2020:20:10:05 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 239  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,754] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,521] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-1 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:10:05,578] INFO 68.93.140.216 - - [20/May/2020:20:10:05 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 212  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	retries = 5
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,754] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,522] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1-1) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:10:05,579] INFO 68.93.140.216 - - [20/May/2020:20:10:05 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 239  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,754] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:05,583] INFO 68.93.140.216 - - [20/May/2020:20:10:05 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 202  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,522] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 93 for partition EN_WIKIPEDIA_GT_1-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,755] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:07,438] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,522] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition EN_WIKIPEDIA_GT_1-1 as part of become-follower request with correlation id 93 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,755] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,523] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(EN_WIKIPEDIA_GT_1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:10:07,440] INFO 68.93.140.216 - - [20/May/2020:20:10:07 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,755] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 21 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,523] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 93 for partition EN_WIKIPEDIA_GT_1-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,756] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 21 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:07,490] INFO 68.93.140.216 - - [20/May/2020:20:10:07 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 260  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,523] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 93 from controller 2 epoch 1 for the become-follower transition for partition EN_WIKIPEDIA_GT_1-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,756] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:10:07,490] INFO 68.93.140.216 - - [20/May/2020:20:10:07 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 202  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,759] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[32mcontrol-center                 |[0m [2020-05-20 20:10:07,490] INFO 68.93.140.216 - - [20/May/2020:20:10:07 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 236  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,525] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 94 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,759] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:10:07,491] INFO 68.93.140.216 - - [20/May/2020:20:10:07 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 212  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,173] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,760] INFO Created log for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,525] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 94 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,174] INFO 68.93.140.216 - - [20/May/2020:20:10:09 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,761] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,748] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition EN_WIKIPEDIA_GT_1-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,222] INFO 68.93.140.216 - - [20/May/2020:20:10:09 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 207  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,761] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:14,748] INFO [Log partition=EN_WIKIPEDIA_GT_1-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,222] INFO 68.93.140.216 - - [20/May/2020:20:10:09 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 239  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,761] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 95 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,224] INFO 68.93.140.216 - - [20/May/2020:20:10:09 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 239  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,761] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 broker=2] _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 95 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,226] INFO 68.93.140.216 - - [20/May/2020:20:10:09 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 239  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,764] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 21 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,630] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 95 from controller 2 epoch 1 starting the become-leader transition for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[32mcontrol-center                 |[0m [2020-05-20 20:10:09,555] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,630] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1_COUNTS-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[32mcontrol-center                 |[0m [2020-05-20 20:10:10,421] INFO 68.93.140.216 - - [20/May/2020:20:10:10 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,766] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 22 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,633] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:10,424] INFO 68.93.140.216 - - [20/May/2020:20:10:10 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,807] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 21 for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,633] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[32mcontrol-center                 |[0m [2020-05-20 20:10:10,424] INFO 68.93.140.216 - - [20/May/2020:20:10:10 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,807] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 21 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[32mcontrol-center                 |[0m [2020-05-20 20:10:10,424] INFO 68.93.140.216 - - [20/May/2020:20:10:10 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,633] INFO Created log for partition EN_WIKIPEDIA_GT_1_COUNTS-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,813] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 21 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:10:10,427] INFO 68.93.140.216 - - [20/May/2020:20:10:10 +0000] "GET /3.0/license HTTP/1.1" 200 275  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,817] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 22 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,634] INFO [Partition EN_WIKIPEDIA_GT_1_COUNTS-1 broker=1] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,007] INFO 68.93.140.216 - - [20/May/2020:20:10:11 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 45  3 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,818] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 22 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,634] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,196] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,837] INFO Creating topic _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,634] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,197] INFO 68.93.140.216 - - [20/May/2020:20:10:11 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,850] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,634] INFO [Partition EN_WIKIPEDIA_GT_1_COUNTS-1 broker=1] EN_WIKIPEDIA_GT_1_COUNTS-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,239] INFO 68.93.140.216 - - [20/May/2020:20:10:11 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 261  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,850] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,636] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 95 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,850] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,636] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 95 from controller 2 epoch 1 for the become-leader transition for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,239] INFO 68.93.140.216 - - [20/May/2020:20:10:11 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 202  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,850] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,242] INFO 68.93.140.216 - - [20/May/2020:20:10:11 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 260  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,636] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 95 from controller 2 epoch 1 starting the become-follower transition for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,850] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:11,242] INFO 68.93.140.216 - - [20/May/2020:20:10:11 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 212  1 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,636] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,855] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:13,209] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,638] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:10:13,210] INFO 68.93.140.216 - - [20/May/2020:20:10:13 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,856] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,639] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[32mcontrol-center                 |[0m [2020-05-20 20:10:13,353] INFO 68.93.140.216 - - [20/May/2020:20:10:13 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 210  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,639] INFO Created log for partition EN_WIKIPEDIA_GT_1_COUNTS-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,856] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:13,354] INFO 68.93.140.216 - - [20/May/2020:20:10:13 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] INFO [Partition EN_WIKIPEDIA_GT_1_COUNTS-0 broker=1] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,856] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:10:13,354] INFO 68.93.140.216 - - [20/May/2020:20:10:13 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 245  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,856] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,106] WARN The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:10:13,356] INFO 68.93.140.216 - - [20/May/2020:20:10:13 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 234  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1_COUNTS-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,856] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:10:14,601] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,857] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 23 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 95 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,858] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 23 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:15,534] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition EN_WIKIPEDIA_GT_1_COUNTS-0 as part of become-follower request with correlation id 95 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,858] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(EN_WIKIPEDIA_GT_1_COUNTS-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:10:15,535] INFO 68.93.140.216 - - [20/May/2020:20:10:15 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,861] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 95 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:15,579] INFO 68.93.140.216 - - [20/May/2020:20:10:15 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 268  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,861] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 95 from controller 2 epoch 1 for the become-follower transition for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with leader 2 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:15,579] INFO 68.93.140.216 - - [20/May/2020:20:10:15 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 238  3 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,642] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1_COUNTS-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 96 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:15,579] INFO 68.93.140.216 - - [20/May/2020:20:10:15 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 266  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,862] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:20,642] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1_COUNTS-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 96 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:15,584] INFO 68.93.140.216 - - [20/May/2020:20:10:15 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 210  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,862] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[32mcontrol-center                 |[0m [2020-05-20 20:10:17,439] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:05:21,066] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition EN_WIKIPEDIA_GT_1_COUNTS-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,862] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:10:17,440] INFO 68.93.140.216 - - [20/May/2020:20:10:17 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:21,066] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,107] INFO Kafka startTimeMs: 1590005144107 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:10:17,485] INFO 68.93.140.216 - - [20/May/2020:20:10:17 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 245  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,862] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-10 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,202] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Subscribed to topic(s): WIKIPEDIABOT (org.apache.kafka.clients.consumer.KafkaConsumer)
[32mcontrol-center                 |[0m [2020-05-20 20:10:17,487] INFO 68.93.140.216 - - [20/May/2020:20:10:17 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,862] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 23 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,204] INFO Starting ElasticsearchSinkTask. (io.confluent.connect.elasticsearch.ElasticsearchSinkTask)
[32mcontrol-center                 |[0m [2020-05-20 20:10:17,488] INFO 68.93.140.216 - - [20/May/2020:20:10:17 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 234  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,862] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 as part of become-follower request with correlation id 23 from controller 2 epoch 1 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:17,490] INFO 68.93.140.216 - - [20/May/2020:20:10:17 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 247  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,204] INFO ElasticsearchSinkConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,863] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[32mcontrol-center                 |[0m [2020-05-20 20:10:18,438] INFO 68.93.140.216 - - [20/May/2020:20:10:18 +0000] "GET /2.0/health/status HTTP/1.1" 200 149  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	auto.create.indices.at.start = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,863] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 23 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,397] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	batch.size = 2000
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,863] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 23 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-0 (state.change.logger)
[36;1mconnect                        |[0m 	behavior.on.malformed.documents = fail
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,398] INFO 68.93.140.216 - - [20/May/2020:20:10:19 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,908] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 23 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,439] INFO 68.93.140.216 - - [20/May/2020:20:10:19 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 266  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-4 (state.change.logger)
[36;1mconnect                        |[0m 	behavior.on.null.values = ignore
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,912] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 24 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,439] INFO 68.93.140.216 - - [20/May/2020:20:10:19 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 210  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-24 (state.change.logger)
[36;1mconnect                        |[0m 	compact.map.entries = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,912] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 23 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,450] INFO 68.93.140.216 - - [20/May/2020:20:10:19 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 268  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	connection.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,917] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 24 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,567] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,932] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 24 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	connection.timeout.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-16 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:19,783] INFO 68.93.140.216 - - [20/May/2020:20:10:19 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 238  2 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,934] INFO Creating topic _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	connection.url = [http://elasticsearch:9200]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-22 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:21,196] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[36;1mconnect                        |[0m 	connection.username = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:21,197] INFO 68.93.140.216 - - [20/May/2020:20:10:21 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[32mcontrol-center                 |[0m [2020-05-20 20:10:21,237] INFO 68.93.140.216 - - [20/May/2020:20:10:21 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 246  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-20 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:21,238] INFO 68.93.140.216 - - [20/May/2020:20:10:21 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	drop.invalid.message = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-9 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:21,240] INFO 68.93.140.216 - - [20/May/2020:20:10:21 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 247  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,947] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	elastic.https.ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-7 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:21,240] INFO 68.93.140.216 - - [20/May/2020:20:10:21 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 234  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	elastic.https.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	elastic.https.ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-13 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,947] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (kafka.controller.KafkaController)
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,150] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-11 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.key.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,947] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,150] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-1 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.keymanager.algorithm = SunX509
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,150] INFO metric=CONSUMPTION_DIFF value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,948] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-5 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.location = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,150] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,948] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-3 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.password = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,203] INFO condition=GREATER_THAN value=0 (io.confluent.controlcenter.alert.TriggerEventUtil)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,953] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-23 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,412] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,953] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-17 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:32,953] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,413] INFO 68.93.140.216 - - [20/May/2020:20:10:23 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[36;1mconnect                        |[0m 	elastic.https.ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-15 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,000] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 25 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.secure.random.implementation = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,466] INFO 68.93.140.216 - - [20/May/2020:20:10:23 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 210  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,001] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 25 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.trustmanager.algorithm = PKIX
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,468] INFO 68.93.140.216 - - [20/May/2020:20:10:23 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 267  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 97 from controller 2 epoch 1 for partition connect-offsets-19 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,002] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.location = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,469] INFO 68.93.140.216 - - [20/May/2020:20:10:23 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 268  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-5 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,002] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.password = null
[32mcontrol-center                 |[0m [2020-05-20 20:10:23,476] INFO 68.93.140.216 - - [20/May/2020:20:10:23 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-replicator HTTP/1.1" 200 238  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,003] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,007] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-15 (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:24,551] INFO [Consumer clientId=consumer-1, groupId=] Unsubscribed all topics or patterns and assigned partitions (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,008] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	elastic.security.protocol = PLAINTEXT
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,174] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-9 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,009] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	flush.timeout.ms = 10000
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,175] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-3 (state.change.logger)
[36;1mconnect                        |[0m 	key.ignore = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,009] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 25 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-19 (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,010] INFO Created log for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-13 (state.change.logger)
[36;1mconnect                        |[0m 	max.buffered.records = 20000
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,244] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/clusters/ksql HTTP/1.1" 200 91  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,014] INFO [Partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-17 (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests = 5
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,251] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /3.0/license HTTP/1.1" 200 275  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,015] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-7 (state.change.logger)
[36;1mconnect                        |[0m 	max.retries = 5
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,251] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/clusters/connect HTTP/1.1" 200 95  1 (io.confluent.rest-utils.requests)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,015] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 26 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-23 (state.change.logger)
[36;1mconnect                        |[0m 	read.timeout.ms = 3000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,015] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,256] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/metrics/lbUe4hq7QeWfnY0W4R-PhA/maxtime HTTP/1.1" 200 45  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,030] INFO [Partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,287] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=WIKIPEDIANOBOT-consumer HTTP/1.1" 200 246  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-11 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,036] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 25 for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	schema.ignore = true
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,291] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=connect-elasticsearch-ksql HTTP/1.1" 200 244  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,638] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect-offsets-7, connect-offsets-3, connect-offsets-21, connect-offsets-11, connect-offsets-17, connect-offsets-23, connect-offsets-15, connect-offsets-5, connect-offsets-13, connect-offsets-9, connect-offsets-1, connect-offsets-19) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,036] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 25 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.index.map = [WIKIPEDIABOT:wikipediabot]
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,291] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 HTTP/1.1" 200 272  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,641] INFO [Log partition=connect-offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,037] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 25 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	topic.key.ignore = []
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,293] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=wikipedia-activity-monitor HTTP/1.1" 200 247  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,641] INFO [Log partition=connect-offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,039] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 26 (state.change.logger)
[36;1mconnect                        |[0m 	topic.schema.ignore = []
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,359] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/clusters/kafka/display/CLUSTER_MANAGEMENT HTTP/1.1" 200 108  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,642] INFO Created log for partition connect-offsets-5 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,041] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 26 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	type.name = wikichange
[32mcontrol-center                 |[0m [2020-05-20 20:10:25,476] INFO 68.93.140.216 - - [20/May/2020:20:10:25 +0000] "GET /2.0/clusters/kafka HTTP/1.1" 200 148  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,642] INFO [Partition connect-offsets-5 broker=1] No checkpointed highwatermark is found for partition connect-offsets-5 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	write.method = insert
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,049] INFO Creating topic _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,642] INFO Replica loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[32mcontrol-center                 |[0m [2020-05-20 20:10:27,316] INFO Returning most recent window with monitoring data for cluster lbUe4hq7QeWfnY0W4R-PhA: 9.223372036854776E18 (io.confluent.controlcenter.rest.StatusResource)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,126] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,642] INFO Replica loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (io.confluent.connect.elasticsearch.ElasticsearchSinkConnectorConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:10:27,317] INFO 68.93.140.216 - - [20/May/2020:20:10:27 +0000] "GET /2.0/status/progress_window/monitoring/lbUe4hq7QeWfnY0W4R-PhA HTTP/1.1" 200 39  2 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,642] INFO [Partition connect-offsets-5 broker=1] connect-offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,126] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,302] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[32mcontrol-center                 |[0m [2020-05-20 20:10:27,374] INFO 68.93.140.216 - - [20/May/2020:20:10:27 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=OVERVIEW HTTP/1.1" 200 212  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,644] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-5 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,126] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,302] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:10:27,375] INFO 68.93.140.216 - - [20/May/2020:20:10:27 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1589991060000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER_LIST HTTP/1.1" 200 322  3 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,646] INFO [Log partition=connect-offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,127] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,302] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[32mcontrol-center                 |[0m [2020-05-20 20:10:27,376] INFO 68.93.140.216 - - [20/May/2020:20:10:27 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 HTTP/1.1" 200 269  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,647] INFO [Log partition=connect-offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,127] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[32mcontrol-center                 |[0m [2020-05-20 20:10:27,376] INFO 68.93.140.216 - - [20/May/2020:20:10:27 +0000] "GET /2.0/monitoring/lbUe4hq7QeWfnY0W4R-PhA/consumer_groups?startTimeMs=1590005400000&stopTimeMs=1590005460000&rollup=ONE_MINUTE&type=MEMBER&memberGroup=_confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 HTTP/1.1" 200 268  1 (io.confluent.rest-utils.requests)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,647] INFO Created log for partition connect-offsets-21 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,136] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,302] INFO Kafka startTimeMs: 1590005144302 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,647] INFO [Partition connect-offsets-21 broker=1] No checkpointed highwatermark is found for partition connect-offsets-21 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,136] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,306] INFO ElasticsearchSinkConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,647] INFO Replica loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,137] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	auto.create.indices.at.start = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,647] INFO Replica loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	batch.size = 2000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,138] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,647] INFO [Partition connect-offsets-21 broker=1] connect-offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	behavior.on.malformed.documents = fail
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,139] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,650] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-21 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	behavior.on.null.values = ignore
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,139] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,652] INFO [Log partition=connect-offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	compact.map.entries = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,652] INFO [Log partition=connect-offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,140] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 27 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	connection.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,652] INFO Created log for partition connect-offsets-15 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,141] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 27 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	connection.timeout.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,143] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,653] INFO [Partition connect-offsets-15 broker=1] No checkpointed highwatermark is found for partition connect-offsets-15 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	connection.url = [http://elasticsearch:9200]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,149] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 27 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,653] INFO Replica loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	connection.username = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,150] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,653] INFO Replica loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	drop.invalid.message = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,150] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	elastic.https.ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,653] INFO [Partition connect-offsets-15 broker=1] connect-offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,151] INFO Created log for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,655] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-15 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,152] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,657] INFO [Log partition=connect-offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	elastic.https.ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,152] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,657] INFO [Log partition=connect-offsets-9, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	elastic.https.ssl.key.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,152] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,658] INFO Created log for partition connect-offsets-9 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,152] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 28 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,658] INFO [Partition connect-offsets-9 broker=1] No checkpointed highwatermark is found for partition connect-offsets-9 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.location = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,152] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 27 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,658] INFO Replica loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.password = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,153] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 as part of become-follower request with correlation id 27 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,658] INFO Replica loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	elastic.https.ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,658] INFO [Partition connect-offsets-9 broker=1] connect-offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,153] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	elastic.https.ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,661] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-9 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,153] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 27 for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,153] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 27 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,662] INFO [Log partition=connect-offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	elastic.https.ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,663] INFO [Log partition=connect-offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,154] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 27 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,663] INFO Created log for partition connect-offsets-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,155] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 28 (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.location = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,663] INFO [Partition connect-offsets-3 broker=1] No checkpointed highwatermark is found for partition connect-offsets-3 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,156] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 28 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.password = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,664] INFO Replica loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	elastic.https.ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,200] INFO Creating topic _confluent-metrics with configuration {message.timestamp.type=CreateTime, retention.ms=259200000, min.insync.replicas=1, max.message.bytes=10485760, cleanup.policy=delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,664] INFO Replica loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	elastic.security.protocol = PLAINTEXT
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,664] INFO [Partition connect-offsets-3 broker=1] connect-offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,221] INFO [Controller id=2] New topics: [Set(_confluent-metrics)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-metrics-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	flush.timeout.ms = 10000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,666] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-3 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,221] INFO [Controller id=2] New partition creation callback for _confluent-metrics-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	key.ignore = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,702] INFO [Log partition=connect-offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,221] TRACE [Controller id=2 epoch=1] Changed partition _confluent-metrics-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 1
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,702] INFO [Log partition=connect-offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,222] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,703] INFO Created log for partition connect-offsets-19 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	max.buffered.records = 20000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,222] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-metrics-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests = 5
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,703] INFO [Partition connect-offsets-19 broker=1] No checkpointed highwatermark is found for partition connect-offsets-19 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,237] TRACE [Controller id=2 epoch=1] Changed partition _confluent-metrics-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	max.retries = 5
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,703] INFO Replica loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,237] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	read.timeout.ms = 3000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,703] INFO Replica loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,239] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,703] INFO [Partition connect-offsets-19 broker=1] connect-offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,239] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	schema.ignore = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,706] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-19 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	topic.index.map = [WIKIPEDIABOT:wikipediabot]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,243] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	topic.key.ignore = []
[36;1mconnect                        |[0m 	topic.schema.ignore = []
[36;1mconnect                        |[0m 	type.name = wikichange
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,708] INFO [Log partition=connect-offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	write.method = insert
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,244] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m  (io.confluent.connect.elasticsearch.ElasticsearchSinkConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,708] INFO [Log partition=connect-offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,309] INFO Using unsecured connection to [http://elasticsearch:9200] (io.confluent.connect.elasticsearch.jest.JestElasticsearchClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,244] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,709] INFO Created log for partition connect-offsets-13 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:44,602] INFO ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,244] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-metrics-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,709] INFO [Partition connect-offsets-13 broker=1] No checkpointed highwatermark is found for partition connect-offsets-13 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	acks = all
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,244] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,709] INFO Replica loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	batch.size = 16384
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,239] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 29 from controller 2 epoch 1 for partition _confluent-metrics-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,709] INFO Replica loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,245] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-metrics-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,709] INFO [Partition connect-offsets-13 broker=1] connect-offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,712] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-13 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,245] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 29 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-metrics-0 (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,713] INFO [Log partition=connect-offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,245] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-metrics-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,714] INFO [Log partition=connect-offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,249] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	compression.type = none
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,714] INFO Created log for partition connect-offsets-17 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,249] INFO [Log partition=_confluent-metrics-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,715] INFO [Partition connect-offsets-17 broker=1] No checkpointed highwatermark is found for partition connect-offsets-17 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,250] INFO Created log for partition _confluent-metrics-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 259200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 10485760, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,715] INFO Replica loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,251] INFO [Partition _confluent-metrics-0 broker=2] No checkpointed highwatermark is found for partition _confluent-metrics-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,715] INFO Replica loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,251] INFO Replica loaded for partition _confluent-metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,715] INFO [Partition connect-offsets-17 broker=1] connect-offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,251] INFO Replica loaded for partition _confluent-metrics-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,717] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-17 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 0
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,720] INFO [Log partition=connect-offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,252] INFO [Partition _confluent-metrics-0 broker=2] _confluent-metrics-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	max.block.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,720] INFO [Log partition=connect-offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,253] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-metrics,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 29 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,721] INFO Created log for partition connect-offsets-7 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,255] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 29 for partition _confluent-metrics-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	max.request.size = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,721] INFO [Partition connect-offsets-7 broker=1] No checkpointed highwatermark is found for partition connect-offsets-7 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,255] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 29 from controller 2 epoch 1 for the become-leader transition for partition _confluent-metrics-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,721] INFO Replica loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,256] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-metrics,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 29 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,721] INFO Replica loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metric.reporters = []
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,721] INFO [Partition connect-offsets-7 broker=1] connect-offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,257] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 30 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,257] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-metrics-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 30 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,724] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-7 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,726] INFO [Log partition=connect-offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,317] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 30 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,727] INFO [Log partition=connect-offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,331] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,727] INFO Created log for partition connect-offsets-23 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,341] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,727] INFO [Partition connect-offsets-23 broker=1] No checkpointed highwatermark is found for partition connect-offsets-23 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,341] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,727] INFO Replica loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	retries = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,341] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,727] INFO Replica loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,342] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,728] INFO [Partition connect-offsets-23 broker=1] connect-offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,342] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,730] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-23 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,346] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,732] INFO [Log partition=connect-offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,346] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,732] INFO [Log partition=connect-offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,347] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,732] INFO Created log for partition connect-offsets-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,347] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,733] INFO [Partition connect-offsets-1 broker=1] No checkpointed highwatermark is found for partition connect-offsets-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,347] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,733] INFO Replica loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,347] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,348] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 31 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,733] INFO Replica loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,349] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 31 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,733] INFO [Partition connect-offsets-1 broker=1] connect-offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,349] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,735] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,796] INFO [Log partition=connect-offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,796] INFO [Log partition=connect-offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,353] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,797] INFO Created log for partition connect-offsets-11 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,353] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,797] INFO [Partition connect-offsets-11 broker=1] No checkpointed highwatermark is found for partition connect-offsets-11 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,353] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,797] INFO Replica loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,353] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,797] INFO Replica loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,353] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,797] INFO [Partition connect-offsets-11 broker=1] connect-offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,355] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 31 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,357] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 31 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-11 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-5 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,357] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 31 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,357] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 31 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,358] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 32 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-15 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,359] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 32 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-9 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,399] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 32 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-3 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,424] INFO Creating topic _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-19 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,439] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-13 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,440] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-17 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,440] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,799] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-7 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-23 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,440] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,440] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-11 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,445] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-8 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,445] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-24 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,445] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-2 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,445] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-18 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,446] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-12 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,446] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-6 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,446] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 33 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-22 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	transactional.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,447] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 33 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-16 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,447] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,450] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,406] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-10 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,450] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,406] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-4 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,451] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,406] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-14 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 97 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-20 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,451] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,406] INFO Kafka startTimeMs: 1590005145406 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,800] INFO Replica loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,407] INFO ConsumerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,451] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,802] INFO [Log partition=connect-offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	allow.auto.create.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,802] INFO [Log partition=connect-offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,451] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	auto.commit.interval.ms = 5000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,803] INFO Created log for partition connect-offsets-8 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	auto.offset.reset = earliest
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,451] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 33 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,803] INFO [Partition connect-offsets-8 broker=1] No checkpointed highwatermark is found for partition connect-offsets-8 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,452] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 as part of become-follower request with correlation id 33 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	check.crcs = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,803] INFO Replica loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,452] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,803] INFO Replica loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,452] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 33 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,806] INFO [Log partition=connect-offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	client.rack = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,452] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 33 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,806] INFO [Log partition=connect-offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,453] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 33 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,807] INFO Created log for partition connect-offsets-24 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,454] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 34 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,807] INFO [Partition connect-offsets-24 broker=1] No checkpointed highwatermark is found for partition connect-offsets-24 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	default.api.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,455] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 33 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,807] INFO Replica loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	enable.auto.commit = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,457] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 34 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	exclude.internal.topics = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,807] INFO Replica loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,509] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 34 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	fetch.max.bytes = 52428800
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,809] INFO [Log partition=connect-offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,525] INFO Creating topic _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,809] INFO [Log partition=connect-offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,537] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	group.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,810] INFO Created log for partition connect-offsets-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,537] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	group.instance.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,810] INFO [Partition connect-offsets-2 broker=1] No checkpointed highwatermark is found for partition connect-offsets-2 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect                        |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,537] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,810] INFO Replica loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	internal.leave.group.on.close = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,810] INFO Replica loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,538] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	isolation.level = read_uncommitted
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,813] INFO [Log partition=connect-offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
[36;1mconnect                        |[0m 	max.partition.fetch.bytes = 1048576
[36;1mconnect                        |[0m 	max.poll.interval.ms = 300000
[36;1mconnect                        |[0m 	max.poll.records = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,538] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,814] INFO [Log partition=connect-offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,545] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,814] INFO Created log for partition connect-offsets-18 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,545] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,814] INFO [Partition connect-offsets-18 broker=1] No checkpointed highwatermark is found for partition connect-offsets-18 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,545] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,814] INFO Replica loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,545] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,814] INFO Replica loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,546] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,816] INFO [Log partition=connect-offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,546] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,546] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 35 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,816] INFO [Log partition=connect-offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,547] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 35 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,817] INFO Created log for partition connect-offsets-12 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,818] INFO [Partition connect-offsets-12 broker=1] No checkpointed highwatermark is found for partition connect-offsets-12 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,547] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,818] INFO Replica loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,551] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,818] INFO Replica loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,551] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,819] INFO [Log partition=connect-offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,552] INFO Created log for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,820] INFO [Log partition=connect-offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,552] INFO [Partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,552] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,820] INFO Created log for partition connect-offsets-6 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,821] INFO [Partition connect-offsets-6 broker=1] No checkpointed highwatermark is found for partition connect-offsets-6 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,552] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,821] INFO Replica loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,552] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 35 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,821] INFO Replica loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,552] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 as part of become-follower request with correlation id 35 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,822] INFO [Log partition=connect-offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,553] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,823] INFO [Log partition=connect-offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,553] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 35 for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,823] INFO Created log for partition connect-offsets-22 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,553] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 35 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,553] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 35 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,824] INFO [Partition connect-offsets-22 broker=1] No checkpointed highwatermark is found for partition connect-offsets-22 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,555] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 36 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,824] INFO Replica loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,556] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 35 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,824] INFO Replica loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,896] INFO [Log partition=connect-offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,897] INFO [Log partition=connect-offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,556] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 36 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,897] INFO Created log for partition connect-offsets-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,558] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 36 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,897] INFO [Partition connect-offsets-0 broker=1] No checkpointed highwatermark is found for partition connect-offsets-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,560] INFO Creating topic _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,898] INFO Replica loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,898] INFO Replica loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,616] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,901] INFO [Log partition=connect-offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,616] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,901] INFO [Log partition=connect-offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,616] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,902] INFO Created log for partition connect-offsets-16 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,617] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,623] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,902] INFO [Partition connect-offsets-16 broker=1] No checkpointed highwatermark is found for partition connect-offsets-16 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,639] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,902] INFO Replica loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,640] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,902] INFO Replica loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,640] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,904] INFO [Log partition=connect-offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,905] INFO [Log partition=connect-offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,905] INFO Created log for partition connect-offsets-10 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,906] INFO [Partition connect-offsets-10 broker=1] No checkpointed highwatermark is found for partition connect-offsets-10 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,641] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,906] INFO Replica loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,906] INFO Replica loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,641] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,908] INFO [Log partition=connect-offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,641] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,908] INFO [Log partition=connect-offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,643] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 37 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,909] INFO Created log for partition connect-offsets-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,644] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 37 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,909] INFO [Partition connect-offsets-4 broker=1] No checkpointed highwatermark is found for partition connect-offsets-4 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,644] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,909] INFO Replica loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,649] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 37 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,652] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 38 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,909] INFO Replica loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,652] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,911] INFO [Log partition=connect-offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,652] INFO [Log partition=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,912] INFO [Log partition=connect-offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,653] INFO Created log for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,912] INFO Created log for partition connect-offsets-14 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,506] INFO [Producer clientId=producer-4] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,913] INFO [Partition connect-offsets-14 broker=1] No checkpointed highwatermark is found for partition connect-offsets-14 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,653] INFO [Partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,815] INFO Setting server pool to a list of 1 servers: [http://elasticsearch:9200] (io.searchbox.client.AbstractJestClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,913] INFO Replica loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,653] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:45,816] INFO Using multi thread/connection supporting pooling connection manager (io.searchbox.client.JestClientFactory)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,913] INFO Replica loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,653] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,103] INFO Using default GSON instance (io.searchbox.client.JestClientFactory)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,915] INFO [Log partition=connect-offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,103] INFO Node Discovery disabled... (io.searchbox.client.JestClientFactory)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,915] INFO [Log partition=connect-offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,654] INFO [Partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,103] INFO Idle connection reaping disabled... (io.searchbox.client.JestClientFactory)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,916] INFO Created log for partition connect-offsets-20 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,656] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 37 for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,312] WARN The configuration 'replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,916] INFO [Partition connect-offsets-20 broker=1] No checkpointed highwatermark is found for partition connect-offsets-20 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,656] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 37 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,312] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,916] INFO Replica loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,658] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 37 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,312] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect-offsets-18, connect-offsets-16, connect-offsets-0, connect-offsets-22, connect-offsets-20, connect-offsets-4, connect-offsets-2, connect-offsets-24, connect-offsets-8, connect-offsets-6, connect-offsets-14, connect-offsets-12, connect-offsets-10) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,659] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 38 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,312] INFO Kafka startTimeMs: 1590005146312 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,695] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 38 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-20 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,405] INFO [Consumer clientId=consumer-4, groupId=null] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,708] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,412] INFO JsonConverterConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-4 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,727] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	converter.type = value
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-10 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	schemas.cache.size = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,727] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-16 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	schemas.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-0 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,727] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.json.JsonConverterConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-22 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,728] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,494] INFO WorkerSinkTask{id=elasticsearch-ksql-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-6 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,728] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,500] INFO [Consumer clientId=consumer-4, groupId=null] Subscribed to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-12 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,733] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-18 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,500] INFO [Consumer clientId=consumer-4, groupId=null] Seeking to EARLIEST offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,733] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-2 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-24 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,734] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,512] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-8 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,512] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,735] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-14 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,514] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,735] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-20 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,514] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-4 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,735] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,604] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-10 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,740] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 39 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-16 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,613] INFO [Consumer clientId=consumer-4, groupId=null] Resetting offset for partition _confluent-command-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,741] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 39 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-0 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,719] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,741] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-22 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,719] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,746] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:46,719] INFO Started License Store (io.confluent.license.LicenseStore)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-6 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,746] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-12 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,502] INFO Trial license for Confluent Enterprise expires in 29 days on 2020-06-19. (io.confluent.license.LicenseManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,747] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-18 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,749] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-2 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,504] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,749] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-24 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-8 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,749] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,749] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 39 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,917] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-14 as part of become-follower request with correlation id 97 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(connect-offsets-20 -> (offset=0, leaderEpoch=0), connect-offsets-24 -> (offset=0, leaderEpoch=0), connect-offsets-16 -> (offset=0, leaderEpoch=0), connect-offsets-6 -> (offset=0, leaderEpoch=0), connect-offsets-10 -> (offset=0, leaderEpoch=0), connect-offsets-2 -> (offset=0, leaderEpoch=0), connect-offsets-18 -> (offset=0, leaderEpoch=0), connect-offsets-4 -> (offset=0, leaderEpoch=0), connect-offsets-12 -> (offset=0, leaderEpoch=0), connect-offsets-14 -> (offset=0, leaderEpoch=0), connect-offsets-0 -> (offset=0, leaderEpoch=0), connect-offsets-8 -> (offset=0, leaderEpoch=0), connect-offsets-22 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,750] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-20 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-4 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,753] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 39 for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-10 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,753] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 39 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-16 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,754] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 39 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,754] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 40 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-22 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,755] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 40 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-6 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,757] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 40 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-12 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-18 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,758] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-2 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,758] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-24 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,758] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-8 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,758] INFO [Log partition=_confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,762] INFO Creating topic _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 97 for partition connect-offsets-14 with leader 2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-8 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,819] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	retries = 5
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,819] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-24 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,819] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-2 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,821] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-18 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,821] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-12 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,832] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-6 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,832] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-22 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,832] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,833] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 41 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-0 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,834] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 41 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-16 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,834] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-10 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,840] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-4 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,842] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-14 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,842] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,918] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 97 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-20 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,845] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,845] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,847] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 41 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,848] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,849] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,849] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,849] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,849] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,852] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 41 for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,852] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 41 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,853] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 41 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,854] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 42 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,855] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 42 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,856] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 42 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,859] INFO Creating topic _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,911] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,911] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,911] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,912] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,912] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,927] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.bootstrap.servers' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,928] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,929] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 98 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,929] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,084] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-18 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,930] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,084] INFO [Log partition=connect-offsets-18, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,930] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 43 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-16 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,937] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 43 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,937] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-16, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,937] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 43 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,845] INFO Kafka startTimeMs: 1590005147845 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,937] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,895] INFO Finished creating connector replicate-topic (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-22 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,940] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 44 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,895] INFO SourceConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-22, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,943] INFO [Log partition=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-20 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,944] INFO [Log partition=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-20, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,944] INFO Created log for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	errors.log.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,945] INFO [Partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,945] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-4, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,945] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-24 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,945] INFO [Partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 broker=2] _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,949] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 43 for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-24, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,949] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 43 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,950] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 43 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[36;1mconnect                        |[0m 	name = replicate-topic
[36;1mconnect                        |[0m 	tasks.max = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,951] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 44 (state.change.logger)
[36;1mconnect                        |[0m 	transforms = []
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-2, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,954] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 44 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:33,957] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-8, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,018] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,895] INFO EnrichedConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,018] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-6, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,019] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-14 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,019] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-14, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,019] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-12 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,026] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-12, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,026] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-offsets-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:05:25,085] INFO [Log partition=connect-offsets-10, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,027] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 99 from controller 2 epoch 1 for partition connect-statuses-0 (state.change.logger)
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 99 from controller 2 epoch 1 for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,028] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 45 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 99 from controller 2 epoch 1 for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,029] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 99 from controller 2 epoch 1 for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,029] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 45 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 99 from controller 2 epoch 1 for partition connect-statuses-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,029] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	name = replicate-topic
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,442] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 99 from controller 2 epoch 1 starting the become-leader transition for partition connect-statuses-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,029] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	tasks.max = 1
[36;1mconnect                        |[0m 	transforms = []
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,033] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,442] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 99 from controller 2 epoch 1 starting the become-leader transition for partition connect-statuses-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,033] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:47,997] INFO ReplicatorSourceTaskConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,442] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 99 from controller 2 epoch 1 starting the become-leader transition for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,034] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	confluent.license = 
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,442] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect-statuses-2, connect-statuses-0, connect-statuses-4) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,034] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	confluent.topic = _confluent-command
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,445] INFO [Log partition=connect-statuses-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,034] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	dest.kafka.bootstrap.servers = [kafka1:9091]
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,445] INFO [Log partition=connect-statuses-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,035] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	dest.kafka.client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,446] INFO Created log for partition connect-statuses-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,035] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 45 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,446] INFO [Partition connect-statuses-2 broker=1] No checkpointed highwatermark is found for partition connect-statuses-2 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,035] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 as part of become-follower request with correlation id 45 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,446] INFO Replica loaded for partition connect-statuses-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,035] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	dest.kafka.metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,446] INFO Replica loaded for partition connect-statuses-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,035] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 45 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,035] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 45 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,446] INFO [Partition connect-statuses-2 broker=1] connect-statuses-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,450] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-2 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,036] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 45 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,452] INFO [Log partition=connect-statuses-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,452] INFO [Log partition=connect-statuses-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,039] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 46 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,452] INFO Created log for partition connect-statuses-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	dest.kafka.retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,042] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 45 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,453] INFO [Partition connect-statuses-0 broker=1] No checkpointed highwatermark is found for partition connect-statuses-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	dest.kafka.send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,044] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 46 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	dest.zookeeper.connect = 
[36;1mconnect                        |[0m 	dest.zookeeper.connection.timeout.ms = 6000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,453] INFO Replica loaded for partition connect-statuses-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,046] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	dest.zookeeper.session.timeout.ms = 6000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,453] INFO Replica loaded for partition connect-statuses-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,047] INFO Creating topic _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,453] INFO [Partition connect-statuses-0 broker=1] connect-statuses-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,455] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	offset.start = connect
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,047] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 46 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	offset.timestamps.commit = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,457] INFO [Log partition=connect-statuses-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,051] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,457] INFO [Log partition=connect-statuses-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	offset.topic.commit = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,051] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,457] INFO Created log for partition connect-statuses-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,107] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	offset.translator.batch.period.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,458] INFO [Partition connect-statuses-4 broker=1] No checkpointed highwatermark is found for partition connect-statuses-4 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,107] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	offset.translator.batch.size = 1
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,458] INFO Replica loaded for partition connect-statuses-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,107] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.tasks.max = -1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,108] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.tasks.separate = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,458] INFO Replica loaded for partition connect-statuses-4 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	partition.assignment = AAAAAAABABB3aWtpcGVkaWEucGFyc2VkAAAAAgAAAAAAAAABAAAAAA==
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,108] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,458] INFO [Partition connect-statuses-4 broker=1] connect-statuses-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	provenance.header.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,116] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-4 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	provenance.header.filter.overrides = 
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 99 from controller 2 epoch 1 for the become-leader transition for partition connect-statuses-2 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.credentials.source = URL
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,116] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 99 from controller 2 epoch 1 for the become-leader transition for partition connect-statuses-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,117] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 47 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 99 from controller 2 epoch 1 for the become-leader transition for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,118] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 47 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.max.schemas.per.subject = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 99 from controller 2 epoch 1 starting the become-follower transition for partition connect-statuses-3 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.topic = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,118] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 99 from controller 2 epoch 1 starting the become-follower transition for partition connect-statuses-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.url = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,460] INFO Replica loaded for partition connect-statuses-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,121] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	schema.subject.translator.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,462] INFO [Log partition=connect-statuses-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,121] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,462] INFO [Log partition=connect-statuses-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,121] INFO Created log for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	src.consumer.check.crcs = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,463] INFO Created log for partition connect-statuses-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,122] INFO [Partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.bytes = 52428800
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,463] INFO [Partition connect-statuses-3 broker=1] No checkpointed highwatermark is found for partition connect-statuses-3 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,122] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.wait.ms = 500
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,463] INFO Replica loaded for partition connect-statuses-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,122] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.consumer.fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,122] INFO [Partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 broker=2] _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,463] INFO Replica loaded for partition connect-statuses-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.consumer.interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,465] INFO [Log partition=connect-statuses-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,123] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.max.partition.fetch.bytes = 1048576
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,465] INFO [Log partition=connect-statuses-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,125] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,465] INFO Created log for partition connect-statuses-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	src.consumer.max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,125] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] INFO [Partition connect-statuses-1 broker=1] No checkpointed highwatermark is found for partition connect-statuses-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.consumer.max.poll.records = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,125] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] INFO Replica loaded for partition connect-statuses-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,126] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 47 for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect-statuses-3, connect-statuses-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,126] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 47 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,127] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 47 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-3 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,146] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 48 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-statuses-1 as part of become-follower request with correlation id 99 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,155] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 48 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition connect-statuses-3 as part of become-follower request with correlation id 99 from controller 2 epoch 1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,206] INFO Creating topic _confluent-command with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=259200000, min.insync.replicas=1, cleanup.policy=compact, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,466] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(connect-statuses-3 -> (offset=0, leaderEpoch=0), connect-statuses-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,467] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,218] INFO [Controller id=2] New topics: [Set(_confluent-command)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-command-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	src.kafka.receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,467] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 99 for partition connect-statuses-3 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,218] INFO [Controller id=2] New partition creation callback for _confluent-command-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	src.kafka.reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,467] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 99 from controller 2 epoch 1 for the become-follower transition for partition connect-statuses-3 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,219] TRACE [Controller id=2 epoch=1] Changed partition _confluent-command-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,467] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 99 from controller 2 epoch 1 for the become-follower transition for partition connect-statuses-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.request.timeout.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,496] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-statuses-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 100 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,219] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-command-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,219] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-command-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,222] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-group-stream-extension-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 47 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,496] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-statuses-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 100 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,227] TRACE [Controller id=2 epoch=1] Changed partition _confluent-command-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,227] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-command-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,496] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-statuses-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 100 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,229] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 49 from controller 2 epoch 1 for partition _confluent-command-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,496] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-statuses-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 100 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,230] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 49 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-command-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,496] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-statuses-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 100 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,230] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,751] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-statuses-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,232] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,751] INFO [Log partition=connect-statuses-3, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,233] INFO [Log partition=_confluent-command-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,751] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition connect-statuses-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,234] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 259200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:28,751] INFO [Log partition=connect-statuses-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,234] INFO [Partition _confluent-command-0 broker=2] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,230] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 101 from controller 2 epoch 1 for partition connect-configs-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,234] INFO Replica loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,234] INFO Replica loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,230] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 101 from controller 2 epoch 1 starting the become-leader transition for partition connect-configs-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,231] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(connect-configs-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.class = null
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,233] INFO [Log partition=connect-configs-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,235] INFO [Partition _confluent-command-0 broker=2] _confluent-command-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,234] INFO [Log partition=connect-configs-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,236] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-command-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,234] INFO Created log for partition connect-configs-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,237] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-command-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,235] INFO [Partition connect-configs-0 broker=1] No checkpointed highwatermark is found for partition connect-configs-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,237] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 49 for partition _confluent-command-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,235] INFO Replica loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,238] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 49 from controller 2 epoch 1 for the become-leader transition for partition _confluent-command-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,235] INFO Replica loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,235] INFO [Partition connect-configs-0 broker=1] connect-configs-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,239] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-command,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 49 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,240] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-command-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 50 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,237] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 101 for partition connect-configs-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,243] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 50 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,238] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 101 from controller 2 epoch 1 for the become-leader transition for partition connect-configs-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,244] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-command-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.key.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:05:30,239] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-configs-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 102 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,244] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-command-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.keymanager.algorithm = SunX509
[31;1mkafka1                         |[0m [2020-05-20 20:05:32,297] INFO [GroupCoordinator 1]: Preparing to rebalance group connect in state PreparingRebalance with old generation 0 (__consumer_offsets-30) (reason: Adding new member connect-1-534a2a13-2f66-4763-9455-ccc532644fa6 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,249] INFO Creating topic _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition with configuration {message.timestamp.type=CreateTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:05:35,298] INFO [GroupCoordinator 1]: Stabilized group connect generation 1 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,298] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 48 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:35,320] INFO [GroupCoordinator 1]: Assignment received from leader for group connect for generation 1 (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:05:37,298] INFO [GroupCoordinator 1]: Preparing to rebalance group connect in state PreparingRebalance with old generation 1 (__consumer_offsets-30) (reason: Updating metadata for member connect-1-534a2a13-2f66-4763-9455-ccc532644fa6) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,305] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,305] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:05:37,298] INFO [GroupCoordinator 1]: Stabilized group connect generation 2 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,306] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:37,303] INFO [GroupCoordinator 1]: Assignment received from leader for group connect for generation 2 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.kafka.ssl.protocol = TLS
[31;1mkafka1                         |[0m [2020-05-20 20:05:38,814] INFO [GroupCoordinator 1]: Preparing to rebalance group connect in state PreparingRebalance with old generation 2 (__consumer_offsets-30) (reason: Updating metadata for member connect-1-534a2a13-2f66-4763-9455-ccc532644fa6) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,306] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.provider = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:38,814] INFO [GroupCoordinator 1]: Stabilized group connect generation 3 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,306] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.secure.random.implementation = null
[31;1mkafka1                         |[0m [2020-05-20 20:05:38,816] INFO [GroupCoordinator 1]: Assignment received from leader for group connect for generation 3 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,329] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.trustmanager.algorithm = PKIX
[31;1mkafka1                         |[0m [2020-05-20 20:05:40,903] INFO [GroupCoordinator 1]: Preparing to rebalance group connect in state PreparingRebalance with old generation 3 (__consumer_offsets-30) (reason: Updating metadata for member connect-1-534a2a13-2f66-4763-9455-ccc532644fa6) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,329] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:40,903] INFO [GroupCoordinator 1]: Stabilized group connect generation 4 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,330] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 51 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:40,906] INFO [GroupCoordinator 1]: Assignment received from leader for group connect for generation 4 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:05:42,939] INFO [GroupCoordinator 1]: Preparing to rebalance group connect in state PreparingRebalance with old generation 4 (__consumer_offsets-30) (reason: Updating metadata for member connect-1-534a2a13-2f66-4763-9455-ccc532644fa6) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,331] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 51 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[31;1mkafka1                         |[0m [2020-05-20 20:05:42,940] INFO [GroupCoordinator 1]: Stabilized group connect generation 5 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,331] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,332] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:42,942] INFO [GroupCoordinator 1]: Assignment received from leader for group connect for generation 5 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.zookeeper.connect = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,334] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:46,604] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-elasticsearch-ksql in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member connector-consumer-elasticsearch-ksql-0-0f4a1ca5-a846-4b04-9f69-3c67206de697 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.zookeeper.connection.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,334] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:49,027] INFO [GroupCoordinator 1]: Preparing to rebalance group connect in state PreparingRebalance with old generation 5 (__consumer_offsets-30) (reason: Updating metadata for member connect-1-534a2a13-2f66-4763-9455-ccc532644fa6) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	src.zookeeper.session.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,335] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:49,027] INFO [GroupCoordinator 1]: Stabilized group connect generation 6 (__consumer_offsets-30) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	task.id = replicate-topic-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,335] INFO [Partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:49,028] INFO [GroupCoordinator 1]: Assignment received from leader for group connect for generation 6 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	topic.auto.create = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,335] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:49,605] INFO [GroupCoordinator 1]: Stabilized group connect-elasticsearch-ksql generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,335] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	topic.blacklist = []
[31;1mkafka1                         |[0m [2020-05-20 20:05:49,607] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-elasticsearch-ksql for generation 1 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	topic.config.sync = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,958] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 103 from controller 2 epoch 1 for partition wikipedia.parsed.replica-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,335] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 51 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	topic.config.sync.interval.ms = 120000
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,958] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 103 from controller 2 epoch 1 for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,335] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 as part of become-follower request with correlation id 51 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,336] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,959] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 103 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.parsed.replica-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.create.backoff.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,336] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 51 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,959] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.parsed.replica-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	topic.poll.interval.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,336] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 51 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,962] INFO [Log partition=wikipedia.parsed.replica-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,337] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 51 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	topic.preserve.partitions = true
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,962] INFO [Log partition=wikipedia.parsed.replica-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,342] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.regex = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,342] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,963] INFO Created log for partition wikipedia.parsed.replica-0 in /var/lib/kafka/data with properties {compression.type -> producer, leader.replication.throttled.replicas -> , message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, follower.replication.throttled.replicas -> , segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	topic.rename.format = ${topic}.replica
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,342] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,344] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 52 (state.change.logger)
[36;1mconnect                        |[0m 	topic.timestamp.type = CreateTime
[36;1mconnect                        |[0m 	topic.whitelist = [wikipedia.parsed]
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,963] INFO [Partition wikipedia.parsed.replica-0 broker=1] No checkpointed highwatermark is found for partition wikipedia.parsed.replica-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,346] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 52 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m  (io.confluent.connect.replicator.ReplicatorSourceTaskConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,963] INFO Replica loaded for partition wikipedia.parsed.replica-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,408] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:48,524] INFO [Worker clientId=connect-1, groupId=connect] Tasks [replicate-topic-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,963] INFO Replica loaded for partition wikipedia.parsed.replica-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,414] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,025] INFO [Worker clientId=connect-1, groupId=connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,963] INFO [Partition wikipedia.parsed.replica-0 broker=1] wikipedia.parsed.replica-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,414] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,026] INFO [Worker clientId=connect-1, groupId=connect] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,967] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 103 for partition wikipedia.parsed.replica-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,414] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,026] INFO [Worker clientId=connect-1, groupId=connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,967] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 103 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.parsed.replica-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,414] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,967] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 103 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.parsed.replica-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,026] INFO [Worker clientId=connect-1, groupId=connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,414] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,032] INFO [Worker clientId=connect-1, groupId=connect] Successfully joined group with generation 6 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,424] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-command,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 49 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,968] INFO Replica loaded for partition wikipedia.parsed.replica-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,032] INFO [Worker clientId=connect-1, groupId=connect] Joined group at generation 6 and got assignment: Assignment{error=0, leader='connect-1-534a2a13-2f66-4763-9455-ccc532644fa6', leaderUrl='https://connect:8083/', offset=9, connectorIds=[replicate-topic, elasticsearch-ksql, wikipedia-irc], taskIds=[replicate-topic-0, elasticsearch-ksql-0, wikipedia-irc-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,426] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,969] INFO [Log partition=wikipedia.parsed.replica-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,032] INFO [Worker clientId=connect-1, groupId=connect] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,426] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,970] INFO [Log partition=wikipedia.parsed.replica-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,428] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 53 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,032] INFO [Worker clientId=connect-1, groupId=connect] Starting task replicate-topic-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,970] INFO Created log for partition wikipedia.parsed.replica-1 in /var/lib/kafka/data with properties {compression.type -> producer, leader.replication.throttled.replicas -> , message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, follower.replication.throttled.replicas -> , segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,033] INFO Creating task replicate-topic-0 (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,429] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 53 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,033] INFO ConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] INFO [Partition wikipedia.parsed.replica-1 broker=1] No checkpointed highwatermark is found for partition wikipedia.parsed.replica-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,429] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 50 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] INFO Replica loaded for partition wikipedia.parsed.replica-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,429] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(wikipedia.parsed.replica-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,429] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] TRACE [Broker id=1] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 103 for partition wikipedia.parsed.replica-1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,430] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] TRACE [Broker id=1] Truncated logs and checkpointed recovery boundaries for partition wikipedia.parsed.replica-1 as part of become-follower request with correlation id 103 from controller 2 epoch 1 with leader 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,430] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=kafka2:9092) for partitions Map(wikipedia.parsed.replica-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,430] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] TRACE [Broker id=1] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 103 for partition wikipedia.parsed.replica-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,436] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,971] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 103 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.parsed.replica-1 with leader 2 (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,436] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	errors.tolerance = none
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,972] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.parsed.replica-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 104 (state.change.logger)
[36;1mconnect                        |[0m 	header.converter = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,437] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:05:52,972] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.parsed.replica-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 104 (state.change.logger)
[36;1mconnect                        |[0m 	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,438] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:05:53,082] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition wikipedia.parsed.replica-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	name = replicate-topic
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,438] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:05:53,082] INFO [Log partition=wikipedia.parsed.replica-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	tasks.max = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,438] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:06:12,903] INFO [GroupCoordinator 1]: Preparing to rebalance group _confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 in state PreparingRebalance with old generation 0 (__consumer_offsets-36) (reason: Adding new member _confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0-4a593bfd-0a70-47a3-b616-bf743bb85a57-StreamThread-4-consumer-60f49a1e-e1f9-4ddb-ae09-1720b460e781 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,438] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:06:18,905] INFO [GroupCoordinator 1]: Stabilized group _confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 generation 1 (__consumer_offsets-36) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	transforms = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,445] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 53 for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (last update controller epoch 1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:19,004] INFO [GroupCoordinator 1]: Assignment received from leader for group _confluent-ksql-default_query_CSAS_WIKIPEDIANOBOT_0 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,445] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 53 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,033] INFO EnrichedConnectorConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:06:19,928] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 19 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,447] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 53 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	config.action.reload = restart
[31;1mkafka1                         |[0m [2020-05-20 20:06:19,935] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 49 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,449] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 54 (state.change.logger)
[36;1mconnect                        |[0m 	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
[31;1mkafka1                         |[0m [2020-05-20 20:06:20,005] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 70 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,449] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 51 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.enable = false
[31;1mkafka1                         |[0m [2020-05-20 20:06:20,008] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 63 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,452] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 54 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	errors.log.include.messages = false
[31;1mkafka1                         |[0m [2020-05-20 20:06:20,011] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 70 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,506] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 52 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	errors.retry.delay.max.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:06:20,023] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 19 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,509] INFO Creating topic _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	errors.retry.timeout = 0
[31;1mkafka1                         |[0m [2020-05-20 20:06:26,001] INFO [GroupCoordinator 1]: Preparing to rebalance group _confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member _confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1-57fa9643-68ac-436f-a26a-a3c7dc59711b-StreamThread-1-consumer-71388b6a-e6d6-4730-a351-81dad41aed18 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	errors.tolerance = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,516] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:06:32,001] INFO [GroupCoordinator 1]: Stabilized group _confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 generation 1 (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:06:32,006] INFO [GroupCoordinator 1]: Assignment received from leader for group _confluent-ksql-default_query_CSAS_WIKIPEDIABOT_1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,516] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	header.converter = null
[31;1mkafka1                         |[0m [2020-05-20 20:06:41,020] INFO [GroupCoordinator 1]: Preparing to rebalance group WIKIPEDIANOBOT-consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-1-0395170c-e457-4714-a7c6-7536fb9a62c2 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka1                         |[0m [2020-05-20 20:06:44,021] INFO [GroupCoordinator 1]: Stabilized group WIKIPEDIANOBOT-consumer generation 1 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,516] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	name = replicate-topic
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,516] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:44,026] INFO [GroupCoordinator 1]: Assignment received from leader for group WIKIPEDIANOBOT-consumer for generation 1 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,516] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	tasks.max = 1
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,152] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 105 from controller 2 epoch 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,537] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	transforms = []
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,153] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 105 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,537] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,153] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,537] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,156] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,537] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,035] INFO TaskConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,156] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,538] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	task.class = class io.confluent.connect.replicator.ReplicatorSourceTask
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,538] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,156] INFO Created log for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m  (org.apache.kafka.connect.runtime.TaskConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,538] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 55 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,157] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 broker=1] No checkpointed highwatermark is found for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,038] INFO Instantiated task replicate-topic-0 with version 5.3.1 of type io.confluent.connect.replicator.ReplicatorSourceTask (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,157] INFO Replica loaded for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,539] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 55 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,038] INFO Set up the key converter class io.confluent.connect.replicator.util.ByteArrayConverter for task replicate-topic-0 using the connector config (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,540] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,157] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 broker=1] _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,038] INFO Set up the value converter class io.confluent.connect.replicator.util.ByteArrayConverter for task replicate-topic-0 using the connector config (org.apache.kafka.connect.runtime.Worker)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,545] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,159] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 105 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,038] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task replicate-topic-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,159] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 105 from controller 2 epoch 1 for the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,160] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 106 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,038] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,160] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 106 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,219] TRACE [Broker id=1] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) correlation id 107 from controller 2 epoch 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,039] INFO ProducerConfig values: 
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,219] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 107 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	acks = all
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,219] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,546] INFO [Log partition=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	batch.size = 16384
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,221] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,546] INFO Created log for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,547] INFO [Partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,222] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,548] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,222] INFO Created log for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	client.id = connect-worker-producer
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,548] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,223] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 broker=1] No checkpointed highwatermark is found for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	compression.type = none
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,223] INFO Replica loaded for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,550] INFO [Partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,223] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 broker=1] _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,553] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 55 for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,553] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 55 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,226] TRACE [Broker id=1] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 107 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,554] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 53 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,226] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 107 from controller 2 epoch 1 for the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,554] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 55 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,227] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 108 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,555] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 56 (state.change.logger)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[31;1mkafka1                         |[0m [2020-05-20 20:06:47,227] TRACE [Broker id=1] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 108 (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 0
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,556] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 56 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:50,500] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 65 (kafka.log.Log)
[36;1mconnect                        |[0m 	max.block.ms = 9223372036854775807
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,560] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=60566400000, retention.ms=60566400000, min.insync.replicas=1, cleanup.policy=compact,delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:06:50,504] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 179 (kafka.log.Log)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,567] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:06:50,599] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 224 (kafka.log.Log)
[36;1mconnect                        |[0m 	max.request.size = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,567] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:06:50,602] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 224 (kafka.log.Log)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,567] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:50,605] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 193 (kafka.log.Log)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,567] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:06:50,608] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 65 (kafka.log.Log)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,567] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[31;1mkafka1                         |[0m [2020-05-20 20:06:58,202] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 1 (kafka.log.Log)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,571] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:00,166] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 12 (kafka.log.Log)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,572] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:02,306] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 15 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,572] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[31;1mkafka1                         |[0m [2020-05-20 20:07:04,409] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 17 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,572] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,572] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:07:06,451] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 18 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,572] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:08,513] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 23 (kafka.log.Log)
[36;1mconnect                        |[0m 	request.timeout.ms = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,609] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 54 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	retries = 2147483647
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,610] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 57 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:10,616] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 28 (kafka.log.Log)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,611] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 57 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:07:12,813] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 33 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,611] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:07:14,898] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 40 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,623] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:07:16,993] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 47 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,624] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:07:19,055] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 51 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,624] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 60566400000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 60566400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,096] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 173 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,099] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 515 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,135] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 547 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,625] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,138] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 630 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,625] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,141] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 630 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,144] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 173 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,625] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:07:21,150] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 54 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,625] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:07:23,171] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 55 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,628] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 57 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:07:25,277] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 60 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,628] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 57 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[31;1mkafka1                         |[0m [2020-05-20 20:07:27,351] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 61 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,629] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 57 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[31;1mkafka1                         |[0m [2020-05-20 20:07:29,408] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 66 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,633] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 58 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:31,435] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 67 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,638] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 58 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:07:33,510] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 69 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,648] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[31;1mkafka1                         |[0m [2020-05-20 20:07:35,590] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 71 (kafka.log.Log)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,648] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:07:37,631] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 76 (kafka.log.Log)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,657] INFO Creating topic _confluent-monitoring with configuration {message.timestamp.type=LogAppendTime, retention.ms=259200000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:07:39,705] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 78 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka1                         |[0m [2020-05-20 20:07:41,758] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 80 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,658] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 55 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[31;1mkafka1                         |[0m [2020-05-20 20:07:43,867] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 83 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,661] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 56 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,663] INFO [Controller id=2] New topics: [Set(_confluent-monitoring)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-monitoring-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:07:45,927] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 84 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,663] INFO [Controller id=2] New partition creation callback for _confluent-monitoring-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[31;1mkafka1                         |[0m [2020-05-20 20:07:47,997] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 87 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,663] TRACE [Controller id=2 epoch=1] Changed partition _confluent-monitoring-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:07:50,039] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 91 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:07:51,505] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 301 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,664] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-monitoring-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[31;1mkafka1                         |[0m [2020-05-20 20:07:51,508] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 899 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,664] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-monitoring-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:51,525] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 931 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,723] TRACE [Controller id=2 epoch=1] Changed partition _confluent-monitoring-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:51,528] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1106 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,724] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-monitoring-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,724] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 57 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,725] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-monitoring-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:51,530] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1106 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,725] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 59 from controller 2 epoch 1 for partition _confluent-monitoring-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:51,533] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 301 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,726] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 59 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-monitoring-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:52,082] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 95 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,726] INFO Replica loaded for partition _confluent-monitoring-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:07:54,136] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 97 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,725] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-monitoring-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:07:56,206] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 98 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,728] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-monitoring-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:07:58,252] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 102 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,728] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-monitoring-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	transactional.id = null
[31;1mkafka1                         |[0m [2020-05-20 20:08:00,344] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 106 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,729] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,732] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:08:02,437] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 110 (kafka.log.Log)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,741] INFO Created log for partition _confluent-monitoring-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 259200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:08:04,487] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 115 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:08:06,545] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 120 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[31;1mkafka1                         |[0m [2020-05-20 20:08:08,571] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 125 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,742] INFO [Partition _confluent-monitoring-0 broker=2] No checkpointed highwatermark is found for partition _confluent-monitoring-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:08:10,661] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 130 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,742] INFO Replica loaded for partition _confluent-monitoring-0 with initial high watermark 0 (kafka.cluster.Replica)
[31;1mkafka1                         |[0m [2020-05-20 20:08:12,735] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 134 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,741] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 58 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:14,813] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 137 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,743] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-monitoring-0) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:08:16,904] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 139 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,743] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 59 for partition _confluent-monitoring-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:18,942] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 144 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,743] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-monitoring-0 as part of become-follower request with correlation id 59 from controller 2 epoch 1 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,014] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 146 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,744] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-monitoring-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,742] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 424 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,744] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 59 for partition _confluent-monitoring-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,744] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 59 from controller 2 epoch 1 for the become-follower transition for partition _confluent-monitoring-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,745] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1283 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,749] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-monitoring,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 59 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,815] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1319 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,750] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-monitoring-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 60 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,818] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1547 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,528] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,821] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1547 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,753] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 60 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:21,823] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 424 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,529] INFO Kafka startTimeMs: 1590005149528 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,756] INFO Creating topic _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=67108864, delete.retention.ms=432000000, retention.ms=432000000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:08:23,064] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 151 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,530] WARN Error registering AppInfo mbean (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,815] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:08:25,076] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 156 (kafka.log.Log)
[36;1mconnect                        |[0m javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=connect-worker-producer
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,816] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:08:27,163] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 160 (kafka.log.Log)
[36;1mconnect                        |[0m 	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,816] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,816] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
[31;1mkafka1                         |[0m [2020-05-20 20:08:29,176] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 162 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,817] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
[31;1mkafka1                         |[0m [2020-05-20 20:08:31,196] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 166 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,823] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
[31;1mkafka1                         |[0m [2020-05-20 20:08:33,213] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 172 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,823] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
[31;1mkafka1                         |[0m [2020-05-20 20:08:37,323] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 174 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,834] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
[31;1mkafka1                         |[0m [2020-05-20 20:08:39,399] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 175 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,834] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:41,411] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 176 (kafka.log.Log)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
[31;1mkafka1                         |[0m [2020-05-20 20:08:43,446] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 179 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,835] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:427)
[31;1mkafka1                         |[0m [2020-05-20 20:08:45,534] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 183 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,835] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:270)
[31;1mkafka1                         |[0m [2020-05-20 20:08:47,603] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 185 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,825] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-monitoring,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 59 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:49,713] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 190 (kafka.log.Log)
[36;1mconnect                        |[0m 	at org.apache.kafka.connect.runtime.Worker.buildWorkerTask(Worker.java:514)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,835] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 61 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:459)
[31;1mkafka1                         |[0m [2020-05-20 20:08:51,763] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 194 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,845] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 61 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1036)
[31;1mkafka1                         |[0m [2020-05-20 20:08:52,022] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 552 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,845] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$1600(DistributedHerder.java:117)
[31;1mkafka1                         |[0m [2020-05-20 20:08:52,024] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1667 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,848] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	at org.apache.kafka.connect.runtime.distributed.DistributedHerder$13.call(DistributedHerder.java:1051)
[31;1mkafka1                         |[0m [2020-05-20 20:08:52,039] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1703 (kafka.log.Log)
[36;1mconnect                        |[0m 	at org.apache.kafka.connect.runtime.distributed.DistributedHerder$13.call(DistributedHerder.java:1047)
[31;1mkafka1                         |[0m [2020-05-20 20:08:52,041] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1995 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,848] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[31;1mkafka1                         |[0m [2020-05-20 20:08:52,044] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1995 (kafka.log.Log)
[36;1mconnect                        |[0m 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,849] INFO Created log for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 67108864, retention.ms -> 432000000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 432000000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,849] INFO [Partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:08:52,046] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 552 (kafka.log.Log)
[36;1mconnect                        |[0m 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[31;1mkafka1                         |[0m [2020-05-20 20:08:53,784] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 197 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,849] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka1                         |[0m [2020-05-20 20:08:55,808] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 201 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,849] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,532] INFO [Worker clientId=connect-1, groupId=connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,849] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 61 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:08:57,821] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 204 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:08:59,884] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 209 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,849] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 as part of become-follower request with correlation id 61 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,534] INFO ReplicatorSourceTaskConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,850] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	confluent.license = 
[31;1mkafka1                         |[0m [2020-05-20 20:09:01,919] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 212 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:09:04,012] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 215 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,850] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 61 for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	confluent.topic = _confluent-command
[31;1mkafka1                         |[0m [2020-05-20 20:09:06,047] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 218 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,850] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 61 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,850] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 60 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:08,116] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 219 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.client.id = 
[31;1mkafka1                         |[0m [2020-05-20 20:09:10,190] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 222 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,851] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 61 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:12,273] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 226 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,852] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 62 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,854] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 62 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:14,307] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 227 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,861] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 61 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:16,335] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 232 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,895] INFO Creating topic _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:09:18,430] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 234 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,901] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 62 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:20,448] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 237 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,922] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	dest.kafka.receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,343] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 676 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,922] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,346] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2051 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,922] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,523] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2091 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,922] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,526] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2443 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,922] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,528] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2443 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.retry.backoff.ms = 100
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,531] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 676 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,932] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.send.buffer.bytes = 131072
[31;1mkafka1                         |[0m [2020-05-20 20:09:22,536] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 243 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.zookeeper.connect = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,932] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:24,623] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 250 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.zookeeper.connection.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,932] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:26,731] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 254 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.zookeeper.session.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,932] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	offset.start = connect
[36;1mconnect                        |[0m 	offset.timestamps.commit = false
[36;1mconnect                        |[0m 	offset.topic.commit = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,933] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.batch.period.ms = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:09:28,796] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 257 (kafka.log.Log)
[36;1mconnect                        |[0m 	offset.translator.batch.size = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,933] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:30,812] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 260 (kafka.log.Log)
[36;1mconnect                        |[0m 	offset.translator.tasks.max = -1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,936] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 63 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:32,828] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 262 (kafka.log.Log)
[36;1mconnect                        |[0m 	offset.translator.tasks.separate = false
[31;1mkafka1                         |[0m [2020-05-20 20:09:34,855] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 267 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,937] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 63 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	partition.assignment = AAAAAAABABB3aWtpcGVkaWEucGFyc2VkAAAAAgAAAAAAAAABAAAAAA==
[31;1mkafka1                         |[0m [2020-05-20 20:09:36,891] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 270 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,937] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	provenance.header.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,945] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:09:38,913] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 273 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,945] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	provenance.header.filter.overrides = 
[31;1mkafka1                         |[0m [2020-05-20 20:09:40,987] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 277 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,946] INFO Created log for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.credentials.source = URL
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,946] INFO [Partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:09:43,005] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 280 (kafka.log.Log)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.user.info = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:09:45,044] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 283 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,946] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	schema.registry.max.schemas.per.subject = 1000
[31;1mkafka1                         |[0m [2020-05-20 20:09:47,068] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 288 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,946] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	schema.registry.topic = null
[31;1mkafka1                         |[0m [2020-05-20 20:09:49,108] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 298 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,946] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 63 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.url = null
[31;1mkafka1                         |[0m [2020-05-20 20:09:51,204] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 299 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,946] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 as part of become-follower request with correlation id 63 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	schema.subject.translator.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:09:52,741] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 800 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,947] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.consumer.check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,947] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 63 for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:52,744] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2435 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,947] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 63 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 with leader 1 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:52,746] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2891 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,947] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 63 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:52,749] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2891 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,948] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 63 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:52,812] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2475 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,949] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 64 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:52,815] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 800 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,954] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 64 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:09:53,247] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 302 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.consumer.max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:34,955] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 64 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.max.poll.records = 500
[36;1mconnect                        |[0m 	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[31;1mkafka1                         |[0m [2020-05-20 20:09:55,350] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 304 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,004] INFO Creating topic _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog with configuration {message.timestamp.type=CreateTime, segment.bytes=134217728, delete.retention.ms=691200000, retention.ms=691200000, min.insync.replicas=1, cleanup.policy=compact, retention.bytes=-1, message.timestamp.difference.max.ms=9223372036854775807} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[31;1mkafka1                         |[0m [2020-05-20 20:09:57,404] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 309 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,033] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:09:59,430] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 313 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,033] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (kafka.controller.KafkaController)
[31;1mkafka1                         |[0m [2020-05-20 20:10:01,497] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 318 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,033] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.metric.reporters = []
[31;1mkafka1                         |[0m [2020-05-20 20:10:03,520] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 321 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,033] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.metrics.num.samples = 2
[31;1mkafka1                         |[0m [2020-05-20 20:10:05,620] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 324 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,033] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.metrics.sample.window.ms = 30000
[31;1mkafka1                         |[0m [2020-05-20 20:10:07,719] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 326 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.receive.buffer.bytes = 65536
[31;1mkafka1                         |[0m [2020-05-20 20:10:09,752] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 330 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.reconnect.backoff.ms = 50
[31;1mkafka1                         |[0m [2020-05-20 20:10:11,788] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 336 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,049] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.request.timeout.ms = 30000
[36;1mconnect                        |[0m 	src.kafka.retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,049] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[31;1mkafka1                         |[0m [2020-05-20 20:10:13,827] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 341 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.client.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:10:15,851] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 343 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,050] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.jaas.config = [hidden]
[31;1mkafka1                         |[0m [2020-05-20 20:10:17,950] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 346 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,050] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 65 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka1                         |[0m [2020-05-20 20:10:20,006] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 348 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,051] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 65 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka1                         |[0m [2020-05-20 20:10:22,109] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 351 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,051] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.service.name = null
[31;1mkafka1                         |[0m [2020-05-20 20:10:23,147] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 924 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,051] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:10:23,150] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2812 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,052] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.callback.handler.class = null
[31;1mkafka1                         |[0m [2020-05-20 20:10:23,195] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2856 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,052] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,054] INFO [Log partition=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:10:23,198] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 3332 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,055] INFO [Log partition=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,055] INFO Created log for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 134217728, retention.ms -> 691200000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 691200000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[31;1mkafka1                         |[0m [2020-05-20 20:10:23,201] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 3332 (kafka.log.Log)
[31;1mkafka1                         |[0m [2020-05-20 20:10:23,204] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 924 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] INFO [Partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 (kafka.cluster.Partition)
[31;1mkafka1                         |[0m [2020-05-20 20:10:24,195] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 354 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.factor = 0.8
[31;1mkafka1                         |[0m [2020-05-20 20:10:26,267] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 358 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.jitter = 0.05
[31;1mkafka1                         |[0m [2020-05-20 20:10:28,308] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1, dir=/var/lib/kafka/data] Incrementing log start offset to 365 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 65 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 as part of become-follower request with correlation id 65 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	src.kafka.ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 65 for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,056] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 65 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.endpoint.identification.algorithm = https
[36;1mconnect                        |[0m 	src.kafka.ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,057] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 65 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,058] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 66 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,110] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 66 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,125] INFO Creating topic _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey with configuration {message.timestamp.type=LogAppendTime, retention.ms=604800000, min.insync.replicas=1, cleanup.policy=delete, retention.bytes=-1} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,136] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 65 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,145] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	src.kafka.ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,145] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	src.kafka.ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,145] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,145] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 66 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.type = JKS
[36;1mconnect                        |[0m 	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,146] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,146] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,154] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.connect = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,154] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.connection.timeout.ms = 6000
[36;1mconnect                        |[0m 	src.zookeeper.session.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,155] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	task.id = replicate-topic-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,155] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.auto.create = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,156] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,156] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,156] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 67 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,157] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 67 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,157] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	topic.blacklist = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,159] INFO [Log partition=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,160] INFO [Log partition=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	topic.config.sync = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	topic.config.sync.interval.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [Log partition=_confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	topic.create.backoff.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-monitoring-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	topic.poll.interval.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [Log partition=_confluent-monitoring-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	topic.preserve.partitions = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	topic.regex = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [Log partition=_confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	topic.rename.format = ${topic}.replica
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	topic.timestamp.type = CreateTime
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,162] INFO [Log partition=_confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	topic.whitelist = [wikipedia.parsed]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,208] INFO Created log for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> LogAppendTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,209] INFO [Partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m  (io.confluent.connect.replicator.ReplicatorSourceTaskConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,209] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,536] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,209] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,209] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 67 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,209] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 as part of become-follower request with correlation id 67 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,210] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,210] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 67 for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,210] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 67 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,221] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 67 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,223] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 68 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,245] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 68 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,253] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 67 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,257] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 68 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,547] INFO [GroupCoordinator 2]: Preparing to rebalance group schema-registry in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member sr-1-c8b7a812-56d2-4908-9d8b-9bd1575ad52e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,746] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:35,746] INFO [Log partition=_confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] INFO [Controller id=2] New topics: [Set(users)], deleted topics: [Set()], new partition replica assignment [Map(users-1 -> Vector(1, 2), users-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	retries = 5
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] INFO [Controller id=2] New partition creation callback for users-1,users-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] TRACE [Controller id=2 epoch=1] Changed partition users-1 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] TRACE [Controller id=2 epoch=1] Changed partition users-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition users-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition users-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition users-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,128] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition users-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,134] TRACE [Controller id=2 epoch=1] Changed partition users-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,134] TRACE [Controller id=2 epoch=1] Changed partition users-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,134] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition users-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,134] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition users-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,135] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition users-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,135] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition users-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,135] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition users-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,135] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition users-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,135] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition users-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,135] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition users-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,136] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition users-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,136] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition users-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,136] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 69 from controller 2 epoch 1 for partition users-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,136] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 69 from controller 2 epoch 1 for partition users-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,137] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 69 from controller 2 epoch 1 starting the become-leader transition for partition users-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,137] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(users-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,139] INFO [Log partition=users-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,140] INFO [Log partition=users-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,140] INFO Created log for partition users-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,141] INFO [Partition users-0 broker=2] No checkpointed highwatermark is found for partition users-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,141] INFO Replica loaded for partition users-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,141] INFO Replica loaded for partition users-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,141] INFO [Partition users-0 broker=2] users-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,144] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 69 for partition users-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,144] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 69 from controller 2 epoch 1 for the become-leader transition for partition users-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,601] INFO [Producer clientId=connect-worker-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,144] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 69 from controller 2 epoch 1 starting the become-follower transition for partition users-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,614] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,144] INFO Replica loaded for partition users-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,618] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Setting newly assigned partitions: WIKIPEDIABOT-1, WIKIPEDIABOT-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,146] INFO [Log partition=users-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,697] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Found no committed offset for partition WIKIPEDIABOT-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,147] INFO [Log partition=users-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,699] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Found no committed offset for partition WIKIPEDIABOT-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,147] INFO Created log for partition users-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,805] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Resetting offset for partition WIKIPEDIABOT-1 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,148] INFO [Partition users-1 broker=2] No checkpointed highwatermark is found for partition users-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,148] INFO Replica loaded for partition users-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:49,817] INFO [Consumer clientId=connector-consumer-elasticsearch-ksql-0, groupId=connect-elasticsearch-ksql] Resetting offset for partition WIKIPEDIABOT-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,148] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(users-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:50,518] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,148] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 69 for partition users-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:50,518] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,148] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition users-1 as part of become-follower request with correlation id 69 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:50,518] INFO Kafka startTimeMs: 1590005150518 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,149] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(users-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:50,598] INFO AdminClientConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,149] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 69 for partition users-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,149] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 69 from controller 2 epoch 1 for the become-follower transition for partition users-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,150] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=users,partition=1,error_code=0},{topic=users,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 69 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,151] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition users-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,151] INFO [Log partition=users-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,152] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=users,partition=1,error_code=0},{topic=users,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 69 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,153] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition users-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 70 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,153] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition users-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 70 (state.change.logger)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,153] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 70 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,154] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 70 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,555] INFO [GroupCoordinator 2]: Stabilized group schema-registry generation 1 (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,573] INFO [GroupCoordinator 2]: Assignment received from leader for group schema-registry for generation 1 (kafka.coordinator.group.GroupCoordinator)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:38,646] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition users-1 at offset 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:42,279] INFO [Admin Manager on Broker 2]: Error processing create topic request CreatableTopic(name='_confluent-command', numPartitions=1, replicationFactor=2, assignments=[], configs=[CreateableTopicConfig(name='cleanup.policy', value='compact')]) (kafka.server.AdminManager)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.TopicExistsException: Topic '_confluent-command' already exists.
[36;1mconnect                        |[0m 	request.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,305] INFO [Controller id=2] New topics: [Set(wikipedia.parsed)], deleted topics: [Set()], new partition replica assignment [Map(wikipedia.parsed-1 -> Vector(1, 2), wikipedia.parsed-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,305] INFO [Controller id=2] New partition creation callback for wikipedia.parsed-1,wikipedia.parsed-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,305] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed-1 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,305] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	retries = 5
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,306] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,306] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,306] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,306] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,316] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,317] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,317] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition wikipedia.parsed-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,317] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition wikipedia.parsed-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,317] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition wikipedia.parsed-1 (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,318] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition wikipedia.parsed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,318] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.parsed-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 71 from controller 2 epoch 1 for partition wikipedia.parsed-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.parsed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 71 from controller 2 epoch 1 for partition wikipedia.parsed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,319] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,320] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 71 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.parsed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,320] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.parsed-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,323] INFO [Log partition=wikipedia.parsed-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,324] INFO [Log partition=wikipedia.parsed-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,325] INFO Created log for partition wikipedia.parsed-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,325] INFO [Partition wikipedia.parsed-0 broker=2] No checkpointed highwatermark is found for partition wikipedia.parsed-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,325] INFO Replica loaded for partition wikipedia.parsed-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,326] INFO Replica loaded for partition wikipedia.parsed-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,326] INFO [Partition wikipedia.parsed-0 broker=2] wikipedia.parsed-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,329] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 71 for partition wikipedia.parsed-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,329] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 71 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.parsed-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,329] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 71 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.parsed-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,330] INFO Replica loaded for partition wikipedia.parsed-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.bootstrap.servers' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,334] INFO [Log partition=wikipedia.parsed-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,334] INFO [Log partition=wikipedia.parsed-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,335] INFO Created log for partition wikipedia.parsed-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,335] INFO [Partition wikipedia.parsed-1 broker=2] No checkpointed highwatermark is found for partition wikipedia.parsed-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,335] INFO Replica loaded for partition wikipedia.parsed-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,336] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.parsed-1) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,336] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 71 for partition wikipedia.parsed-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,336] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition wikipedia.parsed-1 as part of become-follower request with correlation id 71 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,336] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(wikipedia.parsed-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,336] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 71 for partition wikipedia.parsed-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,612] INFO Kafka startTimeMs: 1590005151612 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,336] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 71 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.parsed-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:51,615] INFO ConsumerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,337] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.parsed,partition=1,error_code=0},{topic=wikipedia.parsed,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 71 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	allow.auto.create.topics = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,338] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.parsed-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 72 (state.change.logger)
[36;1mconnect                        |[0m 	auto.commit.interval.ms = 5000
[36;1mconnect                        |[0m 	auto.offset.reset = none
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,338] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.parsed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 72 (state.change.logger)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,340] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 72 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,342] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.parsed,partition=1,error_code=0},{topic=wikipedia.parsed,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 71 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,344] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 72 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,595] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition wikipedia.parsed-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	client.id = replicate-topic-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:44,595] INFO [Log partition=wikipedia.parsed-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	client.rack = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,237] INFO Creating topic _confluent-ksql-default__command_topic with configuration {retention.ms=9223372036854775807, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,245] INFO [Controller id=2] New topics: [Set(_confluent-ksql-default__command_topic)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-ksql-default__command_topic-0 -> Vector(1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	default.api.timeout.ms = 60000
[36;1mconnect                        |[0m 	enable.auto.commit = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,245] INFO [Controller id=2] New partition creation callback for _confluent-ksql-default__command_topic-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	exclude.internal.topics = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,245] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default__command_topic-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[36;1mconnect                        |[0m 	fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,245] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-ksql-default__command_topic-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,250] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default__command_topic-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	fetch.min.bytes = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,250] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-ksql-default__command_topic-0 (state.change.logger)
[36;1mconnect                        |[0m 	group.id = connect-replicator
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,250] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-ksql-default__command_topic-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,251] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-ksql-default__command_topic-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	group.instance.id = null
[36;1mconnect                        |[0m 	heartbeat.interval.ms = 3000
[36;1mconnect                        |[0m 	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,251] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-ksql-default__command_topic-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 73 (state.change.logger)
[36;1mconnect                        |[0m 	internal.leave.group.on.close = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,253] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 73 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	isolation.level = read_uncommitted
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,260] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-ksql-default__command_topic,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 73 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,262] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 74 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,417] INFO Creating topic wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(1 -> ArrayBuffer(2), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,427] INFO [Controller id=2] New topics: [Set(wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog)], deleted topics: [Set()], new partition replica assignment [Map(wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 -> Vector(2), wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	max.poll.records = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,427] INFO [Controller id=2] New partition creation callback for wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1,wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,427] TRACE [Controller id=2 epoch=1] Changed partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,427] TRACE [Controller id=2 epoch=1] Changed partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,428] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,428] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,439] TRACE [Controller id=2 epoch=1] Changed partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,439] TRACE [Controller id=2 epoch=1] Changed partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,439] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2, zkVersion=0, replicas=2, isNew=true) to broker 2 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,439] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,439] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,440] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,440] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,440] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2, zkVersion=0, replicas=2, isNew=true) correlation id 74 from controller 2 epoch 1 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,440] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,441] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 74 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,441] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,443] INFO [Log partition=wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,444] INFO [Log partition=wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,444] INFO Created log for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,445] INFO [Partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 broker=2] No checkpointed highwatermark is found for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,445] INFO Replica loaded for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,445] INFO [Partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 broker=2] wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,447] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 74 for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,447] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 74 from controller 2 epoch 1 for the become-leader transition for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,448] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 74 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,448] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 75 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,449] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 76 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,501] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 75 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,501] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) for partition wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 75 (state.change.logger)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:45,503] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 75 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,331] INFO Creating topic _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	session.timeout.ms = 10000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,337] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,338] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,338] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,338] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,339] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,339] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,347] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,347] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,348] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,348] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,348] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,348] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,349] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 76 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,349] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 76 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,349] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,351] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,351] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,351] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,351] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,130] WARN The configuration 'confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,351] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,352] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,352] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.bootstrap.servers' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,353] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,353] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.sasl.jaas.config' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,353] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,353] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 broker=2] _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,355] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,355] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 77 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,356] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 76 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,356] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 76 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,357] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 78 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,397] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 76 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.ssl.keystore.location' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,400] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.ssl.key.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,400] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,401] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.bootstrap.servers' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,401] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 77 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.sasl.mechanism' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,401] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.interceptor.classes' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,402] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.ssl.truststore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,402] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'timestamps.producer.confluent.monitoring.interceptor.security.protocol' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,404] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 77 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] WARN The configuration 'confluent.monitoring.interceptor.ssl.keystore.password' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,404] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 78 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,411] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 79 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,412] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 78 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,131] INFO Kafka startTimeMs: 1590005152131 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,412] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,134] INFO ConsumerOffsetsTranslatorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,414] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 80 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	confluent.license = 
[36;1mconnect                        |[0m 	confluent.topic = _confluent-command
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,415] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,415] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	dest.kafka.client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,416] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	dest.kafka.connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,416] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	dest.kafka.metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,416] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	dest.kafka.metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,416] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	dest.kafka.metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,416] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	dest.kafka.receive.buffer.bytes = 65536
[36;1mconnect                        |[0m 	dest.kafka.reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] INFO [Controller id=2] New topics: [Set(wikipedia.parsed.count-by-channel)], deleted topics: [Set()], new partition replica assignment [Map(wikipedia.parsed.count-by-channel-1 -> Vector(1, 2), wikipedia.parsed.count-by-channel-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	dest.kafka.request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] INFO [Controller id=2] New partition creation callback for wikipedia.parsed.count-by-channel-1,wikipedia.parsed.count-by-channel-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	dest.kafka.retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.count-by-channel-1 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	dest.kafka.send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.count-by-channel-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	dest.zookeeper.connect = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.count-by-channel-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	dest.zookeeper.connection.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.count-by-channel-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	dest.zookeeper.session.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.count-by-channel-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	fetch.offset.expiry.ms = 600000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,418] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.count-by-channel-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	fetch.offset.retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,419] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 78 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	offset.start = connect
[36;1mconnect                        |[0m 	offset.timestamps.commit = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,419] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 78 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	offset.topic.commit = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,420] INFO Creating topic _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	offset.translator.batch.period.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,421] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 78 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.batch.size = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,422] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 79 (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.tasks.max = -1
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,423] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 79 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	offset.translator.tasks.separate = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,427] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.count-by-channel-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,427] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.count-by-channel-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	provenance.header.enable = false
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,427] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[36;1mconnect                        |[0m 	provenance.header.filter.overrides = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,427] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.credentials.source = URL
[36;1mconnect                        |[0m 	schema.registry.client.basic.auth.user.info = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,428] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.max.schemas.per.subject = 1000
[36;1mconnect                        |[0m 	schema.registry.topic = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,428] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	schema.registry.url = null
[36;1mconnect                        |[0m 	schema.subject.translator.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,428] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.check.crcs = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,429] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.bytes = 52428800
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,429] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.count-by-channel-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,429] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.count-by-channel-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.fetch.max.wait.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,429] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.count-by-channel-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.fetch.min.bytes = 1
[36;1mconnect                        |[0m 	src.consumer.interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
[36;1mconnect                        |[0m 	src.consumer.max.partition.fetch.bytes = 1048576
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,429] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.count-by-channel-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.max.poll.interval.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,495] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 80 from controller 2 epoch 1 for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.consumer.max.poll.records = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,495] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 80 from controller 2 epoch 1 for partition wikipedia.parsed.count-by-channel-1 (state.change.logger)
[36;1mconnect                        |[0m 	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[36;1mconnect                        |[0m 	src.kafka.bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,496] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m 	src.kafka.client.id = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,496] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 80 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,496] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.parsed.count-by-channel-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,499] INFO [Log partition=wikipedia.parsed.count-by-channel-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.metrics.num.samples = 2
[36;1mconnect                        |[0m 	src.kafka.metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,500] INFO [Log partition=wikipedia.parsed.count-by-channel-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	src.kafka.receive.buffer.bytes = 65536
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,500] INFO Created log for partition wikipedia.parsed.count-by-channel-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	src.kafka.reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,501] INFO [Partition wikipedia.parsed.count-by-channel-0 broker=2] No checkpointed highwatermark is found for partition wikipedia.parsed.count-by-channel-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,501] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,501] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.retry.backoff.ms = 100
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,501] INFO [Partition wikipedia.parsed.count-by-channel-0 broker=2] wikipedia.parsed.count-by-channel-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	src.kafka.sasl.client.callback.handler.class = null
[36;1mconnect                        |[0m 	src.kafka.sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,503] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 80 for partition wikipedia.parsed.count-by-channel-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,503] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 80 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.parsed.count-by-channel-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.service.name = null
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,504] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 80 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.parsed.count-by-channel-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,504] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,507] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition, _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,507] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0,_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,507] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,507] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,508] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,508] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,508] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,508] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,513] INFO [Log partition=wikipedia.parsed.count-by-channel-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,513] INFO [Log partition=wikipedia.parsed.count-by-channel-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,514] INFO Created log for partition wikipedia.parsed.count-by-channel-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,514] INFO [Partition wikipedia.parsed.count-by-channel-1 broker=2] No checkpointed highwatermark is found for partition wikipedia.parsed.count-by-channel-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,514] INFO Replica loaded for partition wikipedia.parsed.count-by-channel-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	src.kafka.sasl.mechanism = PLAIN
[36;1mconnect                        |[0m 	src.kafka.security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,515] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.parsed.count-by-channel-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,515] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 80 for partition wikipedia.parsed.count-by-channel-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.cipher.suites = null
[36;1mconnect                        |[0m 	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,515] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition wikipedia.parsed.count-by-channel-1 as part of become-follower request with correlation id 80 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.endpoint.identification.algorithm = https
[36;1mconnect                        |[0m 	src.kafka.ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	src.kafka.ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,515] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(wikipedia.parsed.count-by-channel-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	src.kafka.ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,515] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 80 for partition wikipedia.parsed.count-by-channel-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,515] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 80 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.parsed.count-by-channel-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,517] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.parsed.count-by-channel,partition=0,error_code=0},{topic=wikipedia.parsed.count-by-channel,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 80 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,518] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.parsed.count-by-channel-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 81 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,518] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.parsed.count-by-channel-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 81 (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,519] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 81 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,527] INFO Creating topic _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,528] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,528] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	src.kafka.ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,528] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[36;1mconnect                        |[0m 	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,528] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.connect = 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,529] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.connection.timeout.ms = 6000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,529] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	src.zookeeper.session.timeout.ms = 6000
[36;1mconnect                        |[0m 	topic.auto.create = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,529] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.blacklist = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,529] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.parsed.count-by-channel,partition=0,error_code=0},{topic=wikipedia.parsed.count-by-channel,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 81 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	topic.config.sync = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,529] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.config.sync.interval.ms = 120000
[36;1mconnect                        |[0m 	topic.create.backoff.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,530] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 82 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,530] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 82 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.poll.interval.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,530] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	topic.preserve.partitions = true
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,530] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	topic.regex = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,530] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	topic.rename.format = ${topic}.replica
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,531] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,532] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 82 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	topic.timestamp.type = CreateTime
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,532] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 82 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,532] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	topic.whitelist = [wikipedia.parsed]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,536] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m  (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslatorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,134] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Subscribed to partition(s): wikipedia.parsed-0, wikipedia.parsed-1 (org.apache.kafka.clients.consumer.KafkaConsumer)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,537] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,137] INFO Requesting metadata refresh after 1 new topics were added (io.confluent.connect.replicator.util.ReplicatorAdminClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,537] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,210] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,229] WARN Failed to refresh topic metadata. Will try again in 30000ms. (io.confluent.connect.replicator.util.ReplicatorAdminClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,538] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,538] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,538] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,538] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,596] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 82 for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,596] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 82 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,596] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 82 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	at io.confluent.connect.replicator.util.NewReplicatorAdminClient$TopicMetadataTask.refreshTopicMetadata(NewReplicatorAdminClient.java:407)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,597] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	at io.confluent.connect.replicator.util.NewReplicatorAdminClient$TopicMetadataTask.run(NewReplicatorAdminClient.java:393)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,599] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition wikipedia.parsed.count-by-channel-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] INFO [Controller id=2] New topics: [Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition, _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[36;1mconnect                        |[0m 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] INFO [Controller id=2] New partition creation callback for _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0,_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[36;1mconnect                        |[0m 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,600] INFO [Log partition=wikipedia.parsed.count-by-channel-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,601] INFO Created log for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,232] WARN Failed to refresh topic metadata. Will try again in 30000ms. (io.confluent.connect.replicator.util.ReplicatorAdminClient)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,602] INFO [Partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,602] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,603] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,603] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 82 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,603] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 as part of become-follower request with correlation id 82 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,603] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	at io.confluent.connect.replicator.util.NewReplicatorAdminClient$TopicMetadataTask.refreshTopicMetadata(NewReplicatorAdminClient.java:407)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,604] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 82 for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	at io.confluent.connect.replicator.util.NewReplicatorAdminClient$TopicMetadataTask.run(NewReplicatorAdminClient.java:393)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,604] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 82 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,605] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,605] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition,partition=0,error_code=0},{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 83 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,605] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition,partition=0,error_code=0},{topic=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 82 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,605] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,606] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,607] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 83 (state.change.logger)
[36;1mconnect                        |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,607] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 83 (state.change.logger)
[36;1mconnect                        |[0m Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[36;1mconnect                        |[0m [2020-05-20 20:05:52,426] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Discovered group coordinator kafka1:9091 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,607] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 84 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,443] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Found no committed offset for partition wikipedia.parsed-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,608] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 83 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,444] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Seeking to EARLIEST offset of partition wikipedia.parsed-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,618] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,444] INFO Seeking to the beginning and pausing source partition wikipedia.parsed-0 since destination partition wikipedia.parsed.replica-0 is not ready yet (io.confluent.connect.replicator.ReplicatorSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,619] TRACE [Controller id=2 epoch=1] Changed partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,914] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Found no committed offset for partition wikipedia.parsed-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,619] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,914] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Seeking to EARLIEST offset of partition wikipedia.parsed-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,619] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,914] INFO Seeking to the beginning and pausing source partition wikipedia.parsed-1 since destination partition wikipedia.parsed.replica-1 is not ready yet (io.confluent.connect.replicator.ReplicatorSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,619] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,914] INFO Started kafka replicator task replicate-topic-0 replicating partitions [wikipedia.parsed-0, wikipedia.parsed-1] (io.confluent.connect.replicator.ReplicatorSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,619] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,914] INFO WorkerSourceTask{id=replicate-topic-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,620] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 84 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,941] INFO Creating topic wikipedia.parsed.replica in destination cluster with 2 partitions and replication factor 2 (io.confluent.connect.replicator.ReplicatorSourceTask)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,942] INFO Creating topic wikipedia.parsed.replica with 2 partitions, replication factor 2, and config {message.downconversion.enable=true, file.delete.delay.ms=60000, segment.ms=604800000, min.compaction.lag.ms=0, retention.bytes=-1, segment.index.bytes=10485760, cleanup.policy=delete, max.compaction.lag.ms=9223372036854775807, follower.replication.throttled.replicas=, message.timestamp.difference.max.ms=9223372036854775807, segment.jitter.ms=0, preallocate=false, message.timestamp.type=CreateTime, message.format.version=2.3-IV1, segment.bytes=1073741824, unclean.leader.election.enable=false, max.message.bytes=1000012, retention.ms=604800000, flush.ms=9223372036854775807, delete.retention.ms=86400000, leader.replication.throttled.replicas=, min.insync.replicas=1, flush.messages=9223372036854775807, compression.type=producer, index.interval.bytes=4096, min.cleanable.dirty.ratio=0.5} (io.confluent.connect.replicator.util.ReplicatorAdminClient)
[36;1mconnect                        |[0m [2020-05-20 20:05:52,990] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Resetting offset for partition wikipedia.parsed-1 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,620] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:53,009] INFO [Consumer clientId=replicate-topic-0, groupId=connect-replicator] Resetting offset for partition wikipedia.parsed-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,620] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 84 from controller 2 epoch 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:54,296] INFO creating interceptor (io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor)
[36;1mconnect                        |[0m [2020-05-20 20:05:54,299] INFO creating interceptor (io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,620] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:54,409] INFO MonitoringInterceptorConfig values: 
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,621] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect                        |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:54,409] INFO MonitoringInterceptorConfig values: 
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,622] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,622] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,622] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:54,507] INFO ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,623] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 84 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	acks = all
[36;1mconnect                        |[0m 	batch.size = 16384
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,624] INFO [Controller id=2] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,628] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,695] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition,partition=0,error_code=0},{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 85 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,697] INFO [Controller id=2] New topics: [Set()], deleted topics: [Set()], new partition replica assignment [Map()] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,698] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 86 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	client.id = confluent.monitoring.interceptor.replicate-topic-0
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,698] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	compression.type = lz4
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,699] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,699] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	enable.idempotence = false
[36;1mconnect                        |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,699] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,700] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	linger.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,700] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	max.block.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,700] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 broker=2] _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,703] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 84 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,703] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 84 from controller 2 epoch 1 for the become-leader transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 (state.change.logger)
[36;1mconnect                        |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,703] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 84 from controller 2 epoch 1 starting the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,703] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,705] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,706] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,706] INFO Created log for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,707] INFO [Partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,707] INFO Replica loaded for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,707] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,707] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 84 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,707] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 as part of become-follower request with correlation id 84 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,708] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,708] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 84 for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,708] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 84 from controller 2 epoch 1 for the become-follower transition for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m 	retries = 10
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,709] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition,partition=0,error_code=0},{topic=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 84 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,710] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 85 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,710] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 85 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,712] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 85 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,729] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,729] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,730] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:50,730] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,398] INFO [Controller id=2] New topics: [Set(wikipedia.failed)], deleted topics: [Set()], new partition replica assignment [Map(wikipedia.failed-1 -> Vector(2, 1), wikipedia.failed-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,398] INFO [Controller id=2] New partition creation callback for wikipedia.failed-1,wikipedia.failed-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,398] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.failed-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,399] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.failed-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,399] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.failed-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,399] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.failed-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,399] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.failed-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,399] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.failed-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,405] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.failed-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,405] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.failed-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,405] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,405] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition wikipedia.failed-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,405] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,405] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition wikipedia.failed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.failed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.client.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.failed-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.failed-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.failed-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.failed-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 86 from controller 2 epoch 1 for partition wikipedia.failed-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,406] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 86 from controller 2 epoch 1 for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,407] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 86 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.client.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,407] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.failed-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,409] INFO [Log partition=wikipedia.failed-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,410] INFO [Log partition=wikipedia.failed-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,410] INFO Created log for partition wikipedia.failed-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,410] INFO [Partition wikipedia.failed-1 broker=2] No checkpointed highwatermark is found for partition wikipedia.failed-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,411] INFO Replica loaded for partition wikipedia.failed-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,411] INFO Replica loaded for partition wikipedia.failed-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:54,507] INFO ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,411] INFO [Partition wikipedia.failed-1 broker=2] wikipedia.failed-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	acks = all
[36;1mconnect                        |[0m 	batch.size = 16384
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,414] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 86 for partition wikipedia.failed-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,414] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 86 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.failed-1 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = confluent.monitoring.interceptor.connect-worker-producer
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,414] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 86 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.failed-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	compression.type = lz4
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,414] INFO Replica loaded for partition wikipedia.failed-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,416] INFO [Log partition=wikipedia.failed-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	enable.idempotence = false
[36;1mconnect                        |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,416] INFO [Log partition=wikipedia.failed-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[36;1mconnect                        |[0m 	linger.ms = 500
[36;1mconnect                        |[0m 	max.block.ms = 60000
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,417] INFO Created log for partition wikipedia.failed-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,417] INFO [Partition wikipedia.failed-0 broker=2] No checkpointed highwatermark is found for partition wikipedia.failed-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,417] INFO Replica loaded for partition wikipedia.failed-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,418] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.failed-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,418] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 86 for partition wikipedia.failed-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,418] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition wikipedia.failed-0 as part of become-follower request with correlation id 86 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,418] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(wikipedia.failed-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,418] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 86 for partition wikipedia.failed-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,418] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 86 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.failed-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,419] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.failed,partition=0,error_code=0},{topic=wikipedia.failed,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 86 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,420] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.failed-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 87 (state.change.logger)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,420] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.failed,partition=0,error_code=0},{topic=wikipedia.failed,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 87 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,420] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.failed-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 87 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,420] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 87 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,421] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 88 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,427] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition wikipedia.failed-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:04:56,428] INFO [Log partition=wikipedia.failed-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[36;1mconnect                        |[0m 	retries = 10
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,418] INFO [Controller id=2] New topics: [Set(WIKIPEDIABOT)], deleted topics: [Set()], new partition replica assignment [Map(WIKIPEDIABOT-1 -> Vector(2, 1), WIKIPEDIABOT-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	retry.backoff.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,418] INFO [Controller id=2] New partition creation callback for WIKIPEDIABOT-1,WIKIPEDIABOT-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,418] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIABOT-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,418] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIABOT-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,419] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIABOT-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,419] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIABOT-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,419] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIABOT-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,419] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIABOT-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,429] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIABOT-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,429] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIABOT-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,429] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition WIKIPEDIABOT-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,429] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition WIKIPEDIABOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,429] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition WIKIPEDIABOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,429] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition WIKIPEDIABOT-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition WIKIPEDIABOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition WIKIPEDIABOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIABOT-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIABOT-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 88 from controller 2 epoch 1 for partition WIKIPEDIABOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIABOT-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIABOT-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,430] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 88 from controller 2 epoch 1 for partition WIKIPEDIABOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,454] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=WIKIPEDIABOT,partition=1,error_code=0},{topic=WIKIPEDIABOT,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 89 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,454] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 88 from controller 2 epoch 1 starting the become-leader transition for partition WIKIPEDIABOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,455] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(WIKIPEDIABOT-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,456] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 90 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,457] INFO [Log partition=WIKIPEDIABOT-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,457] INFO [Log partition=WIKIPEDIABOT-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,458] INFO Created log for partition WIKIPEDIABOT-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,311] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,458] INFO [Partition WIKIPEDIABOT-1 broker=2] No checkpointed highwatermark is found for partition WIKIPEDIABOT-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,404] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,458] INFO Replica loaded for partition WIKIPEDIABOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,404] INFO Kafka startTimeMs: 1590005155311 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,458] INFO Replica loaded for partition WIKIPEDIABOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,458] INFO [Partition WIKIPEDIABOT-1 broker=2] WIKIPEDIABOT-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,407] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,408] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,496] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 88 for partition WIKIPEDIABOT-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,408] INFO Kafka startTimeMs: 1590005155407 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,496] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 88 from controller 2 epoch 1 for the become-leader transition for partition WIKIPEDIABOT-1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,407] INFO interceptor=confluent.monitoring.interceptor.replicate-topic-0 created for client_id=replicate-topic-0 client_type=CONSUMER session= cluster=lbUe4hq7QeWfnY0W4R-PhA group=connect-replicator (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,496] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 88 from controller 2 epoch 1 starting the become-follower transition for partition WIKIPEDIABOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,408] INFO interceptor=confluent.monitoring.interceptor.connect-worker-producer created for client_id=connect-worker-producer client_type=PRODUCER session= cluster=lbUe4hq7QeWfnY0W4R-PhA (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,497] INFO Replica loaded for partition WIKIPEDIABOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,499] INFO [Producer clientId=confluent.monitoring.interceptor.replicate-topic-0] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,499] INFO [Log partition=WIKIPEDIABOT-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,501] INFO [Producer clientId=confluent.monitoring.interceptor.connect-worker-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,499] INFO [Log partition=WIKIPEDIABOT-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,606] INFO creating interceptor (io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,500] INFO Created log for partition WIKIPEDIABOT-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,500] INFO [Partition WIKIPEDIABOT-0 broker=2] No checkpointed highwatermark is found for partition WIKIPEDIABOT-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,609] INFO MonitoringInterceptorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,500] INFO Replica loaded for partition WIKIPEDIABOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,500] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(WIKIPEDIABOT-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[36;1mconnect                        |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,501] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 88 for partition WIKIPEDIABOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:55,610] INFO ProducerConfig values: 
[36;1mconnect                        |[0m 	acks = all
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,501] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition WIKIPEDIABOT-0 as part of become-follower request with correlation id 88 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	batch.size = 16384
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,501] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(WIKIPEDIABOT-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,501] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 88 for partition WIKIPEDIABOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,501] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 88 from controller 2 epoch 1 for the become-follower transition for partition WIKIPEDIABOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = confluent.monitoring.interceptor.connect-worker-producer
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,502] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=WIKIPEDIABOT,partition=1,error_code=0},{topic=WIKIPEDIABOT,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 88 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	compression.type = lz4
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,502] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition WIKIPEDIABOT-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 89 (state.change.logger)
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[36;1mconnect                        |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,502] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition WIKIPEDIABOT-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 89 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,503] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 89 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,595] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition WIKIPEDIABOT-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	interceptor.classes = []
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:05:02,595] INFO [Log partition=WIKIPEDIABOT-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,413] INFO [Controller id=2] New topics: [Set(WIKIPEDIANOBOT)], deleted topics: [Set()], new partition replica assignment [Map(WIKIPEDIANOBOT-1 -> Vector(2, 1), WIKIPEDIANOBOT-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	linger.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] INFO [Controller id=2] New partition creation callback for WIKIPEDIANOBOT-1,WIKIPEDIANOBOT-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	max.block.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIANOBOT-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIANOBOT-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIANOBOT-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m 	metric.reporters = []
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIANOBOT-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIANOBOT-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,414] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIANOBOT-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,426] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIANOBOT-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,426] TRACE [Controller id=2 epoch=1] Changed partition WIKIPEDIANOBOT-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,426] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition WIKIPEDIANOBOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,426] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition WIKIPEDIANOBOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	retries = 10
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,426] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition WIKIPEDIANOBOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	retry.backoff.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,426] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition WIKIPEDIANOBOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition WIKIPEDIANOBOT-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition WIKIPEDIANOBOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIANOBOT-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition WIKIPEDIANOBOT-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIANOBOT-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition WIKIPEDIANOBOT-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 90 from controller 2 epoch 1 for partition WIKIPEDIANOBOT-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,427] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 90 from controller 2 epoch 1 for partition WIKIPEDIANOBOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,428] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 90 from controller 2 epoch 1 starting the become-leader transition for partition WIKIPEDIANOBOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,428] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(WIKIPEDIANOBOT-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,431] INFO [Log partition=WIKIPEDIANOBOT-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,431] INFO [Log partition=WIKIPEDIANOBOT-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,431] INFO Created log for partition WIKIPEDIANOBOT-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,432] INFO [Partition WIKIPEDIANOBOT-1 broker=2] No checkpointed highwatermark is found for partition WIKIPEDIANOBOT-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,432] INFO Replica loaded for partition WIKIPEDIANOBOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,432] INFO Replica loaded for partition WIKIPEDIANOBOT-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,432] INFO [Partition WIKIPEDIANOBOT-1 broker=2] WIKIPEDIANOBOT-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,435] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 90 for partition WIKIPEDIANOBOT-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,435] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 90 from controller 2 epoch 1 for the become-leader transition for partition WIKIPEDIANOBOT-1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,435] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 90 from controller 2 epoch 1 starting the become-follower transition for partition WIKIPEDIANOBOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,435] INFO Replica loaded for partition WIKIPEDIANOBOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,437] INFO [Log partition=WIKIPEDIANOBOT-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,437] INFO [Log partition=WIKIPEDIANOBOT-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] INFO Created log for partition WIKIPEDIANOBOT-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] INFO [Partition WIKIPEDIANOBOT-0 broker=2] No checkpointed highwatermark is found for partition WIKIPEDIANOBOT-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] INFO Replica loaded for partition WIKIPEDIANOBOT-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(WIKIPEDIANOBOT-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 90 for partition WIKIPEDIANOBOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition WIKIPEDIANOBOT-0 as part of become-follower request with correlation id 90 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(WIKIPEDIANOBOT-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 90 for partition WIKIPEDIANOBOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,438] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 90 from controller 2 epoch 1 for the become-follower transition for partition WIKIPEDIANOBOT-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,439] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=WIKIPEDIANOBOT,partition=0,error_code=0},{topic=WIKIPEDIANOBOT,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 90 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:56,605] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,440] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=WIKIPEDIANOBOT,partition=0,error_code=0},{topic=WIKIPEDIANOBOT,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 91 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:56,605] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,440] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition WIKIPEDIANOBOT-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 91 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,440] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition WIKIPEDIANOBOT-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 91 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:56,605] INFO Kafka startTimeMs: 1590005156605 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,440] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 91 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:05:56,605] WARN Error registering AppInfo mbean (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,441] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 92 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=confluent.monitoring.interceptor.connect-worker-producer
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,930] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition WIKIPEDIANOBOT-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
[34;1mkafka2                         |[0m [2020-05-20 20:05:08,930] INFO [Log partition=WIKIPEDIANOBOT-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,498] INFO [Controller id=2] New topics: [Set(EN_WIKIPEDIA_GT_1)], deleted topics: [Set()], new partition replica assignment [Map(EN_WIKIPEDIA_GT_1-1 -> Vector(2, 1), EN_WIKIPEDIA_GT_1-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,498] INFO [Controller id=2] New partition creation callback for EN_WIKIPEDIA_GT_1-1,EN_WIKIPEDIA_GT_1-0 (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,498] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,498] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,499] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:427)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,499] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:270)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,499] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at io.confluent.monitoring.clients.interceptor.MonitoringInterceptor.create(MonitoringInterceptor.java:88)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,499] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	at io.confluent.monitoring.clients.interceptor.MonitoringInterceptor.createForProducer(MonitoringInterceptor.java:158)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,504] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,504] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	at io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor.onAcknowledgement(MonitoringProducerInterceptor.java:78)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,504] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.ProducerInterceptors.onAcknowledgement(ProducerInterceptors.java:88)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1316)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:227)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:196)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,504] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:707)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,504] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:688)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,504] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:596)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender.access$100(Sender.java:74)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender$1.onComplete(Sender.java:798)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 92 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:561)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 92 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1-0 (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:553)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:335)
[36;1mconnect                        |[0m 	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:244)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,505] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,506] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 92 from controller 2 epoch 1 starting the become-leader transition for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,506] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1-1) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,509] INFO [Log partition=EN_WIKIPEDIA_GT_1-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,510] INFO [Log partition=EN_WIKIPEDIA_GT_1-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,510] INFO Created log for partition EN_WIKIPEDIA_GT_1-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,511] INFO [Partition EN_WIKIPEDIA_GT_1-1 broker=2] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:05:56,605] INFO interceptor=confluent.monitoring.interceptor.connect-worker-producer created for client_id=connect-worker-producer client_type=PRODUCER session= cluster=lbUe4hq7QeWfnY0W4R-PhA (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,511] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:05:56,705] INFO [Producer clientId=confluent.monitoring.interceptor.connect-worker-producer] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,511] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:06:35,198] INFO creating interceptor (io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,511] INFO [Partition EN_WIKIPEDIA_GT_1-1 broker=2] EN_WIKIPEDIA_GT_1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m [2020-05-20 20:06:35,199] INFO MonitoringInterceptorConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,513] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 92 for partition EN_WIKIPEDIA_GT_1-1 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.publishMs = 15000
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,513] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 92 from controller 2 epoch 1 for the become-leader transition for partition EN_WIKIPEDIA_GT_1-1 (state.change.logger)
[36;1mconnect                        |[0m 	confluent.monitoring.interceptor.topic = _confluent-monitoring
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,513] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 92 from controller 2 epoch 1 starting the become-follower transition for partition EN_WIKIPEDIA_GT_1-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m  (io.confluent.monitoring.clients.interceptor.MonitoringInterceptorConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,514] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m [2020-05-20 20:06:35,199] INFO ProducerConfig values: 
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,517] INFO [Log partition=EN_WIKIPEDIA_GT_1-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	acks = all
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,517] INFO [Log partition=EN_WIKIPEDIA_GT_1-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	batch.size = 16384
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,518] INFO Created log for partition EN_WIKIPEDIA_GT_1-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	bootstrap.servers = [kafka1:9091, kafka2:9092]
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,518] INFO [Partition EN_WIKIPEDIA_GT_1-0 broker=2] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	buffer.memory = 33554432
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,518] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,519] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	client.dns.lookup = default
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,519] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 92 for partition EN_WIKIPEDIA_GT_1-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	client.id = confluent.monitoring.interceptor.connector-consumer-elasticsearch-ksql-0
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,519] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition EN_WIKIPEDIA_GT_1-0 as part of become-follower request with correlation id 92 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	compression.type = lz4
[36;1mconnect                        |[0m 	connections.max.idle.ms = 540000
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,519] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(EN_WIKIPEDIA_GT_1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	delivery.timeout.ms = 120000
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,519] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 92 for partition EN_WIKIPEDIA_GT_1-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	enable.idempotence = false
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,519] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 92 from controller 2 epoch 1 for the become-follower transition for partition EN_WIKIPEDIA_GT_1-0 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	interceptor.classes = []
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,520] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=EN_WIKIPEDIA_GT_1,partition=1,error_code=0},{topic=EN_WIKIPEDIA_GT_1,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 92 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,521] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 93 (state.change.logger)
[36;1mconnect                        |[0m 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,521] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 93 (state.change.logger)
[36;1mconnect                        |[0m 	linger.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,521] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 93 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	max.block.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,524] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=EN_WIKIPEDIA_GT_1,partition=1,error_code=0},{topic=EN_WIKIPEDIA_GT_1,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 93 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	max.in.flight.requests.per.connection = 1
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,525] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 94 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m 	max.request.size = 10485760
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,749] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition EN_WIKIPEDIA_GT_1-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m 	metadata.max.age.ms = 300000
[36;1mconnect                        |[0m 	metric.reporters = []
[34;1mkafka2                         |[0m [2020-05-20 20:05:14,749] INFO [Log partition=EN_WIKIPEDIA_GT_1-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m 	metrics.num.samples = 2
[36;1mconnect                        |[0m 	metrics.recording.level = INFO
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,618] INFO [Controller id=2] New topics: [Set(EN_WIKIPEDIA_GT_1_COUNTS)], deleted topics: [Set()], new partition replica assignment [Map(EN_WIKIPEDIA_GT_1_COUNTS-1 -> Vector(1, 2), EN_WIKIPEDIA_GT_1_COUNTS-0 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] INFO [Controller id=2] New partition creation callback for EN_WIKIPEDIA_GT_1_COUNTS-1,EN_WIKIPEDIA_GT_1_COUNTS-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1_COUNTS-1 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1_COUNTS-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m 	receive.buffer.bytes = 32768
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.max.ms = 1000
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	reconnect.backoff.ms = 50
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,619] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 from NonExistentReplica to NewReplica (state.change.logger)
[36;1mconnect                        |[0m 	request.timeout.ms = 30000
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,627] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1_COUNTS-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	retries = 10
[36;1mconnect                        |[0m 	retry.backoff.ms = 500
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,627] TRACE [Controller id=2 epoch=1] Changed partition EN_WIKIPEDIA_GT_1_COUNTS-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[36;1mconnect                        |[0m 	sasl.client.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.jaas.config = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.service.name = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36;1mconnect                        |[0m 	sasl.login.callback.handler.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.class = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 from NewReplica to OnlineReplica (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.buffer.seconds = 300
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 94 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.min.period.seconds = 60
[36;1mconnect                        |[0m 	sasl.login.refresh.window.factor = 0.8
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 94 from controller 2 epoch 1 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (state.change.logger)
[36;1mconnect                        |[0m 	sasl.login.refresh.window.jitter = 0.05
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,629] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 94 from controller 2 epoch 1 starting the become-leader transition for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,630] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1_COUNTS-0) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	sasl.mechanism = PLAIN
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,632] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	security.protocol = SASL_SSL
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,632] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36;1mconnect                        |[0m 	send.buffer.bytes = 131072
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,633] INFO Created log for partition EN_WIKIPEDIA_GT_1_COUNTS-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.cipher.suites = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,633] INFO [Partition EN_WIKIPEDIA_GT_1_COUNTS-0 broker=2] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,633] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.endpoint.identification.algorithm = https
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,633] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-0 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.key.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,633] INFO [Partition EN_WIKIPEDIA_GT_1_COUNTS-0 broker=2] EN_WIKIPEDIA_GT_1_COUNTS-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,636] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 94 for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (last update controller epoch 1) (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.location = /etc/kafka/secrets/kafka.connect.keystore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,636] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 94 from controller 2 epoch 1 for the become-leader transition for partition EN_WIKIPEDIA_GT_1_COUNTS-0 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 94 from controller 2 epoch 1 starting the become-follower transition for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.keystore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,636] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.protocol = TLS
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,638] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36;1mconnect                        |[0m 	ssl.provider = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,639] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,639] INFO Created log for partition EN_WIKIPEDIA_GT_1_COUNTS-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36;1mconnect                        |[0m 	ssl.secure.random.implementation = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] INFO [Partition EN_WIKIPEDIA_GT_1_COUNTS-1 broker=2] No checkpointed highwatermark is found for partition EN_WIKIPEDIA_GT_1_COUNTS-1 (kafka.cluster.Partition)
[36;1mconnect                        |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] INFO Replica loaded for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with initial high watermark 0 (kafka.cluster.Replica)
[36;1mconnect                        |[0m 	ssl.truststore.location = /etc/kafka/secrets/kafka.connect.truststore.jks
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(EN_WIKIPEDIA_GT_1_COUNTS-1) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	ssl.truststore.password = [hidden]
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 94 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	ssl.truststore.type = JKS
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition EN_WIKIPEDIA_GT_1_COUNTS-1 as part of become-follower request with correlation id 94 from controller 2 epoch 1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	transaction.timeout.ms = 60000
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(EN_WIKIPEDIA_GT_1_COUNTS-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[36;1mconnect                        |[0m 	transactional.id = null
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 94 for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,640] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 94 from controller 2 epoch 1 for the become-follower transition for partition EN_WIKIPEDIA_GT_1_COUNTS-1 with leader 1 (state.change.logger)
[36;1mconnect                        |[0m  (org.apache.kafka.clients.producer.ProducerConfig)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,641] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=EN_WIKIPEDIA_GT_1_COUNTS,partition=0,error_code=0},{topic=EN_WIKIPEDIA_GT_1_COUNTS,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 94 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:37,294] INFO Kafka version: 5.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,641] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=EN_WIKIPEDIA_GT_1_COUNTS,partition=0,error_code=0},{topic=EN_WIKIPEDIA_GT_1_COUNTS,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 95 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:37,295] INFO Kafka commitId: 03799faf9878a999 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,642] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1_COUNTS-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 95 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:37,296] INFO Kafka startTimeMs: 1590005197294 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,642] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition EN_WIKIPEDIA_GT_1_COUNTS-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 95 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:37,297] INFO interceptor=confluent.monitoring.interceptor.connector-consumer-elasticsearch-ksql-0 created for client_id=connector-consumer-elasticsearch-ksql-0 client_type=CONSUMER session= cluster=lbUe4hq7QeWfnY0W4R-PhA group=connect-elasticsearch-ksql (io.confluent.monitoring.clients.interceptor.MonitoringInterceptor)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,642] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 95 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:37,596] INFO [Producer clientId=confluent.monitoring.interceptor.connector-consumer-elasticsearch-ksql-0] Cluster ID: lbUe4hq7QeWfnY0W4R-PhA (org.apache.kafka.clients.Metadata)
[36;1mconnect                        |[0m [2020-05-20 20:06:40,304] INFO WorkerSourceTask{id=wikipedia-irc-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,642] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 96 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:40,308] INFO WorkerSourceTask{id=wikipedia-irc-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,731] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition EN_WIKIPEDIA_GT_1_COUNTS-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[36;1mconnect                        |[0m [2020-05-20 20:06:40,609] INFO WorkerSourceTask{id=wikipedia-irc-0} Finished commitOffsets successfully in 301 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:20,731] INFO [Log partition=EN_WIKIPEDIA_GT_1_COUNTS-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[36;1mconnect                        |[0m [2020-05-20 20:06:44,197] INFO WorkerSinkTask{id=elasticsearch-ksql-0} Committing offsets asynchronously using sequence number 1: {WIKIPEDIABOT-1=OffsetAndMetadata{offset=11, leaderEpoch=null, metadata=''}, WIKIPEDIABOT-0=OffsetAndMetadata{offset=21, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,598] INFO Creating topic connect-offsets with configuration {cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1, 2), 8 -> ArrayBuffer(2, 1), 17 -> ArrayBuffer(1, 2), 11 -> ArrayBuffer(1, 2), 2 -> ArrayBuffer(2, 1), 20 -> ArrayBuffer(2, 1), 5 -> ArrayBuffer(1, 2), 14 -> ArrayBuffer(2, 1), 4 -> ArrayBuffer(2, 1), 13 -> ArrayBuffer(1, 2), 22 -> ArrayBuffer(2, 1), 7 -> ArrayBuffer(1, 2), 16 -> ArrayBuffer(2, 1), 10 -> ArrayBuffer(2, 1), 1 -> ArrayBuffer(1, 2), 19 -> ArrayBuffer(1, 2), 9 -> ArrayBuffer(1, 2), 18 -> ArrayBuffer(2, 1), 12 -> ArrayBuffer(2, 1), 3 -> ArrayBuffer(1, 2), 21 -> ArrayBuffer(1, 2), 15 -> ArrayBuffer(1, 2), 6 -> ArrayBuffer(2, 1), 24 -> ArrayBuffer(2, 1), 0 -> ArrayBuffer(2, 1)) (kafka.zk.AdminZkClient)
[36;1mconnect                        |[0m [2020-05-20 20:06:49,532] INFO WorkerSourceTask{id=replicate-topic-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] INFO [Controller id=2] New topics: [Set(connect-offsets)], deleted topics: [Set()], new partition replica assignment [Map(connect-offsets-20 -> Vector(2, 1), connect-offsets-7 -> Vector(1, 2), connect-offsets-24 -> Vector(2, 1), connect-offsets-16 -> Vector(2, 1), connect-offsets-3 -> Vector(1, 2), connect-offsets-21 -> Vector(1, 2), connect-offsets-11 -> Vector(1, 2), connect-offsets-6 -> Vector(2, 1), connect-offsets-17 -> Vector(1, 2), connect-offsets-10 -> Vector(2, 1), connect-offsets-2 -> Vector(2, 1), connect-offsets-18 -> Vector(2, 1), connect-offsets-23 -> Vector(1, 2), connect-offsets-15 -> Vector(1, 2), connect-offsets-4 -> Vector(2, 1), connect-offsets-12 -> Vector(2, 1), connect-offsets-5 -> Vector(1, 2), connect-offsets-13 -> Vector(1, 2), connect-offsets-14 -> Vector(2, 1), connect-offsets-0 -> Vector(2, 1), connect-offsets-8 -> Vector(2, 1), connect-offsets-9 -> Vector(1, 2), connect-offsets-1 -> Vector(1, 2), connect-offsets-19 -> Vector(1, 2), connect-offsets-22 -> Vector(2, 1))] (kafka.controller.KafkaController)
[36;1mconnect                        |[0m [2020-05-20 20:06:49,533] INFO WorkerSourceTask{id=replicate-topic-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] INFO [Controller id=2] New partition creation callback for connect-offsets-20,connect-offsets-7,connect-offsets-24,connect-offsets-16,connect-offsets-3,connect-offsets-21,connect-offsets-11,connect-offsets-6,connect-offsets-17,connect-offsets-10,connect-offsets-2,connect-offsets-18,connect-offsets-23,connect-offsets-15,connect-offsets-4,connect-offsets-12,connect-offsets-5,connect-offsets-13,connect-offsets-14,connect-offsets-0,connect-offsets-8,connect-offsets-9,connect-offsets-1,connect-offsets-19,connect-offsets-22 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-20 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:06:49,544] INFO WorkerSourceTask{id=replicate-topic-0} Finished commitOffsets successfully in 12 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-7 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:40,609] INFO WorkerSourceTask{id=wikipedia-irc-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-24 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:40,609] INFO WorkerSourceTask{id=wikipedia-irc-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-16 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:40,612] INFO WorkerSourceTask{id=wikipedia-irc-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:44,197] INFO WorkerSinkTask{id=elasticsearch-ksql-0} Committing offsets asynchronously using sequence number 2: {WIKIPEDIABOT-1=OffsetAndMetadata{offset=35, leaderEpoch=null, metadata=''}, WIKIPEDIABOT-0=OffsetAndMetadata{offset=115, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-21 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:49,545] INFO WorkerSourceTask{id=replicate-topic-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-11 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:49,545] INFO WorkerSourceTask{id=replicate-topic-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-6 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:07:49,549] INFO WorkerSourceTask{id=replicate-topic-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-17 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:08:40,612] INFO WorkerSourceTask{id=wikipedia-irc-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-10 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:08:40,612] INFO WorkerSourceTask{id=wikipedia-irc-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:08:40,615] INFO WorkerSourceTask{id=wikipedia-irc-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,605] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-18 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:08:44,197] INFO WorkerSinkTask{id=elasticsearch-ksql-0} Committing offsets asynchronously using sequence number 3: {WIKIPEDIABOT-1=OffsetAndMetadata{offset=63, leaderEpoch=null, metadata=''}, WIKIPEDIABOT-0=OffsetAndMetadata{offset=221, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask)
[36;1mconnect                        |[0m [2020-05-20 20:08:49,550] INFO WorkerSourceTask{id=replicate-topic-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-23 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:08:49,550] INFO WorkerSourceTask{id=replicate-topic-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-15 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:08:49,554] INFO WorkerSourceTask{id=replicate-topic-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect                        |[0m [2020-05-20 20:09:40,615] INFO WorkerSourceTask{id=wikipedia-irc-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:09:40,615] INFO WorkerSourceTask{id=wikipedia-irc-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[36;1mconnect                        |[0m [2020-05-20 20:09:40,618] INFO WorkerSourceTask{id=wikipedia-irc-0} Finished commitOffsets successfully in 3 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-12 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:09:44,197] INFO WorkerSinkTask{id=elasticsearch-ksql-0} Committing offsets asynchronously using sequence number 4: {WIKIPEDIABOT-1=OffsetAndMetadata{offset=89, leaderEpoch=null, metadata=''}, WIKIPEDIABOT-0=OffsetAndMetadata{offset=347, leaderEpoch=null, metadata=''}} (org.apache.kafka.connect.runtime.WorkerSinkTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-5 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:09:49,554] INFO WorkerSourceTask{id=replicate-topic-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-13 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:09:49,554] INFO WorkerSourceTask{id=replicate-topic-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-14 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[36;1mconnect                        |[0m [2020-05-20 20:09:49,558] INFO WorkerSourceTask{id=replicate-topic-0} Finished commitOffsets successfully in 4 ms (org.apache.kafka.connect.runtime.WorkerSourceTask)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-8 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-9 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-19 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-22 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,606] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-21 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-16 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-15 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-2 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-10 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-18 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-6 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-19 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-5 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-14 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-24 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-7 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-11 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-3 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-12 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-17 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-13 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-4 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-9 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-23 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-8 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-20 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,607] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-22 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-20 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-24 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-16 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-21 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-17 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-18 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-23 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-15 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,626] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-12 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-13 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-14 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-19 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Changed partition connect-offsets-22 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-15 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-23 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-9 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-17 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-11 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-19 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-5 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-24 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-13 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-offsets-7 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-15 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-23 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-9 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-17 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,627] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-11 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-19 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-5 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-24 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-13 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-offsets-7 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-15 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-23 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-9 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-17 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-11 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-19 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-5 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-13 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-24 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-24 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,628] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-offsets-7 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-9 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-7 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-13 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-11 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-5 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-23 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-17 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-15 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-21 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 96 from controller 2 epoch 1 for partition connect-offsets-19 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-9 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-3 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-8 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-4 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-10 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-15 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-6 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-11 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-5 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-2 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-12 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-18 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-23 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-22 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-20 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-13 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-17 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-24 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-14 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-19 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-7 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-21 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,629] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-offsets-16 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-21 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-16 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-15 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-2 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-10 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-18 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-6 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-19 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-5 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-14 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-24 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-7 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-11 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-3 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-12 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-17 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-13 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-4 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-9 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-23 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-8 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-20 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,630] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-offsets-22 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-24 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-leader transition for partition connect-offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,636] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(connect-offsets-20, connect-offsets-24, connect-offsets-16, connect-offsets-6, connect-offsets-10, connect-offsets-2, connect-offsets-18, connect-offsets-4, connect-offsets-12, connect-offsets-14, connect-offsets-0, connect-offsets-8, connect-offsets-22) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,697] INFO [Log partition=connect-offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,697] INFO [Log partition=connect-offsets-8, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,698] INFO Created log for partition connect-offsets-8 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,698] INFO [Partition connect-offsets-8 broker=2] No checkpointed highwatermark is found for partition connect-offsets-8 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,698] INFO Replica loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,698] INFO Replica loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,698] INFO [Partition connect-offsets-8 broker=2] connect-offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,701] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-8 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,703] INFO [Log partition=connect-offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,703] INFO [Log partition=connect-offsets-24, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,704] INFO Created log for partition connect-offsets-24 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,704] INFO [Partition connect-offsets-24 broker=2] No checkpointed highwatermark is found for partition connect-offsets-24 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,704] INFO Replica loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,704] INFO Replica loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,704] INFO [Partition connect-offsets-24 broker=2] connect-offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,707] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-24 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,709] INFO [Log partition=connect-offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,710] INFO [Log partition=connect-offsets-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,710] INFO Created log for partition connect-offsets-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,711] INFO [Partition connect-offsets-2 broker=2] No checkpointed highwatermark is found for partition connect-offsets-2 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,711] INFO Replica loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,711] INFO Replica loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,711] INFO [Partition connect-offsets-2 broker=2] connect-offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,713] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-2 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,716] INFO [Log partition=connect-offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,716] INFO [Log partition=connect-offsets-18, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,716] INFO Created log for partition connect-offsets-18 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,717] INFO [Partition connect-offsets-18 broker=2] No checkpointed highwatermark is found for partition connect-offsets-18 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,717] INFO Replica loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,717] INFO Replica loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,717] INFO [Partition connect-offsets-18 broker=2] connect-offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,720] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-18 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,723] INFO [Log partition=connect-offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,723] INFO [Log partition=connect-offsets-12, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,724] INFO Created log for partition connect-offsets-12 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,724] INFO [Partition connect-offsets-12 broker=2] No checkpointed highwatermark is found for partition connect-offsets-12 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,724] INFO Replica loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,724] INFO Replica loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,724] INFO [Partition connect-offsets-12 broker=2] connect-offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,727] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-12 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,730] INFO [Log partition=connect-offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,730] INFO [Log partition=connect-offsets-6, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,730] INFO Created log for partition connect-offsets-6 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,731] INFO [Partition connect-offsets-6 broker=2] No checkpointed highwatermark is found for partition connect-offsets-6 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,731] INFO Replica loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,731] INFO Replica loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,731] INFO [Partition connect-offsets-6 broker=2] connect-offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,733] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-6 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,735] INFO [Log partition=connect-offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,735] INFO [Log partition=connect-offsets-22, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,736] INFO Created log for partition connect-offsets-22 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,736] INFO [Partition connect-offsets-22 broker=2] No checkpointed highwatermark is found for partition connect-offsets-22 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,736] INFO Replica loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,736] INFO Replica loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,736] INFO [Partition connect-offsets-22 broker=2] connect-offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,739] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-22 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,795] INFO [Log partition=connect-offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,795] INFO [Log partition=connect-offsets-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,795] INFO Created log for partition connect-offsets-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,796] INFO [Partition connect-offsets-0 broker=2] No checkpointed highwatermark is found for partition connect-offsets-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,797] INFO Replica loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,797] INFO Replica loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,797] INFO [Partition connect-offsets-0 broker=2] connect-offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,800] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,801] INFO [Log partition=connect-offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,802] INFO [Log partition=connect-offsets-16, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,802] INFO Created log for partition connect-offsets-16 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,803] INFO [Partition connect-offsets-16 broker=2] No checkpointed highwatermark is found for partition connect-offsets-16 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,803] INFO Replica loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,803] INFO Replica loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,803] INFO [Partition connect-offsets-16 broker=2] connect-offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,806] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-16 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,809] INFO [Log partition=connect-offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,810] INFO [Log partition=connect-offsets-10, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,810] INFO Created log for partition connect-offsets-10 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,811] INFO [Partition connect-offsets-10 broker=2] No checkpointed highwatermark is found for partition connect-offsets-10 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,811] INFO Replica loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,811] INFO Replica loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,811] INFO [Partition connect-offsets-10 broker=2] connect-offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,813] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-10 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,815] INFO [Log partition=connect-offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,815] INFO [Log partition=connect-offsets-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,816] INFO Created log for partition connect-offsets-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,816] INFO [Partition connect-offsets-4 broker=2] No checkpointed highwatermark is found for partition connect-offsets-4 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,816] INFO Replica loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,816] INFO Replica loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,816] INFO [Partition connect-offsets-4 broker=2] connect-offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,819] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-4 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,821] INFO [Log partition=connect-offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,821] INFO [Log partition=connect-offsets-14, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,822] INFO Created log for partition connect-offsets-14 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,822] INFO [Partition connect-offsets-14 broker=2] No checkpointed highwatermark is found for partition connect-offsets-14 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,822] INFO Replica loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,822] INFO Replica loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,822] INFO [Partition connect-offsets-14 broker=2] connect-offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,825] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-14 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,826] INFO [Log partition=connect-offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,827] INFO [Log partition=connect-offsets-20, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,827] INFO Created log for partition connect-offsets-20 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,827] INFO [Partition connect-offsets-20 broker=2] No checkpointed highwatermark is found for partition connect-offsets-20 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,827] INFO Replica loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,827] INFO Replica loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,827] INFO [Partition connect-offsets-20 broker=2] connect-offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-20 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-8 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-24 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-18 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-12 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-6 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-22 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-16 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-10 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-14 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-leader transition for partition connect-offsets-20 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-5 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-21 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-15 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-9 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-3 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-19 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-13 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-7 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-17 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-23 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-11 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 96 from controller 2 epoch 1 starting the become-follower transition for partition connect-offsets-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,830] INFO Replica loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,832] INFO [Log partition=connect-offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,832] INFO [Log partition=connect-offsets-5, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,832] INFO Created log for partition connect-offsets-5 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,833] INFO [Partition connect-offsets-5 broker=2] No checkpointed highwatermark is found for partition connect-offsets-5 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,833] INFO Replica loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,833] INFO Replica loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,834] INFO [Log partition=connect-offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,835] INFO [Log partition=connect-offsets-21, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,835] INFO Created log for partition connect-offsets-21 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,836] INFO [Partition connect-offsets-21 broker=2] No checkpointed highwatermark is found for partition connect-offsets-21 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,836] INFO Replica loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,836] INFO Replica loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,837] INFO [Log partition=connect-offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,838] INFO [Log partition=connect-offsets-15, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,838] INFO Created log for partition connect-offsets-15 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,838] INFO [Partition connect-offsets-15 broker=2] No checkpointed highwatermark is found for partition connect-offsets-15 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,838] INFO Replica loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,838] INFO Replica loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,840] INFO [Log partition=connect-offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,840] INFO [Log partition=connect-offsets-9, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,841] INFO Created log for partition connect-offsets-9 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,841] INFO [Partition connect-offsets-9 broker=2] No checkpointed highwatermark is found for partition connect-offsets-9 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,841] INFO Replica loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,841] INFO Replica loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,843] INFO [Log partition=connect-offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,843] INFO [Log partition=connect-offsets-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,844] INFO Created log for partition connect-offsets-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,844] INFO [Partition connect-offsets-3 broker=2] No checkpointed highwatermark is found for partition connect-offsets-3 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,895] INFO Replica loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,895] INFO Replica loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,897] INFO [Log partition=connect-offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,897] INFO [Log partition=connect-offsets-19, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,897] INFO Created log for partition connect-offsets-19 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,898] INFO [Partition connect-offsets-19 broker=2] No checkpointed highwatermark is found for partition connect-offsets-19 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,898] INFO Replica loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,898] INFO Replica loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,900] INFO [Log partition=connect-offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,900] INFO [Log partition=connect-offsets-13, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,900] INFO Created log for partition connect-offsets-13 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,901] INFO [Partition connect-offsets-13 broker=2] No checkpointed highwatermark is found for partition connect-offsets-13 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,901] INFO Replica loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,901] INFO Replica loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,906] INFO [Log partition=connect-offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,906] INFO [Log partition=connect-offsets-7, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,907] INFO Created log for partition connect-offsets-7 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,907] INFO [Partition connect-offsets-7 broker=2] No checkpointed highwatermark is found for partition connect-offsets-7 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,907] INFO Replica loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,907] INFO Replica loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,909] INFO [Log partition=connect-offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,910] INFO [Log partition=connect-offsets-17, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,910] INFO Created log for partition connect-offsets-17 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,910] INFO [Partition connect-offsets-17 broker=2] No checkpointed highwatermark is found for partition connect-offsets-17 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,910] INFO Replica loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,911] INFO Replica loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,913] INFO [Log partition=connect-offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,914] INFO [Log partition=connect-offsets-23, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,914] INFO Created log for partition connect-offsets-23 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,914] INFO [Partition connect-offsets-23 broker=2] No checkpointed highwatermark is found for partition connect-offsets-23 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,914] INFO Replica loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,914] INFO Replica loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,916] INFO [Log partition=connect-offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,916] INFO [Log partition=connect-offsets-11, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,917] INFO Created log for partition connect-offsets-11 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,917] INFO [Partition connect-offsets-11 broker=2] No checkpointed highwatermark is found for partition connect-offsets-11 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,917] INFO Replica loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,917] INFO Replica loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,919] INFO [Log partition=connect-offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,919] INFO [Log partition=connect-offsets-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,919] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=connect-offsets,partition=10,error_code=0},{topic=connect-offsets,partition=8,error_code=0},{topic=connect-offsets,partition=14,error_code=0},{topic=connect-offsets,partition=12,error_code=0},{topic=connect-offsets,partition=2,error_code=0},{topic=connect-offsets,partition=0,error_code=0},{topic=connect-offsets,partition=6,error_code=0},{topic=connect-offsets,partition=4,error_code=0},{topic=connect-offsets,partition=24,error_code=0},{topic=connect-offsets,partition=18,error_code=0},{topic=connect-offsets,partition=16,error_code=0},{topic=connect-offsets,partition=22,error_code=0},{topic=connect-offsets,partition=20,error_code=0},{topic=connect-offsets,partition=9,error_code=0},{topic=connect-offsets,partition=7,error_code=0},{topic=connect-offsets,partition=13,error_code=0},{topic=connect-offsets,partition=11,error_code=0},{topic=connect-offsets,partition=1,error_code=0},{topic=connect-offsets,partition=5,error_code=0},{topic=connect-offsets,partition=3,error_code=0},{topic=connect-offsets,partition=23,error_code=0},{topic=connect-offsets,partition=17,error_code=0},{topic=connect-offsets,partition=15,error_code=0},{topic=connect-offsets,partition=21,error_code=0},{topic=connect-offsets,partition=19,error_code=0}]} for request LEADER_AND_ISR with correlation id 97 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,919] INFO Created log for partition connect-offsets-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] INFO [Partition connect-offsets-1 broker=2] No checkpointed highwatermark is found for partition connect-offsets-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] INFO Replica loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(connect-offsets-7, connect-offsets-5, connect-offsets-3, connect-offsets-11, connect-offsets-9, connect-offsets-15, connect-offsets-13, connect-offsets-21, connect-offsets-19, connect-offsets-17, connect-offsets-1, connect-offsets-23) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-23 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-7 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-13 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-19 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-3 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-9 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-15 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-21 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-5 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-11 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-17 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-1 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-23 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-7 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-13 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-19 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-3 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-9 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-15 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-21 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-5 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-11 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,920] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-offsets-17 as part of become-follower request with correlation id 96 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(connect-offsets-7 -> (offset=0, leaderEpoch=0), connect-offsets-3 -> (offset=0, leaderEpoch=0), connect-offsets-21 -> (offset=0, leaderEpoch=0), connect-offsets-11 -> (offset=0, leaderEpoch=0), connect-offsets-17 -> (offset=0, leaderEpoch=0), connect-offsets-23 -> (offset=0, leaderEpoch=0), connect-offsets-15 -> (offset=0, leaderEpoch=0), connect-offsets-5 -> (offset=0, leaderEpoch=0), connect-offsets-13 -> (offset=0, leaderEpoch=0), connect-offsets-9 -> (offset=0, leaderEpoch=0), connect-offsets-1 -> (offset=0, leaderEpoch=0), connect-offsets-19 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-23 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-7 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-13 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-19 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-3 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-9 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-15 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-21 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-5 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-11 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,921] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 96 for partition connect-offsets-17 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-5 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-21 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-15 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-9 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-3 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-19 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-13 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-7 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-17 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-23 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-11 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 96 from controller 2 epoch 1 for the become-follower transition for partition connect-offsets-1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 98 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,922] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=connect-offsets,partition=10,error_code=0},{topic=connect-offsets,partition=8,error_code=0},{topic=connect-offsets,partition=14,error_code=0},{topic=connect-offsets,partition=12,error_code=0},{topic=connect-offsets,partition=2,error_code=0},{topic=connect-offsets,partition=0,error_code=0},{topic=connect-offsets,partition=6,error_code=0},{topic=connect-offsets,partition=4,error_code=0},{topic=connect-offsets,partition=24,error_code=0},{topic=connect-offsets,partition=18,error_code=0},{topic=connect-offsets,partition=16,error_code=0},{topic=connect-offsets,partition=22,error_code=0},{topic=connect-offsets,partition=20,error_code=0},{topic=connect-offsets,partition=9,error_code=0},{topic=connect-offsets,partition=7,error_code=0},{topic=connect-offsets,partition=13,error_code=0},{topic=connect-offsets,partition=11,error_code=0},{topic=connect-offsets,partition=1,error_code=0},{topic=connect-offsets,partition=5,error_code=0},{topic=connect-offsets,partition=3,error_code=0},{topic=connect-offsets,partition=23,error_code=0},{topic=connect-offsets,partition=17,error_code=0},{topic=connect-offsets,partition=15,error_code=0},{topic=connect-offsets,partition=21,error_code=0},{topic=connect-offsets,partition=19,error_code=0}]} for request LEADER_AND_ISR with correlation id 96 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-10 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-8 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-14 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-12 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-6 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-24 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-18 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-16 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-22 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-offsets-20 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-9 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,923] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-7 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-13 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-11 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-5 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-23 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-17 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-15 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-21 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,924] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-offsets-19 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 97 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:24,925] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 97 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,299] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,299] INFO [Log partition=connect-offsets-7, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,299] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,299] INFO [Log partition=connect-offsets-5, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,299] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-3, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-11 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-11, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-9, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-15 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-15, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-13 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-13, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-21 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-21, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-19 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-19, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-17 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-17, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-23 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-23, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-offsets-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:25,300] INFO [Log partition=connect-offsets-1, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,400] INFO Creating topic connect-statuses with configuration {cleanup.policy=compact} and initial partition assignment Map(2 -> ArrayBuffer(1, 2), 4 -> ArrayBuffer(1, 2), 1 -> ArrayBuffer(2, 1), 3 -> ArrayBuffer(2, 1), 0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] INFO [Controller id=2] New topics: [Set(connect-statuses)], deleted topics: [Set()], new partition replica assignment [Map(connect-statuses-3 -> Vector(2, 1), connect-statuses-4 -> Vector(1, 2), connect-statuses-2 -> Vector(1, 2), connect-statuses-0 -> Vector(1, 2), connect-statuses-1 -> Vector(2, 1))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] INFO [Controller id=2] New partition creation callback for connect-statuses-3,connect-statuses-4,connect-statuses-2,connect-statuses-0,connect-statuses-1 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-3 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-4 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-2 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-3 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-4 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-2 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-3 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-2 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-4 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,407] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Changed partition connect-statuses-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-statuses-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,415] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-statuses-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-statuses-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-statuses-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-statuses-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,416] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-statuses-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 98 from controller 2 epoch 1 for partition connect-statuses-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 98 from controller 2 epoch 1 for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 98 from controller 2 epoch 1 for partition connect-statuses-4 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 98 from controller 2 epoch 1 for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-3 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-4 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 98 from controller 2 epoch 1 for partition connect-statuses-2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,440] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-2 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,441] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-statuses-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,441] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-3 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,441] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-2 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,441] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,441] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-4 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,441] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-statuses-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,442] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 98 from controller 2 epoch 1 starting the become-leader transition for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,442] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 98 from controller 2 epoch 1 starting the become-leader transition for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,442] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(connect-statuses-3, connect-statuses-1) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,444] INFO [Log partition=connect-statuses-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,445] INFO [Log partition=connect-statuses-3, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,445] INFO Created log for partition connect-statuses-3 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,446] INFO [Partition connect-statuses-3 broker=2] No checkpointed highwatermark is found for partition connect-statuses-3 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,446] INFO Replica loaded for partition connect-statuses-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,446] INFO Replica loaded for partition connect-statuses-3 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,446] INFO [Partition connect-statuses-3 broker=2] connect-statuses-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,448] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-3 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,450] INFO [Log partition=connect-statuses-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,450] INFO [Log partition=connect-statuses-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,451] INFO Created log for partition connect-statuses-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,451] INFO [Partition connect-statuses-1 broker=2] No checkpointed highwatermark is found for partition connect-statuses-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,451] INFO Replica loaded for partition connect-statuses-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,451] INFO Replica loaded for partition connect-statuses-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,451] INFO [Partition connect-statuses-1 broker=2] connect-statuses-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-1 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 98 from controller 2 epoch 1 for the become-leader transition for partition connect-statuses-3 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 98 from controller 2 epoch 1 for the become-leader transition for partition connect-statuses-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 98 from controller 2 epoch 1 starting the become-follower transition for partition connect-statuses-2 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 98 from controller 2 epoch 1 starting the become-follower transition for partition connect-statuses-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 98 from controller 2 epoch 1 starting the become-follower transition for partition connect-statuses-4 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,453] INFO Replica loaded for partition connect-statuses-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,495] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=connect-statuses,partition=0,error_code=0},{topic=connect-statuses,partition=3,error_code=0},{topic=connect-statuses,partition=4,error_code=0},{topic=connect-statuses,partition=1,error_code=0},{topic=connect-statuses,partition=2,error_code=0}]} for request LEADER_AND_ISR with correlation id 99 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,496] INFO [Log partition=connect-statuses-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,496] INFO [Log partition=connect-statuses-2, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,496] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 100 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,496] INFO Created log for partition connect-statuses-2 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,497] INFO [Partition connect-statuses-2 broker=2] No checkpointed highwatermark is found for partition connect-statuses-2 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,497] INFO Replica loaded for partition connect-statuses-2 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,497] INFO Replica loaded for partition connect-statuses-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,499] INFO [Log partition=connect-statuses-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,499] INFO [Log partition=connect-statuses-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,500] INFO Created log for partition connect-statuses-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,500] INFO [Partition connect-statuses-0 broker=2] No checkpointed highwatermark is found for partition connect-statuses-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,500] INFO Replica loaded for partition connect-statuses-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,500] INFO Replica loaded for partition connect-statuses-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,502] INFO [Log partition=connect-statuses-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,502] INFO [Log partition=connect-statuses-4, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] INFO Created log for partition connect-statuses-4 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] INFO [Partition connect-statuses-4 broker=2] No checkpointed highwatermark is found for partition connect-statuses-4 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] INFO Replica loaded for partition connect-statuses-4 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(connect-statuses-2, connect-statuses-0, connect-statuses-4) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-4 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-2 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-statuses-4 as part of become-follower request with correlation id 98 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-statuses-0 as part of become-follower request with correlation id 98 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,503] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-statuses-2 as part of become-follower request with correlation id 98 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(connect-statuses-2 -> (offset=0, leaderEpoch=0), connect-statuses-4 -> (offset=0, leaderEpoch=0), connect-statuses-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-4 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 98 for partition connect-statuses-2 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 98 from controller 2 epoch 1 for the become-follower transition for partition connect-statuses-2 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 98 from controller 2 epoch 1 for the become-follower transition for partition connect-statuses-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 98 from controller 2 epoch 1 for the become-follower transition for partition connect-statuses-4 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,504] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=connect-statuses,partition=0,error_code=0},{topic=connect-statuses,partition=3,error_code=0},{topic=connect-statuses,partition=4,error_code=0},{topic=connect-statuses,partition=1,error_code=0},{topic=connect-statuses,partition=2,error_code=0}]} for request LEADER_AND_ISR with correlation id 98 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,505] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-statuses-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 99 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,505] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-statuses-3 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 99 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,505] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-statuses-4 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 99 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,505] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition connect-statuses-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 99 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,505] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-statuses-2 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 99 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,506] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 99 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,752] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-statuses-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,752] INFO [Log partition=connect-statuses-2, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,752] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-statuses-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,752] INFO [Log partition=connect-statuses-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,752] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-statuses-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:28,752] INFO [Log partition=connect-statuses-4, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,219] INFO Creating topic connect-configs with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,224] INFO [Controller id=2] New topics: [Set(connect-configs)], deleted topics: [Set()], new partition replica assignment [Map(connect-configs-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,224] INFO [Controller id=2] New partition creation callback for connect-configs-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,224] TRACE [Controller id=2 epoch=1] Changed partition connect-configs-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,225] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-configs-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,225] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-configs-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Controller id=2 epoch=1] Changed partition connect-configs-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition connect-configs-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition connect-configs-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition connect-configs-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition connect-configs-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition connect-configs-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,229] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 100 from controller 2 epoch 1 for partition connect-configs-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,230] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 100 from controller 2 epoch 1 starting the become-follower transition for partition connect-configs-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,230] INFO Replica loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,232] INFO [Log partition=connect-configs-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,233] INFO [Log partition=connect-configs-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,233] INFO Created log for partition connect-configs-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,233] INFO [Partition connect-configs-0 broker=2] No checkpointed highwatermark is found for partition connect-configs-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] INFO Replica loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(connect-configs-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 100 for partition connect-configs-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition connect-configs-0 as part of become-follower request with correlation id 100 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(connect-configs-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 100 for partition connect-configs-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,234] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 100 from controller 2 epoch 1 for the become-follower transition for partition connect-configs-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,236] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=connect-configs,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 100 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,237] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition connect-configs-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 101 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,238] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=connect-configs,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 101 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,238] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 101 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,240] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 102 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,260] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition connect-configs-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:30,260] INFO [Log partition=connect-configs-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:44,533] INFO [Admin Manager on Broker 2]: Error processing create topic request CreatableTopic(name='_confluent-command', numPartitions=1, replicationFactor=2, assignments=[], configs=[CreateableTopicConfig(name='cleanup.policy', value='compact')]) (kafka.server.AdminManager)
[34;1mkafka2                         |[0m org.apache.kafka.common.errors.TopicExistsException: Topic '_confluent-command' already exists.
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,945] INFO Creating topic wikipedia.parsed.replica with configuration {message.downconversion.enable=true, file.delete.delay.ms=60000, segment.ms=604800000, min.compaction.lag.ms=0, retention.bytes=-1, segment.index.bytes=10485760, cleanup.policy=delete, max.compaction.lag.ms=9223372036854775807, follower.replication.throttled.replicas=, message.timestamp.difference.max.ms=9223372036854775807, segment.jitter.ms=0, preallocate=false, message.timestamp.type=CreateTime, message.format.version=2.3-IV1, segment.bytes=1073741824, unclean.leader.election.enable=false, max.message.bytes=1000012, retention.ms=604800000, flush.ms=9223372036854775807, delete.retention.ms=86400000, leader.replication.throttled.replicas=, min.insync.replicas=1, flush.messages=9223372036854775807, compression.type=producer, index.interval.bytes=4096, min.cleanable.dirty.ratio=0.5} and initial partition assignment Map(1 -> ArrayBuffer(2, 1), 0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,950] INFO [Controller id=2] New topics: [Set(wikipedia.parsed.replica)], deleted topics: [Set()], new partition replica assignment [Map(wikipedia.parsed.replica-1 -> Vector(2, 1), wikipedia.parsed.replica-0 -> Vector(1, 2))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] INFO [Controller id=2] New partition creation callback for wikipedia.parsed.replica-1,wikipedia.parsed.replica-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.replica-1 state from NonExistentPartition to NewPartition with assigned replicas 2,1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.replica-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.replica-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.replica-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.replica-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,951] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.replica-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,957] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.replica-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,957] TRACE [Controller id=2 epoch=1] Changed partition wikipedia.parsed.replica-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,957] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 2 for partition wikipedia.parsed.replica-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,957] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 2 for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,957] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) to broker 1 for partition wikipedia.parsed.replica-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,957] TRACE [Controller id=2 epoch=1] Sending become-follower LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) to broker 1 for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.parsed.replica-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) to brokers Set(1, 2) for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.replica-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition wikipedia.parsed.replica-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.replica-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition wikipedia.parsed.replica-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1,2, zkVersion=0, replicas=1,2, isNew=true) correlation id 102 from controller 2 epoch 1 for partition wikipedia.parsed.replica-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,958] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2,1, zkVersion=0, replicas=2,1, isNew=true) correlation id 102 from controller 2 epoch 1 for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,959] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 102 from controller 2 epoch 1 starting the become-leader transition for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,959] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.parsed.replica-1) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,961] INFO [Log partition=wikipedia.parsed.replica-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,962] INFO [Log partition=wikipedia.parsed.replica-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,962] INFO Created log for partition wikipedia.parsed.replica-1 in /var/lib/kafka/data with properties {compression.type -> producer, leader.replication.throttled.replicas -> , message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, follower.replication.throttled.replicas -> , segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,963] INFO [Partition wikipedia.parsed.replica-1 broker=2] No checkpointed highwatermark is found for partition wikipedia.parsed.replica-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,963] INFO Replica loaded for partition wikipedia.parsed.replica-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,963] INFO Replica loaded for partition wikipedia.parsed.replica-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,963] INFO [Partition wikipedia.parsed.replica-1 broker=2] wikipedia.parsed.replica-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,966] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 102 for partition wikipedia.parsed.replica-1 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,966] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 102 from controller 2 epoch 1 for the become-leader transition for partition wikipedia.parsed.replica-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,966] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 102 from controller 2 epoch 1 starting the become-follower transition for partition wikipedia.parsed.replica-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,966] INFO Replica loaded for partition wikipedia.parsed.replica-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,968] INFO [Log partition=wikipedia.parsed.replica-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,968] INFO [Log partition=wikipedia.parsed.replica-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,968] INFO Created log for partition wikipedia.parsed.replica-0 in /var/lib/kafka/data with properties {compression.type -> producer, leader.replication.throttled.replicas -> , message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, follower.replication.throttled.replicas -> , segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] INFO [Partition wikipedia.parsed.replica-0 broker=2] No checkpointed highwatermark is found for partition wikipedia.parsed.replica-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] INFO Replica loaded for partition wikipedia.parsed.replica-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(wikipedia.parsed.replica-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] TRACE [Broker id=2] Stopped fetchers as part of become-follower request from controller 2 epoch 1 with correlation id 102 for partition wikipedia.parsed.replica-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] TRACE [Broker id=2] Truncated logs and checkpointed recovery boundaries for partition wikipedia.parsed.replica-0 as part of become-follower request with correlation id 102 from controller 2 epoch 1 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=kafka1:9091) for partitions Map(wikipedia.parsed.replica-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] TRACE [Broker id=2] Started fetcher to new leader as part of become-follower request from controller 2 epoch 1 with correlation id 102 for partition wikipedia.parsed.replica-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,969] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 102 from controller 2 epoch 1 for the become-follower transition for partition wikipedia.parsed.replica-0 with leader 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,970] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.parsed.replica,partition=0,error_code=0},{topic=wikipedia.parsed.replica,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 102 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,971] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1, 2], zkVersion=0, replicas=[1, 2], offlineReplicas=[]) for partition wikipedia.parsed.replica-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 103 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,971] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2, 1], zkVersion=0, replicas=[2, 1], offlineReplicas=[]) for partition wikipedia.parsed.replica-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 103 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,972] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=wikipedia.parsed.replica,partition=0,error_code=0},{topic=wikipedia.parsed.replica,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 103 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,972] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 103 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:52,973] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 104 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:05:53,333] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition wikipedia.parsed.replica-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[34;1mkafka2                         |[0m [2020-05-20 20:05:53,333] INFO [Log partition=wikipedia.parsed.replica-0, dir=/var/lib/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:19,912] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 70 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:19,919] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 70 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:19,922] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 63 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:19,924] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 19 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:20,009] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 49 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:20,014] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 19 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:41,110] INFO [GroupCoordinator 2]: Preparing to rebalance group _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 in state PreparingRebalance with old generation 0 (__consumer_offsets-17) (reason: Adding new member _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-38055f11-7bf8-44f7-a9ee-5ab14179af47-StreamThread-4-consumer-2825058b-38b5-49b7-b856-28b99799d8a9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:42,210] INFO [GroupCoordinator 2]: Preparing to rebalance group EN_WIKIPEDIA_GT_1_COUNTS-consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-15) (reason: Adding new member consumer-1-15f0f9d3-7b69-48e0-9435-0ec9f3352a2c with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:45,211] INFO [GroupCoordinator 2]: Stabilized group EN_WIKIPEDIA_GT_1_COUNTS-consumer generation 1 (__consumer_offsets-15) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:45,299] INFO [GroupCoordinator 2]: Assignment received from leader for group EN_WIKIPEDIA_GT_1_COUNTS-consumer for generation 1 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,111] INFO [GroupCoordinator 2]: Stabilized group _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 generation 1 (__consumer_offsets-17) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,135] INFO Creating topic _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition with configuration {segment.bytes=52428800, retention.ms=-1, cleanup.policy=delete} and initial partition assignment Map(1 -> ArrayBuffer(1), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,146] INFO [Controller id=2] New topics: [Set(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 -> Vector(1), _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 -> Vector(2))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,146] INFO [Controller id=2] New partition creation callback for _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1,_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,146] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,146] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,146] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,146] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2, zkVersion=0, replicas=2, isNew=true) to broker 2 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,151] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,152] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2, zkVersion=0, replicas=2, isNew=true) correlation id 104 from controller 2 epoch 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,153] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 104 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,153] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,155] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,155] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,156] INFO Created log for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.bytes -> 52428800, retention.ms -> -1, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,156] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 broker=2] No checkpointed highwatermark is found for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,156] INFO Replica loaded for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,156] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 broker=2] _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,159] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 104 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,159] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 104 from controller 2 epoch 1 for the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,160] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 104 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,160] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 105 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,160] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 105 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,160] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 105 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,196] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 106 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,196] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 105 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,201] INFO Creating topic _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog with configuration {retention.ms=172800000, cleanup.policy=compact,delete} and initial partition assignment Map(1 -> ArrayBuffer(2), 0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,210] INFO [Controller id=2] New topics: [Set(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog)], deleted topics: [Set()], new partition replica assignment [Map(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 -> Vector(2), _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 -> Vector(1))] (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,210] INFO [Controller id=2] New partition creation callback for _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1,_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,210] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,210] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,211] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,211] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 from NonExistentReplica to NewReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Changed partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2, zkVersion=0, replicas=2, isNew=true) to broker 2 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Sending become-leader LeaderAndIsr request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=1, zkVersion=0, replicas=1, isNew=true) to broker 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Sending UpdateMetadata request PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) to brokers Set(1, 2) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Broker id=2] Received LeaderAndIsr request PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=2, zkVersion=0, replicas=2, isNew=true) correlation id 106 from controller 2 epoch 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,219] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 106 from controller 2 epoch 1 starting the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,219] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1) (kafka.server.ReplicaFetcherManager)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,218] TRACE [Controller id=2 epoch=1] Changed state of replica 2 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,220] TRACE [Controller id=2 epoch=1] Changed state of replica 1 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 from NewReplica to OnlineReplica (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,221] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,226] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog,partition=0,error_code=0}]} for request LEADER_AND_ISR with correlation id 107 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,227] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 108 sent to broker kafka1:9091 (id: 1 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,232] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1, dir=/var/lib/kafka/data] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,232] INFO Created log for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 in /var/lib/kafka/data with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact,delete, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 172800000, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,233] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 broker=2] No checkpointed highwatermark is found for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,233] INFO Replica loaded for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 with initial high watermark 0 (kafka.cluster.Replica)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,233] INFO [Partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 broker=2] _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,236] TRACE [Broker id=2] Stopped fetchers as part of become-leader request from controller 2 epoch 1 with correlation id 106 for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (last update controller epoch 1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,236] TRACE [Broker id=2] Completed LeaderAndIsr request correlationId 106 from controller 2 epoch 1 for the become-leader transition for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,236] TRACE [Controller id=2 epoch=1] Received response {error_code=0,partitions=[{topic=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog,partition=1,error_code=0}]} for request LEADER_AND_ISR with correlation id 106 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,237] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 107 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,237] TRACE [Broker id=2] Cached leader info PartitionState(controllerEpoch=1, leader=2, leaderEpoch=0, isr=[2], zkVersion=0, replicas=[2], offlineReplicas=[]) for partition _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 in response to UpdateMetadata request sent by controller 2 epoch 1 with correlation id 107 (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,238] TRACE [Controller id=2 epoch=1] Received response {error_code=0} for request UPDATE_METADATA with correlation id 107 sent to broker kafka2:9092 (id: 2 rack: r1) (state.change.logger)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,322] INFO [GroupCoordinator 2]: Assignment received from leader for group _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:47,500] INFO [GroupCoordinator 2]: Preparing to rebalance group _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 in state PreparingRebalance with old generation 1 (__consumer_offsets-17) (reason: Updating metadata for member _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-38055f11-7bf8-44f7-a9ee-5ab14179af47-StreamThread-1-consumer-a21c633c-d847-4eb8-839c-c9a79225f6b9) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,501] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 224 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,505] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 224 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,509] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 193 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,511] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 65 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,605] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 65 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,608] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 179 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,835] INFO [GroupCoordinator 2]: Stabilized group _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 generation 2 (__consumer_offsets-17) (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:50,840] INFO [GroupCoordinator 2]: Assignment received from leader for group _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2 for generation 2 (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka2                         |[0m [2020-05-20 20:06:57,403] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:06:59,512] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 18 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:01,544] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 23 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:03,632] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 29 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:05,796] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 34 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:07,816] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 35 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:09,915] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 43 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:12,001] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 47 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:14,031] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 48 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:16,117] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 51 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:18,135] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 54 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:20,219] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 55 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:21,096] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 630 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:21,099] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 630 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:21,102] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 547 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:21,105] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 173 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:21,152] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 515 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:21,155] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 173 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:22,310] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 57 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:24,403] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 63 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:26,458] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 68 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:28,530] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 72 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:30,628] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 73 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:32,698] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 77 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:34,724] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 79 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:36,743] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 86 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:38,841] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 89 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:40,876] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 91 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:42,911] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 95 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:44,972] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 97 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:46,985] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 98 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:49,048] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 104 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,152] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 108 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,505] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1106 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,508] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1106 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,510] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 931 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,513] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 301 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,516] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 899 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:51,518] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 301 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:53,231] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 113 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:55,245] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 118 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:57,270] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 121 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:07:59,353] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 123 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:01,460] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 128 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:03,528] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 131 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:05,627] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 135 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:07,664] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 138 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:09,802] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 140 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:13,916] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 145 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:15,949] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 148 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:17,987] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 151 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:20,010] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 156 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:21,743] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1547 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:21,745] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1547 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:21,748] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1319 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:21,798] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 424 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:21,829] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1283 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:21,832] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 424 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:22,031] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 160 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:24,107] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 165 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:26,139] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 170 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:28,223] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 171 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:30,288] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 174 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:32,392] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 179 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:34,419] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 185 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:36,527] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 188 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:38,611] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 192 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:40,706] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 194 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:42,772] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 200 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:44,821] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 202 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:46,885] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 206 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:48,995] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 210 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:51,074] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 212 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:52,021] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1995 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:52,024] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1995 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:52,027] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1703 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:52,029] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 552 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:52,030] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 1667 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:52,032] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 552 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:53,117] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 214 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:55,209] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 216 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:57,310] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 223 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:08:59,372] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 225 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:01,391] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 227 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:03,415] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 228 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:05,457] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 230 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:07,504] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 234 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:09,571] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 237 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:11,635] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 238 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:13,662] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 242 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:15,749] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 245 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:17,859] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 249 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:19,903] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 250 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:21,940] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 253 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:22,343] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2443 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:22,346] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2443 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:22,348] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2091 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:22,351] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 676 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:22,436] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2051 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:22,439] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 676 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:23,973] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 256 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,669] INFO [Controller id=2] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,669] TRACE [Controller id=2] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,672] DEBUG [Controller id=2] Preferred replicas by broker Map(2 -> Map(connect-offsets-20 -> Vector(2, 1), WIKIPEDIANOBOT-1 -> Vector(2, 1), __consumer_offsets-21 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-KSTREAM-OUTEROTHER-0000000105-store-changelog-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0 -> Vector(2, 1), _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0 -> Vector(2), __consumer_offsets-27 -> Vector(2, 1), __consumer_offsets-7 -> Vector(2, 1), __consumer_offsets-9 -> Vector(2, 1), connect-offsets-24 -> Vector(2, 1), connect-offsets-16 -> Vector(2, 1), connect-statuses-3 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-group-stream-extension-rekey-0 -> Vector(2, 1), _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-1 -> Vector(2), __consumer_offsets-25 -> Vector(2, 1), EN_WIKIPEDIA_GT_1-1 -> Vector(2, 1), __consumer_offsets-35 -> Vector(2, 1), wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-1 -> Vector(2), _confluent-controlcenter-5-3-1-1-cluster-rekey-0 -> Vector(2, 1), __consumer_offsets-41 -> Vector(2, 1), __consumer_offsets-33 -> Vector(2, 1), __consumer_offsets-23 -> Vector(2, 1), __consumer_offsets-49 -> Vector(2, 1), __consumer_offsets-47 -> Vector(2, 1), connect-offsets-6 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-monitoring-message-rekey-store-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0 -> Vector(2, 1), __consumer_offsets-31 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-changelog-0 -> Vector(2, 1), __consumer_offsets-3 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-aggregate-topic-partition-store-changelog-0 -> Vector(2, 1), __consumer_offsets-37 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-actual-group-consumption-rekey-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-TriggerEventsStore-changelog-0 -> Vector(2, 1), connect-offsets-10 -> Vector(2, 1), _confluent-command-0 -> Vector(2, 1), __consumer_offsets-15 -> Vector(2, 1), connect-offsets-2 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-changelog-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-Group-ONE_MINUTE-changelog-0 -> Vector(2, 1), connect-offsets-18 -> Vector(2, 1), __consumer_offsets-17 -> Vector(2, 1), EN_WIKIPEDIA_GT_1_COUNTS-0 -> Vector(2, 1), __confluent.support.metrics-0 -> Vector(2, 1), __consumer_offsets-19 -> Vector(2, 1), _confluent-metrics-0 -> Vector(2, 1), __consumer_offsets-11 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-changelog-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0 -> Vector(2, 1), __consumer_offsets-13 -> Vector(2, 1), WIKIPEDIABOT-1 -> Vector(2, 1), connect-offsets-4 -> Vector(2, 1), __consumer_offsets-43 -> Vector(2, 1), connect-offsets-12 -> Vector(2, 1), wikipedia.parsed.count-by-channel-0 -> Vector(2, 1), wikipedia.parsed-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-expected-group-consumption-rekey-0 -> Vector(2, 1), connect-offsets-14 -> Vector(2, 1), connect-offsets-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringVerifierStore-changelog-0 -> Vector(2, 1), wikipedia.parsed.replica-1 -> Vector(2, 1), connect-offsets-8 -> Vector(2, 1), wikipedia.failed-1 -> Vector(2, 1), __consumer_offsets-39 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-MonitoringTriggerStore-changelog-0 -> Vector(2, 1), __consumer_offsets-45 -> Vector(2, 1), _confluent-controlcenter-5-3-1-1-group-aggregate-store-THREE_HOURS-changelog-0 -> Vector(2, 1), __consumer_offsets-1 -> Vector(2, 1), __consumer_offsets-5 -> Vector(2, 1), __consumer_offsets-29 -> Vector(2, 1), connect-offsets-22 -> Vector(2, 1), connect-statuses-1 -> Vector(2, 1), users-0 -> Vector(2, 1)), 1 -> Map(wikipedia.parsed.count-by-channel-1 -> Vector(1, 2), __consumer_offsets-22 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-changelog-0 -> Vector(1, 2), __consumer_offsets-30 -> Vector(1, 2), _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-1 -> Vector(1), wikipedia.parsed.replica-0 -> Vector(1, 2), __consumer_offsets-8 -> Vector(1, 2), __consumer_offsets-4 -> Vector(1, 2), _confluent-ksql-default__command_topic-0 -> Vector(1), _confluent-controlcenter-5-3-1-1-AlertHistoryStore-changelog-0 -> Vector(1, 2), __consumer_offsets-46 -> Vector(1, 2), _confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-aggregate-changelog-0 -> Vector(1), connect-offsets-7 -> Vector(1, 2), users-1 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-metrics-trigger-measurement-rekey-0 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-Group-THREE_HOURS-changelog-0 -> Vector(1, 2), connect-statuses-4 -> Vector(1, 2), _schemas-0 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-TriggerActionsStore-changelog-0 -> Vector(1, 2), connect-offsets-3 -> Vector(1, 2), connect-offsets-21 -> Vector(1, 2), connect-offsets-11 -> Vector(1, 2), __consumer_offsets-16 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0 -> Vector(1, 2), connect-configs-0 -> Vector(1, 2), __consumer_offsets-28 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-KSTREAM-OUTERTHIS-0000000104-store-changelog-0 -> Vector(1, 2), __consumer_offsets-36 -> Vector(1, 2), __consumer_offsets-42 -> Vector(1, 2), EN_WIKIPEDIA_GT_1_COUNTS-1 -> Vector(1, 2), __consumer_offsets-18 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-MetricsAggregateStore-repartition-0 -> Vector(1, 2), connect-offsets-17 -> Vector(1, 2), WIKIPEDIANOBOT-0 -> Vector(1, 2), connect-statuses-2 -> Vector(1, 2), wikipedia.parsed-1 -> Vector(1, 2), __consumer_offsets-24 -> Vector(1, 2), connect-offsets-23 -> Vector(1, 2), connect-statuses-0 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-changelog-0 -> Vector(1, 2), __consumer_offsets-38 -> Vector(1, 2), WIKIPEDIABOT-0 -> Vector(1, 2), __consumer_offsets-48 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-monitoring-trigger-event-rekey-0 -> Vector(1, 2), EN_WIKIPEDIA_GT_1-0 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-changelog-0 -> Vector(1, 2), connect-offsets-15 -> Vector(1, 2), wikipedia.failed-0 -> Vector(1, 2), __consumer_offsets-2 -> Vector(1, 2), __consumer_offsets-6 -> Vector(1, 2), __consumer_offsets-14 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0 -> Vector(1, 2), wikipedia-activity-monitor-KSTREAM-AGGREGATE-STATE-STORE-0000000002-changelog-0 -> Vector(1), connect-offsets-5 -> Vector(1, 2), connect-offsets-13 -> Vector(1, 2), __consumer_offsets-20 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-changelog-0 -> Vector(1, 2), __consumer_offsets-0 -> Vector(1, 2), __consumer_offsets-44 -> Vector(1, 2), __consumer_offsets-12 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-monitoring-aggregate-rekey-store-changelog-0 -> Vector(1, 2), _confluent-monitoring-0 -> Vector(1, 2), __consumer_offsets-26 -> Vector(1, 2), connect-offsets-9 -> Vector(1, 2), connect-offsets-1 -> Vector(1, 2), connect-offsets-19 -> Vector(1, 2), __consumer_offsets-34 -> Vector(1, 2), __consumer_offsets-10 -> Vector(1, 2), __consumer_offsets-32 -> Vector(1, 2), __consumer_offsets-40 -> Vector(1, 2), _confluent-controlcenter-5-3-1-1-group-aggregate-store-ONE_MINUTE-changelog-0 -> Vector(1, 2))) (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,672] DEBUG [Controller id=2] Topics not in preferred replica for broker 2 Map() (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,672] TRACE [Controller id=2] Leader imbalance ratio for broker 2 is 0.0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,672] DEBUG [Controller id=2] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:24,672] TRACE [Controller id=2] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
[34;1mkafka2                         |[0m [2020-05-20 20:09:25,996] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 259 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:28,046] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 265 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:30,076] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 268 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:32,127] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 271 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:34,162] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 275 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:36,215] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 280 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:38,289] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 285 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:40,375] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 288 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:42,461] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 294 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:44,539] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 300 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:46,566] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 303 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:48,625] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 304 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:50,731] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 305 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,741] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2891 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,744] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2891 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,747] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2475 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,750] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 800 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,755] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 307 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,802] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2435 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:52,805] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 800 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:54,855] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 312 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:56,879] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 315 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:09:58,912] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 319 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:00,952] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 325 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:02,971] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 329 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:04,997] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 333 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:07,012] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 340 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:09,120] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 343 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:11,218] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 347 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:13,317] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 351 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:15,328] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 358 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:17,357] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 361 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:19,435] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 363 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:21,702] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 367 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,147] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 3332 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,150] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringStream-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 3332 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,153] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2856 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,156] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 924 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,211] INFO [Log partition=_confluent-controlcenter-5-3-1-1-MonitoringMessageAggregatorWindows-THREE_HOURS-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 2812 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,214] INFO [Log partition=_confluent-controlcenter-5-3-1-1-aggregatedTopicPartitionTableWindows-ONE_MINUTE-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 924 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:23,765] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 375 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:25,854] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 377 (kafka.log.Log)
[34;1mkafka2                         |[0m [2020-05-20 20:10:27,897] INFO [Log partition=_confluent-ksql-default_query_CTAS_EN_WIKIPEDIA_GT_1_2-Aggregate-groupby-repartition-0, dir=/var/lib/kafka/data] Incrementing log start offset to 379 (kafka.log.Log)
